{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d070edd",
   "metadata": {},
   "source": [
    "## Εισαγωγικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f6e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a72d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomState(MT19937) at 0x29D7FAB2440"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "import random\n",
    "import os\n",
    "SEED = 56\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "check_random_state(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1571613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f1c43",
   "metadata": {},
   "source": [
    "## Β. Προεπεξεργασία και Εξερεύνηση Δεδομένων"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ff506",
   "metadata": {},
   "source": [
    "### 1. Εξερευνητική Ανάλυση Δεδομένων (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9ae4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the dataset: ['train_images', 'train_labels', 'val_images', 'val_labels', 'test_images', 'test_labels']\n",
      "Shape of file contents: (no of contents, dimensions (224x224))\n",
      "train_images: (546, 224, 224)\n",
      "train_labels: (546, 1)\n",
      "val_images: (78, 224, 224)\n",
      "val_labels: (78, 1)\n",
      "test_images: (156, 224, 224)\n",
      "test_labels: (156, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load data with pickling enabled\n",
    "data = np.load(r'C:\\\\Users\\\\vasgk\\\\Desktop\\\\Μηχανική μάθηση\\\\Data\\\\breastmnist_224.npz', allow_pickle=True)\n",
    "\n",
    "# Inspect the keys in the dataset\n",
    "print(\"Keys in the dataset:\", data.files)\n",
    "print(\"Shape of file contents: (no of contents, dimensions (224x224))\")\n",
    "\n",
    "# Print the shape of each file in the original npz file\n",
    "for key in data.files:\n",
    "    print(f\"{key}: {data[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a DataFrame\n",
    "# Flatten the images and combine them with labels\n",
    "train_images_flat = data['train_images'].reshape(len(data['train_images']), -1)  # Flatten 224x224 images\n",
    "df_train = pd.DataFrame(train_images_flat)\n",
    "df_train['Label'] = data['train_labels']\n",
    "\n",
    "val_images_flat = data['val_images'].reshape(len(data['val_images']), -1)\n",
    "df_val = pd.DataFrame(val_images_flat)\n",
    "df_val['Label'] = data['val_labels']\n",
    "\n",
    "# Combine train and validation sets into a new train set\n",
    "combined_images_flat = np.vstack([train_images_flat, val_images_flat])\n",
    "combined_labels = np.concatenate([data['train_labels'], data['val_labels']])\n",
    "\n",
    "df_train_combined = pd.DataFrame(combined_images_flat)\n",
    "df_train_combined['Label'] = combined_labels\n",
    "\n",
    "# Flatten the test images and create a DataFrame with labels\n",
    "test_images_flat = data['test_images'].reshape(len(data['test_images']), -1)\n",
    "df_test = pd.DataFrame(test_images_flat)\n",
    "df_test['Label'] = data['test_labels']\n",
    "\n",
    "# Split the data into features and labels for the rest of the code to be compatible with my group's code \n",
    "x_train = df_train_combined.drop(columns=['Label']).values\n",
    "y_train = df_train_combined['Label'].values.ravel()\n",
    "x_test = df_test.drop(columns=['Label']).values  \n",
    "y_test = df_test['Label'].values.ravel()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b054651",
   "metadata": {},
   "source": [
    "### 2. Προεπεξεργασία Δεδομένων"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b53a34",
   "metadata": {},
   "source": [
    "#### α. Χειρισμός ακραίων τιμών: δεν υπάρχουν ελλειπούσες τιμές"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b24c64",
   "metadata": {},
   "source": [
    "#### β. Κανονικοποίηση/Τυποποίηση χαρακτηριστικών: \n",
    "Για την κανονικοποίηση/τυποποίηση των χαρακτηριστικών, εφαρμόστηκε η μέθοδος Standard Scaling (Z-score normalization), ώστε κάθε χαρακτηριστικό να έχει μέση τιμή 0 και τυπική απόκλιση 1. Η επιλογή αυτή έγινε επειδή οι αλγόριθμοι PCA, LDA και Logistic Regression είναι ευαίσθητοι στην κλίμακα των χαρακτηριστικών. Η κατανομή των τιμών πριν και μετά την τυποποίηση απεικονίστηκε με ιστογράμματα, ενώ παρατηρήθηκε ότι η τυποποίηση βελτιώνει τη διακριτική ικανότητα και τη σύγκλιση των αλγορίθμων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c5d438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "x_train_std = scaler.fit_transform(train_images_flat)\n",
    "x_val_std = scaler.transform(val_images_flat)  \n",
    "x_test_std = scaler.transform(test_images_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e1b47",
   "metadata": {},
   "source": [
    "### γ. Επιλογή και μετασχηματισμός χαρακτηριστικών:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da9840",
   "metadata": {},
   "source": [
    "#### 1. Αφαίρεση χαρακτηριστικών με χαμηλή διακύμανση (Remove low-variance features)\n",
    "You can use VarianceThreshold from scikit-learn to remove features (pixels) with very low variance, which are unlikely to be useful for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1e0bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (546, 50176)\n",
      "After variance thresholding: (546, 50176)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Remove features with variance below a threshold (e.g., 0.01)\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "x_train_var = selector.fit_transform(x_train_std)\n",
    "x_val_var = selector.transform(x_val_std)\n",
    "x_test_var = selector.transform(x_test_std)\n",
    "\n",
    "print(\"Original shape:\", x_train_std.shape)\n",
    "print(\"After variance thresholding:\", x_train_var.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b20ce8",
   "metadata": {},
   "source": [
    "#### 2. Δημιουργία νέων χαρακτηριστικών (Feature engineering)\n",
    "For images, common new features include mean, standard deviation, or other statistics per image. Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6d1b93",
   "metadata": {},
   "source": [
    "#### Extracting Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aee0a6",
   "metadata": {},
   "source": [
    "#### σσ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00cce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mean and std of pixel values as new features\n",
    "train_means = x_train.reshape(x_train.shape[0], -1).mean(axis=1).reshape(-1, 1)\n",
    "train_stds = x_train.reshape(x_train.shape[0], -1).std(axis=1).reshape(-1, 1)\n",
    "x_train_fe = np.hstack([x_train_var, train_means, train_stds])\n",
    "\n",
    "test_means = x_test.reshape(x_test.shape[0], -1).mean(axis=1).reshape(-1, 1)\n",
    "test_stds = x_test.reshape(x_test.shape[0], -1).std(axis=1).reshape(-1, 1)\n",
    "x_test_fe = np.hstack([x_test_var, test_means, test_stds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a00f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without mean/std: 0.8718\n",
      "Accuracy with mean/std:    0.8590\n"
     ]
    }
   ],
   "source": [
    "# Train a simple model to compare performance with and without the new features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Model with only variance-thresholded features\n",
    "clf1 = LogisticRegression(max_iter=1000, random_state=56)\n",
    "clf1.fit(x_train_var, y_train)\n",
    "y_pred1 = clf1.predict(x_val_var)\n",
    "acc1 = accuracy_score(y_test, y_pred1)\n",
    "\n",
    "# Model with mean and std features added\n",
    "clf2 = LogisticRegression(max_iter=1000, random_state=56)\n",
    "clf2.fit(x_train_fe, y_train)\n",
    "y_pred2 = clf2.predict(x_test_fe)\n",
    "acc2 = accuracy_score(y_test, y_pred2)\n",
    "\n",
    "# model with all stats\n",
    "\n",
    "print(f\"Accuracy without mean/std: {acc1:.4f}\")\n",
    "print(f\"Accuracy with mean/std:    {acc2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
