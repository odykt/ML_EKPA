{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8464c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Εγκατάσταση των βιβλιοθηκών numpy (για αριθμητικούς υπολογισμούς), pandas (για επεξεργασία δεδομένων),\n",
    "# matplotlib και seaborn (για οπτικοποίηση δεδομένων), scikit-learn (για machine learning) και torch (για deep learning)\n",
    "# Οι βιβλιοθήκες είναι ήδη εγκατεστημένες στο περιβάλλον και δεν χρειάζεται να τις ξαναεγκαταστήσουμε.\n",
    "# Αν κάποιος τρέξει το notebook σε νέο περιβάλλον, θα χρειαστεί να εκτελέσει την εξής εντολή για να εγκαταστήσει τις βιβλιοθήκες:\n",
    "# !pip install numpy pandas matplotlib seaborn scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68b106a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Εισαγωγή των απαραίτητων βιβλιοθηκών\n",
    "\n",
    "import torch # για deep learning\n",
    "import numpy as np # για αριθμητικούς υπολογισμούς\n",
    "import torch.nn as nn # για νευρωνικά δίκτυα\n",
    "import torch.optim as optim # για βελτιστοποίηση\n",
    "from torch.utils.data import DataLoader, TensorDataset # για διαχείριση δεδομένων\n",
    "import matplotlib.pyplot as plt # για οπτικοποίηση δεδομένων\n",
    "import seaborn as sns # για οπτικοποίηση δεδομένων\n",
    "import random\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score  # για αξιολόγηση μοντέλου\n",
    "from sklearn.preprocessing import label_binarize # για μετατροπή ετικετών σε δυαδική μορφή\n",
    "from sklearn.preprocessing import LabelEncoder # για μετατροπή ετικετών σε αριθμητικές τιμές\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cecc2f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Ορισμός του seed για αναπαραγωγιμότητα\n",
    "seed = 42\n",
    "random.seed(seed)  # Για τη βιβλιοθήκη random\n",
    "np.random.seed(seed)  # Για τη βιβλιοθήκη NumPy\n",
    "\n",
    "# Για PyTorch, αν το χρησιμοποιείς:\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # Σε πολλαπλές GPU αν υπάρχουν\n",
    "\n",
    "# Ρυθμίσεις για αναπαραγωγιμότητα με GPU\n",
    "torch.backends.cudnn.deterministic = True  # Αναγκάζει ντετερμινιστικές πράξεις\n",
    "torch.backends.cudnn.benchmark = False  # Απενεργοποιεί το benchmarking για τα βελτιστοποιημένα μεγέθη μπλοκ\n",
    "\n",
    "# Ελέγχουμε εάν το seed έχει ρυθμιστεί σωστά\n",
    "print(f\"Random seed set to {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3451e243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Χρησιμοποιούμε τη συσκευή: cuda\n"
     ]
    }
   ],
   "source": [
    "# Ελέγχουμε αν υπάρχει GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Χρησιμοποιούμε τη συσκευή: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26c0422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Φορτώθηκε το Σχήμα Συνόλου Εκπαίδευσης: (2800, 4096), ετικέτες: (2800,)\n",
      "Φορτώθηκε το Σχήμα Συνόλου Δοκιμής: (1200, 4096), ετικέτες: (1200,)\n",
      "Ονόματα Κατηγοριών: ['BreastMRI' 'ChestCT' 'CXR' 'Hand']\n"
     ]
    }
   ],
   "source": [
    "# Φορτώνουμε τα δεδομένα από το αρχείο που αποθηκεύσαμε\n",
    "\n",
    "data = np.load('train_test_images_normalized_images.npz')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "class_names = data['class_names']  # Φόρτωση των ονομάτων των κατηγοριών\n",
    "\n",
    "# Εκτύπωση των σχημάτων και των ονομάτων των κατηγοριών\n",
    "print(f\"Φορτώθηκε το Σχήμα Συνόλου Εκπαίδευσης: {X_train.shape}, ετικέτες: {y_train.shape}\")\n",
    "print(f\"Φορτώθηκε το Σχήμα Συνόλου Δοκιμής: {X_test.shape}, ετικέτες: {y_test.shape}\")\n",
    "print(f\"Ονόματα Κατηγοριών: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5b49f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Τα δεδομένα είναι έτοιμα και μετατράπηκαν σε Tensors με σχήμα:\n",
      "X_train: torch.Size([2800, 4096]), X_test: torch.Size([1200, 4096])\n",
      "y_train: torch.Size([2800]), y_test: torch.Size([1200])\n"
     ]
    }
   ],
   "source": [
    "# Μετατροπή των ετικετών σε κατηγορίες \n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Μετατροπή των δεδομένων σε PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "print(f\"Τα δεδομένα είναι έτοιμα και μετατράπηκαν σε Tensors με σχήμα:\")\n",
    "print(f\"X_train: {X_train_tensor.shape}, X_test: {X_test_tensor.shape}\")\n",
    "print(f\"y_train: {y_train_tensor.shape}, y_test: {y_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b3e28",
   "metadata": {},
   "source": [
    "Για την αρχιτεκτονική του MLP επιλέξαμε τρία κρυφά επίπεδα με 512, 256 και 128 νευρώνες, προκειμένου το μοντέλο να μπορεί να μάθει σύνθετες σχέσεις στα δεδομένα, χωρίς να είναι υπερβολικά μεγάλο και αργό. Χρησιμοποιήσαμε τη συνάρτηση ενεργοποίησης ReLU για να αποφύγουμε το πρόβλημα του vanishing gradient και προσθέσαμε Dropout (50%) για να μειώσουμε την υπερπροσαρμογή και να βελτιώσουμε τη γενίκευση του μοντέλου. Επίσης, ενεργοποιήσαμε το Batch Normalization για πιο γρήγορη και σταθερή εκπαίδευση. Το μοντέλο εκπαιδεύτηκε για 20 εποχές με Adam optimizer και L2 regularization για καλύτερη απόδοση και αποφυγή υπερβολικής προσαρμογής στις ειδικές περιπτώσεις του training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "49161572",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.0, use_batchnorm=False):\n",
    "        super(MLP, self).__init__()\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.layers = nn.ModuleList()  # Αρχικοποιούμε τη λίστα των layers\n",
    "        in_size = input_size\n",
    "        \n",
    "        # Δημιουργία των κρυφών επιπέδων\n",
    "        for hidden_size in hidden_sizes:\n",
    "            self.layers.append(nn.Linear(in_size, hidden_size))  # Πρόσθεση Linear Layer\n",
    "            if self.use_batchnorm: \n",
    "                self.layers.append(nn.BatchNorm1d(hidden_size))  # Πρόσθεση Batch Normalization (αν το ζητήσουμε)\n",
    "            self.layers.append(nn.ReLU())  # Συναρτήσεις ενεργοποίησης ReLU\n",
    "            self.layers.append(nn.Dropout(dropout_rate))  # Πρόσθεση Dropout για κανονικοποίηση\n",
    "            in_size = hidden_size  # Ορίζουμε το in_size για το επόμενο επίπεδο\n",
    "\n",
    "        # Εξοδος\n",
    "        self.output = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Προώθηση μέσω των layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Προώθηση μέσω του τελευταίου επιπέδου (output layer)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b19d8864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.5047, Train Accuracy: 26.36%, Test Accuracy: 96.25%\n",
      "Epoch [2/20], Loss: 0.9106, Train Accuracy: 71.36%, Test Accuracy: 97.33%\n",
      "Epoch [3/20], Loss: 0.6762, Train Accuracy: 88.89%, Test Accuracy: 97.58%\n",
      "Epoch [4/20], Loss: 0.5299, Train Accuracy: 94.32%, Test Accuracy: 97.92%\n",
      "Epoch [5/20], Loss: 0.4270, Train Accuracy: 96.11%, Test Accuracy: 98.00%\n",
      "Epoch [6/20], Loss: 0.3563, Train Accuracy: 96.96%, Test Accuracy: 98.00%\n",
      "Epoch [7/20], Loss: 0.3082, Train Accuracy: 97.36%, Test Accuracy: 98.25%\n",
      "Epoch [8/20], Loss: 0.2712, Train Accuracy: 97.50%, Test Accuracy: 98.25%\n",
      "Epoch [9/20], Loss: 0.2356, Train Accuracy: 97.46%, Test Accuracy: 98.25%\n",
      "Epoch [10/20], Loss: 0.2157, Train Accuracy: 97.75%, Test Accuracy: 98.17%\n",
      "Epoch [11/20], Loss: 0.1929, Train Accuracy: 97.61%, Test Accuracy: 98.25%\n",
      "Epoch [12/20], Loss: 0.1730, Train Accuracy: 97.86%, Test Accuracy: 98.25%\n",
      "Epoch [13/20], Loss: 0.1581, Train Accuracy: 98.18%, Test Accuracy: 98.25%\n",
      "Epoch [14/20], Loss: 0.1506, Train Accuracy: 98.11%, Test Accuracy: 98.33%\n",
      "Epoch [15/20], Loss: 0.1372, Train Accuracy: 98.29%, Test Accuracy: 98.42%\n",
      "Epoch [16/20], Loss: 0.1270, Train Accuracy: 98.29%, Test Accuracy: 98.67%\n",
      "Epoch [17/20], Loss: 0.1177, Train Accuracy: 98.43%, Test Accuracy: 98.75%\n",
      "Epoch [18/20], Loss: 0.1095, Train Accuracy: 98.43%, Test Accuracy: 98.83%\n",
      "Epoch [19/20], Loss: 0.1035, Train Accuracy: 98.68%, Test Accuracy: 99.00%\n",
      "Epoch [20/20], Loss: 0.0999, Train Accuracy: 98.86%, Test Accuracy: 99.17%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.17%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   BreastMRI       0.99      1.00      1.00       300\n",
      "     ChestCT       0.99      0.99      0.99       300\n",
      "         CXR       0.99      1.00      1.00       300\n",
      "        Hand       0.99      0.98      0.98       300\n",
      "\n",
      "    accuracy                           0.99      1200\n",
      "   macro avg       0.99      0.99      0.99      1200\n",
      "weighted avg       0.99      0.99      0.99      1200\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ορισμός υπερπαραμέτρων\n",
    "input_size = X_train_tensor.shape[1]  # 4096\n",
    "hidden_sizes = [512, 256, 128]  # Μπορούμε να προσαρμόσουμε τα μεγέθη των κρυφών επιπέδων\n",
    "output_size = len(np.unique(y_train))  # Ο αριθμός των κατηγοριών\n",
    "dropout_rate = 0.5\n",
    "use_batchnorm = True\n",
    "\n",
    "# Δημιουργία του μοντέλου\n",
    "model = MLP(input_size, hidden_sizes, output_size, dropout_rate, use_batchnorm).to(device)\n",
    "\n",
    "# Ορισμός του Loss Function και του Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Χρησιμοποιούμε το CrossEntropyLoss για ταξινόμηση\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Αριθμός εποχών\n",
    "num_epochs = 20\n",
    "\n",
    "# Αρχικοποίηση των λιστών για την καταγραφή της απώλειας και της ακρίβειας\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Εκπαίδευση του μοντέλου\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()  # Θέτουμε το μοντέλο σε training mode\n",
    "    optimizer.zero_grad()  # Μηδενίζουμε τους παραμέτρους του βελτιστοποιητή\n",
    "    \n",
    "    # Forward Pass για το train set\n",
    "    outputs_train = model(X_train_tensor)\n",
    "    loss_train = criterion(outputs_train, y_train_tensor)\n",
    "    \n",
    "    # Backward Pass και Βελτιστοποίηση\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Υπολογισμός της ακρίβειας για το train set\n",
    "    _, predicted_train = torch.max(outputs_train, 1)\n",
    "    train_accuracy = accuracy_score(y_train_tensor.cpu(), predicted_train.cpu())\n",
    "    \n",
    "    # Αξιολόγηση στο test set\n",
    "    model.eval()  # Θέτουμε το μοντέλο σε evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs_test = model(X_test_tensor)\n",
    "        loss_test = criterion(outputs_test, y_test_tensor)\n",
    "        _, predicted_test = torch.max(outputs_test, 1)\n",
    "        test_accuracy = accuracy_score(y_test_tensor.cpu(), predicted_test.cpu())\n",
    "    \n",
    "    # Καταγραφή των τιμών του loss και accuracy\n",
    "    train_losses.append(loss_train.item())\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_losses.append(loss_test.item())\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    # Εκτύπωση της πρόοδου κάθε epoch\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss_train.item():.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy * 100:.2f}%, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Οπτικοποίηση των Loss και Accuracy για Train και Test\n",
    "# Loss Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss', color='red')\n",
    "plt.title('Train vs Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy', color='blue')\n",
    "plt.plot(range(1, num_epochs + 1), test_accuracies, label='Test Accuracy', color='red')\n",
    "plt.title('Train vs Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Αξιολόγηση του μοντέλου στο test set\n",
    "model.eval()  # Θέτουμε το μοντέλο σε evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs_test = model(X_test_tensor)  # Εκτιμούμε το test set\n",
    "    _, predicted_test = torch.max(outputs_test, 1)  # Παίρνουμε τις προβλέψεις\n",
    "    \n",
    "    # Υπολογισμός της ακρίβειας για το test set\n",
    "    test_accuracy = accuracy_score(y_test_tensor.cpu(), predicted_test.cpu())\n",
    "    print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_tensor.cpu(), predicted_test.cpu(), target_names=class_names))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_tensor.cpu(), predicted_test.cpu())\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve - Multi-class ROC Curve\n",
    "    y_test_bin = label_binarize(y_test_tensor.cpu(), classes=np.arange(len(class_names)))\n",
    "    outputs_test_softmax = outputs_test.softmax(dim=1).cpu().numpy()  # Softmax για την εκτίμηση των πιθανοτήτων\n",
    "    \n",
    "    # Υπολογισμός του ROC Curve για κάθε κατηγορία\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    for i in range(len(class_names)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], outputs_test_softmax[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "    # Plotting ROC Curve για κάθε κατηγορία\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(len(class_names)):\n",
    "        plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-class ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a1fb5c",
   "metadata": {},
   "source": [
    "Ακολουθούν ακόμη κάποιοι πειραματισμοί με διαφορετικές υπερπαραμέτρους (ρυθμός μάθησης-learning rate, αριθμός επιπέδων και νευρώνων, συναρτήσεις ενεργοποίησης) και τεχνικές κανονικοποίησης και regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "853ee7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.5074 | Train Accuracy: 17.36% Test Accuracy: 89.50%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.4053 | Train Accuracy: 95.04% Test Accuracy: 97.75%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2184 | Train Accuracy: 97.18% Test Accuracy: 98.17%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1537 | Train Accuracy: 97.57% Test Accuracy: 98.17%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1204 | Train Accuracy: 97.86% Test Accuracy: 98.17%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1000 | Train Accuracy: 97.96% Test Accuracy: 98.33%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0862 | Train Accuracy: 98.32% Test Accuracy: 98.42%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0799 | Train Accuracy: 98.39% Test Accuracy: 98.67%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0743 | Train Accuracy: 98.43% Test Accuracy: 98.83%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0670 | Train Accuracy: 98.79% Test Accuracy: 99.00%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0610 | Train Accuracy: 98.93% Test Accuracy: 99.17%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0577 | Train Accuracy: 98.96% Test Accuracy: 99.17%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0533 | Train Accuracy: 99.07% Test Accuracy: 99.17%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0512 | Train Accuracy: 99.07% Test Accuracy: 99.17%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0485 | Train Accuracy: 99.11% Test Accuracy: 99.17%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0466 | Train Accuracy: 99.21% Test Accuracy: 99.17%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0430 | Train Accuracy: 99.21% Test Accuracy: 99.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0418 | Train Accuracy: 99.21% Test Accuracy: 99.33%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0383 | Train Accuracy: 99.36% Test Accuracy: 99.42%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0352 | Train Accuracy: 99.32% Test Accuracy: 99.42%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 1.4767 | Train Accuracy: 25.00% Test Accuracy: 60.00%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.5248 | Train Accuracy: 82.64% Test Accuracy: 70.33%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1732 | Train Accuracy: 95.57% Test Accuracy: 97.25%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1237 | Train Accuracy: 96.68% Test Accuracy: 97.58%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0919 | Train Accuracy: 97.32% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0833 | Train Accuracy: 97.64% Test Accuracy: 97.58%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0730 | Train Accuracy: 97.93% Test Accuracy: 97.67%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0687 | Train Accuracy: 98.00% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0601 | Train Accuracy: 98.25% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0547 | Train Accuracy: 98.25% Test Accuracy: 98.17%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0454 | Train Accuracy: 98.57% Test Accuracy: 98.58%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0432 | Train Accuracy: 98.79% Test Accuracy: 98.92%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0413 | Train Accuracy: 98.57% Test Accuracy: 99.00%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0377 | Train Accuracy: 98.79% Test Accuracy: 99.08%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0358 | Train Accuracy: 98.89% Test Accuracy: 99.08%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0337 | Train Accuracy: 99.00% Test Accuracy: 99.08%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0338 | Train Accuracy: 98.79% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0307 | Train Accuracy: 98.93% Test Accuracy: 99.08%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0293 | Train Accuracy: 99.00% Test Accuracy: 99.08%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0292 | Train Accuracy: 98.93% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.4455 | Train Accuracy: 27.50% Test Accuracy: 69.58%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.7328 | Train Accuracy: 88.32% Test Accuracy: 86.00%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4716 | Train Accuracy: 96.00% Test Accuracy: 94.08%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3482 | Train Accuracy: 96.71% Test Accuracy: 96.42%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2819 | Train Accuracy: 97.25% Test Accuracy: 97.42%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2426 | Train Accuracy: 97.39% Test Accuracy: 97.83%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2110 | Train Accuracy: 97.82% Test Accuracy: 97.92%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1929 | Train Accuracy: 97.86% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1741 | Train Accuracy: 97.96% Test Accuracy: 98.08%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1628 | Train Accuracy: 97.96% Test Accuracy: 98.17%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1509 | Train Accuracy: 98.36% Test Accuracy: 98.42%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1425 | Train Accuracy: 98.18% Test Accuracy: 98.75%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1347 | Train Accuracy: 98.29% Test Accuracy: 98.83%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1277 | Train Accuracy: 98.54% Test Accuracy: 98.92%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1205 | Train Accuracy: 98.68% Test Accuracy: 99.00%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1142 | Train Accuracy: 98.93% Test Accuracy: 99.00%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1115 | Train Accuracy: 98.82% Test Accuracy: 99.08%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1068 | Train Accuracy: 98.82% Test Accuracy: 99.08%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0986 | Train Accuracy: 99.11% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0975 | Train Accuracy: 99.18% Test Accuracy: 99.17%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4345 | Train Accuracy: 20.14% Test Accuracy: 97.50%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7959 | Train Accuracy: 95.36% Test Accuracy: 97.58%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6788 | Train Accuracy: 96.68% Test Accuracy: 97.00%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5948 | Train Accuracy: 96.75% Test Accuracy: 97.17%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5356 | Train Accuracy: 96.32% Test Accuracy: 97.42%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4868 | Train Accuracy: 96.46% Test Accuracy: 97.67%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4514 | Train Accuracy: 97.07% Test Accuracy: 97.83%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4207 | Train Accuracy: 97.07% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3927 | Train Accuracy: 97.18% Test Accuracy: 97.75%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3698 | Train Accuracy: 97.36% Test Accuracy: 98.00%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3487 | Train Accuracy: 97.39% Test Accuracy: 98.00%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3320 | Train Accuracy: 97.36% Test Accuracy: 98.17%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3172 | Train Accuracy: 97.54% Test Accuracy: 98.17%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3000 | Train Accuracy: 97.57% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2861 | Train Accuracy: 97.57% Test Accuracy: 98.33%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2739 | Train Accuracy: 97.57% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2607 | Train Accuracy: 97.64% Test Accuracy: 98.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2487 | Train Accuracy: 97.89% Test Accuracy: 98.33%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2409 | Train Accuracy: 97.86% Test Accuracy: 98.33%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2297 | Train Accuracy: 97.86% Test Accuracy: 98.33%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4738 | Train Accuracy: 24.75% Test Accuracy: 44.75%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.0898 | Train Accuracy: 57.93% Test Accuracy: 76.00%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6677 | Train Accuracy: 80.18% Test Accuracy: 90.50%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5018 | Train Accuracy: 95.25% Test Accuracy: 94.75%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4429 | Train Accuracy: 95.79% Test Accuracy: 96.42%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3908 | Train Accuracy: 95.25% Test Accuracy: 97.00%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3150 | Train Accuracy: 96.54% Test Accuracy: 97.17%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2490 | Train Accuracy: 97.36% Test Accuracy: 97.33%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2118 | Train Accuracy: 97.21% Test Accuracy: 97.17%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1948 | Train Accuracy: 97.11% Test Accuracy: 97.17%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1812 | Train Accuracy: 97.11% Test Accuracy: 97.33%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1611 | Train Accuracy: 97.43% Test Accuracy: 97.50%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1419 | Train Accuracy: 97.32% Test Accuracy: 97.58%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1248 | Train Accuracy: 97.36% Test Accuracy: 97.67%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1113 | Train Accuracy: 97.50% Test Accuracy: 97.67%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1027 | Train Accuracy: 97.61% Test Accuracy: 98.17%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.0949 | Train Accuracy: 97.75% Test Accuracy: 98.42%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.0860 | Train Accuracy: 98.04% Test Accuracy: 98.50%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.0861 | Train Accuracy: 97.96% Test Accuracy: 98.50%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.0828 | Train Accuracy: 97.93% Test Accuracy: 98.50%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3523 | Train Accuracy: 31.43% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0776 | Train Accuracy: 71.46% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9406 | Train Accuracy: 84.32% Test Accuracy: 50.25%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8505 | Train Accuracy: 90.75% Test Accuracy: 57.92%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7882 | Train Accuracy: 93.14% Test Accuracy: 80.67%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7444 | Train Accuracy: 94.64% Test Accuracy: 89.75%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7128 | Train Accuracy: 95.18% Test Accuracy: 93.58%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6855 | Train Accuracy: 95.86% Test Accuracy: 95.33%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6605 | Train Accuracy: 96.07% Test Accuracy: 96.17%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6377 | Train Accuracy: 96.50% Test Accuracy: 96.67%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6188 | Train Accuracy: 96.50% Test Accuracy: 96.92%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6072 | Train Accuracy: 96.89% Test Accuracy: 97.17%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5904 | Train Accuracy: 96.57% Test Accuracy: 97.75%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5762 | Train Accuracy: 96.93% Test Accuracy: 97.83%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5674 | Train Accuracy: 96.75% Test Accuracy: 97.92%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5528 | Train Accuracy: 96.89% Test Accuracy: 98.08%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5439 | Train Accuracy: 97.21% Test Accuracy: 98.08%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5361 | Train Accuracy: 97.11% Test Accuracy: 98.17%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5255 | Train Accuracy: 97.11% Test Accuracy: 98.25%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5143 | Train Accuracy: 97.46% Test Accuracy: 98.25%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 1.3420 | Train Accuracy: 36.07% Test Accuracy: 91.33%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2425 | Train Accuracy: 97.00% Test Accuracy: 97.50%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1464 | Train Accuracy: 97.04% Test Accuracy: 97.58%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1244 | Train Accuracy: 97.29% Test Accuracy: 97.75%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1036 | Train Accuracy: 97.57% Test Accuracy: 97.83%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0885 | Train Accuracy: 97.71% Test Accuracy: 98.17%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0814 | Train Accuracy: 98.04% Test Accuracy: 98.17%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0744 | Train Accuracy: 98.11% Test Accuracy: 98.33%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0708 | Train Accuracy: 98.04% Test Accuracy: 98.50%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0659 | Train Accuracy: 98.36% Test Accuracy: 98.58%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0638 | Train Accuracy: 98.29% Test Accuracy: 98.75%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0620 | Train Accuracy: 98.32% Test Accuracy: 98.75%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0586 | Train Accuracy: 98.54% Test Accuracy: 98.83%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0588 | Train Accuracy: 98.68% Test Accuracy: 98.83%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0560 | Train Accuracy: 98.75% Test Accuracy: 98.83%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0536 | Train Accuracy: 98.71% Test Accuracy: 99.08%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0515 | Train Accuracy: 98.82% Test Accuracy: 99.08%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0484 | Train Accuracy: 98.86% Test Accuracy: 99.08%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0477 | Train Accuracy: 98.86% Test Accuracy: 99.08%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0472 | Train Accuracy: 98.82% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 1.5933 | Train Accuracy: 16.36% Test Accuracy: 77.17%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.3052 | Train Accuracy: 90.75% Test Accuracy: 72.50%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.8301 | Train Accuracy: 71.25% Test Accuracy: 97.25%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1440 | Train Accuracy: 97.18% Test Accuracy: 79.00%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2115 | Train Accuracy: 93.11% Test Accuracy: 79.25%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2076 | Train Accuracy: 93.00% Test Accuracy: 90.92%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1535 | Train Accuracy: 96.29% Test Accuracy: 97.42%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1161 | Train Accuracy: 97.36% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1024 | Train Accuracy: 97.50% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1008 | Train Accuracy: 97.54% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0969 | Train Accuracy: 97.54% Test Accuracy: 97.83%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0903 | Train Accuracy: 97.71% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0834 | Train Accuracy: 97.71% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0800 | Train Accuracy: 97.79% Test Accuracy: 98.17%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0720 | Train Accuracy: 98.07% Test Accuracy: 98.33%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0641 | Train Accuracy: 98.04% Test Accuracy: 98.50%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0619 | Train Accuracy: 98.25% Test Accuracy: 98.75%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0568 | Train Accuracy: 98.50% Test Accuracy: 99.08%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0561 | Train Accuracy: 98.54% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0544 | Train Accuracy: 98.54% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.2678 | Train Accuracy: 44.00% Test Accuracy: 95.17%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.5168 | Train Accuracy: 93.25% Test Accuracy: 97.25%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2896 | Train Accuracy: 96.71% Test Accuracy: 97.50%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2029 | Train Accuracy: 97.21% Test Accuracy: 98.00%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1638 | Train Accuracy: 97.39% Test Accuracy: 98.00%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1378 | Train Accuracy: 97.57% Test Accuracy: 97.92%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1224 | Train Accuracy: 97.71% Test Accuracy: 98.00%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1120 | Train Accuracy: 97.75% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1028 | Train Accuracy: 97.96% Test Accuracy: 98.08%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0965 | Train Accuracy: 97.93% Test Accuracy: 98.42%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0894 | Train Accuracy: 98.11% Test Accuracy: 98.50%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0844 | Train Accuracy: 98.21% Test Accuracy: 98.58%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0800 | Train Accuracy: 98.29% Test Accuracy: 98.67%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0779 | Train Accuracy: 98.18% Test Accuracy: 98.92%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0741 | Train Accuracy: 98.32% Test Accuracy: 98.83%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0698 | Train Accuracy: 98.57% Test Accuracy: 98.83%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0677 | Train Accuracy: 98.68% Test Accuracy: 98.92%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0659 | Train Accuracy: 98.71% Test Accuracy: 98.92%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0635 | Train Accuracy: 98.75% Test Accuracy: 98.92%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0618 | Train Accuracy: 98.82% Test Accuracy: 99.00%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.3712 | Train Accuracy: 32.75% Test Accuracy: 75.17%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.4497 | Train Accuracy: 80.68% Test Accuracy: 89.75%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.3211 | Train Accuracy: 88.86% Test Accuracy: 98.00%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1090 | Train Accuracy: 97.50% Test Accuracy: 98.25%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1250 | Train Accuracy: 97.79% Test Accuracy: 99.17%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0686 | Train Accuracy: 98.54% Test Accuracy: 99.17%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0550 | Train Accuracy: 98.71% Test Accuracy: 98.92%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0610 | Train Accuracy: 98.50% Test Accuracy: 99.00%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0509 | Train Accuracy: 98.79% Test Accuracy: 99.17%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0400 | Train Accuracy: 99.07% Test Accuracy: 99.00%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0468 | Train Accuracy: 99.00% Test Accuracy: 99.00%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0437 | Train Accuracy: 99.07% Test Accuracy: 98.92%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0393 | Train Accuracy: 99.04% Test Accuracy: 98.92%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0323 | Train Accuracy: 99.21% Test Accuracy: 99.33%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0318 | Train Accuracy: 99.21% Test Accuracy: 99.42%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0233 | Train Accuracy: 99.39% Test Accuracy: 99.33%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0176 | Train Accuracy: 99.68% Test Accuracy: 99.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0242 | Train Accuracy: 99.64% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0238 | Train Accuracy: 99.68% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0206 | Train Accuracy: 99.61% Test Accuracy: 99.33%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.3830 | Train Accuracy: 26.82% Test Accuracy: 57.75%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 11.5625 | Train Accuracy: 59.04% Test Accuracy: 48.25%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 165.5922 | Train Accuracy: 48.04% Test Accuracy: 49.33%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 20.4682 | Train Accuracy: 49.43% Test Accuracy: 39.00%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.1670 | Train Accuracy: 40.29% Test Accuracy: 77.75%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.1049 | Train Accuracy: 70.64% Test Accuracy: 94.42%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5509 | Train Accuracy: 86.96% Test Accuracy: 94.92%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.6567 | Train Accuracy: 86.07% Test Accuracy: 94.83%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.8132 | Train Accuracy: 84.07% Test Accuracy: 96.00%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.9550 | Train Accuracy: 85.86% Test Accuracy: 96.92%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.6565 | Train Accuracy: 91.43% Test Accuracy: 95.83%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.8487 | Train Accuracy: 90.36% Test Accuracy: 96.83%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5352 | Train Accuracy: 94.11% Test Accuracy: 97.75%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.3091 | Train Accuracy: 96.07% Test Accuracy: 97.17%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2520 | Train Accuracy: 94.82% Test Accuracy: 98.42%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.1924 | Train Accuracy: 96.89% Test Accuracy: 98.00%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2172 | Train Accuracy: 96.82% Test Accuracy: 97.50%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.4356 | Train Accuracy: 94.82% Test Accuracy: 97.42%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2568 | Train Accuracy: 95.93% Test Accuracy: 97.42%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2159 | Train Accuracy: 96.36% Test Accuracy: 98.67%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.4558 | Train Accuracy: 11.00% Test Accuracy: 87.25%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1678 | Train Accuracy: 81.32% Test Accuracy: 96.08%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.9520 | Train Accuracy: 92.79% Test Accuracy: 96.83%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.7764 | Train Accuracy: 95.14% Test Accuracy: 97.17%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.6267 | Train Accuracy: 95.75% Test Accuracy: 97.33%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.5067 | Train Accuracy: 96.50% Test Accuracy: 97.33%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.4074 | Train Accuracy: 96.36% Test Accuracy: 97.42%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3264 | Train Accuracy: 96.75% Test Accuracy: 97.42%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2651 | Train Accuracy: 96.96% Test Accuracy: 97.42%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2212 | Train Accuracy: 97.00% Test Accuracy: 97.50%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1848 | Train Accuracy: 97.00% Test Accuracy: 97.50%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1608 | Train Accuracy: 97.21% Test Accuracy: 97.58%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1393 | Train Accuracy: 97.25% Test Accuracy: 97.75%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1248 | Train Accuracy: 97.21% Test Accuracy: 97.75%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1132 | Train Accuracy: 97.25% Test Accuracy: 97.83%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1029 | Train Accuracy: 97.36% Test Accuracy: 97.83%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0925 | Train Accuracy: 97.36% Test Accuracy: 98.00%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0829 | Train Accuracy: 97.64% Test Accuracy: 98.08%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0784 | Train Accuracy: 97.54% Test Accuracy: 98.17%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0694 | Train Accuracy: 97.89% Test Accuracy: 98.25%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4004 | Train Accuracy: 23.79% Test Accuracy: 91.67%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0902 | Train Accuracy: 74.93% Test Accuracy: 97.08%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9365 | Train Accuracy: 87.11% Test Accuracy: 97.33%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8062 | Train Accuracy: 94.00% Test Accuracy: 97.42%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6917 | Train Accuracy: 96.18% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5951 | Train Accuracy: 96.75% Test Accuracy: 97.58%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5155 | Train Accuracy: 97.11% Test Accuracy: 97.75%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4437 | Train Accuracy: 97.07% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3815 | Train Accuracy: 97.18% Test Accuracy: 97.75%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3304 | Train Accuracy: 97.29% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2846 | Train Accuracy: 97.32% Test Accuracy: 98.00%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2474 | Train Accuracy: 97.29% Test Accuracy: 98.00%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2189 | Train Accuracy: 97.43% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1898 | Train Accuracy: 97.50% Test Accuracy: 98.08%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1676 | Train Accuracy: 97.61% Test Accuracy: 98.08%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1486 | Train Accuracy: 97.75% Test Accuracy: 98.17%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1318 | Train Accuracy: 97.93% Test Accuracy: 98.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1192 | Train Accuracy: 98.00% Test Accuracy: 98.50%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1069 | Train Accuracy: 98.04% Test Accuracy: 98.67%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0980 | Train Accuracy: 98.18% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4218 | Train Accuracy: 24.39% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 2.3770 | Train Accuracy: 25.04% Test Accuracy: 47.42%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.3777 | Train Accuracy: 48.93% Test Accuracy: 73.08%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8809 | Train Accuracy: 71.07% Test Accuracy: 68.58%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7563 | Train Accuracy: 65.00% Test Accuracy: 48.17%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7065 | Train Accuracy: 52.96% Test Accuracy: 76.17%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5746 | Train Accuracy: 74.71% Test Accuracy: 97.58%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4909 | Train Accuracy: 96.96% Test Accuracy: 97.25%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4760 | Train Accuracy: 90.32% Test Accuracy: 97.33%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4250 | Train Accuracy: 93.79% Test Accuracy: 97.58%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3527 | Train Accuracy: 97.21% Test Accuracy: 97.58%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2950 | Train Accuracy: 97.21% Test Accuracy: 97.42%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2621 | Train Accuracy: 97.07% Test Accuracy: 97.33%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2385 | Train Accuracy: 97.04% Test Accuracy: 97.33%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2116 | Train Accuracy: 96.93% Test Accuracy: 97.42%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1802 | Train Accuracy: 97.29% Test Accuracy: 97.50%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1585 | Train Accuracy: 97.21% Test Accuracy: 97.58%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1375 | Train Accuracy: 97.29% Test Accuracy: 97.58%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1236 | Train Accuracy: 97.29% Test Accuracy: 97.58%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1121 | Train Accuracy: 97.29% Test Accuracy: 97.58%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4527 | Train Accuracy: 25.00% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3837 | Train Accuracy: 25.71% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3269 | Train Accuracy: 28.61% Test Accuracy: 25.00%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2730 | Train Accuracy: 35.36% Test Accuracy: 33.58%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2301 | Train Accuracy: 44.36% Test Accuracy: 65.17%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1820 | Train Accuracy: 56.07% Test Accuracy: 83.58%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1435 | Train Accuracy: 65.93% Test Accuracy: 90.83%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1125 | Train Accuracy: 72.04% Test Accuracy: 93.83%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0853 | Train Accuracy: 75.29% Test Accuracy: 95.58%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0602 | Train Accuracy: 78.57% Test Accuracy: 96.58%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0379 | Train Accuracy: 80.39% Test Accuracy: 96.92%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0113 | Train Accuracy: 83.71% Test Accuracy: 97.08%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9897 | Train Accuracy: 83.71% Test Accuracy: 97.17%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9691 | Train Accuracy: 85.39% Test Accuracy: 97.50%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9425 | Train Accuracy: 87.79% Test Accuracy: 97.50%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9282 | Train Accuracy: 88.68% Test Accuracy: 97.58%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9083 | Train Accuracy: 90.36% Test Accuracy: 97.58%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8951 | Train Accuracy: 90.71% Test Accuracy: 97.67%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8760 | Train Accuracy: 92.04% Test Accuracy: 97.67%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8534 | Train Accuracy: 92.43% Test Accuracy: 97.67%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 1.3562 | Train Accuracy: 29.11% Test Accuracy: 97.50%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.4477 | Train Accuracy: 93.89% Test Accuracy: 93.67%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.3232 | Train Accuracy: 92.32% Test Accuracy: 97.17%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1896 | Train Accuracy: 96.61% Test Accuracy: 97.58%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1329 | Train Accuracy: 97.18% Test Accuracy: 97.83%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1086 | Train Accuracy: 97.29% Test Accuracy: 97.67%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0922 | Train Accuracy: 97.50% Test Accuracy: 97.83%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0838 | Train Accuracy: 97.82% Test Accuracy: 98.42%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0738 | Train Accuracy: 98.00% Test Accuracy: 98.50%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0681 | Train Accuracy: 98.54% Test Accuracy: 98.83%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0648 | Train Accuracy: 98.57% Test Accuracy: 98.92%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0604 | Train Accuracy: 98.68% Test Accuracy: 98.92%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0557 | Train Accuracy: 98.82% Test Accuracy: 99.00%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0521 | Train Accuracy: 98.68% Test Accuracy: 99.00%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0482 | Train Accuracy: 98.93% Test Accuracy: 99.00%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0446 | Train Accuracy: 98.79% Test Accuracy: 99.17%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0411 | Train Accuracy: 99.04% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0396 | Train Accuracy: 99.00% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0381 | Train Accuracy: 99.00% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0364 | Train Accuracy: 99.07% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.3011 | Train Accuracy: 52.00% Test Accuracy: 63.08%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.7552 | Train Accuracy: 64.29% Test Accuracy: 47.67%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 2.7580 | Train Accuracy: 47.04% Test Accuracy: 47.75%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.9649 | Train Accuracy: 51.07% Test Accuracy: 97.42%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2584 | Train Accuracy: 96.89% Test Accuracy: 84.92%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.4200 | Train Accuracy: 83.25% Test Accuracy: 79.58%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.4192 | Train Accuracy: 80.04% Test Accuracy: 92.67%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3036 | Train Accuracy: 90.36% Test Accuracy: 96.67%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2099 | Train Accuracy: 96.18% Test Accuracy: 97.17%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1669 | Train Accuracy: 97.07% Test Accuracy: 97.42%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1455 | Train Accuracy: 97.25% Test Accuracy: 97.58%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1438 | Train Accuracy: 97.29% Test Accuracy: 97.58%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1350 | Train Accuracy: 97.32% Test Accuracy: 97.58%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1340 | Train Accuracy: 97.29% Test Accuracy: 97.67%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1247 | Train Accuracy: 97.29% Test Accuracy: 97.75%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1142 | Train Accuracy: 97.21% Test Accuracy: 97.67%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1080 | Train Accuracy: 97.25% Test Accuracy: 97.58%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.0989 | Train Accuracy: 97.32% Test Accuracy: 97.58%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.0939 | Train Accuracy: 97.39% Test Accuracy: 97.75%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.0898 | Train Accuracy: 97.50% Test Accuracy: 98.00%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.3711 | Train Accuracy: 32.00% Test Accuracy: 90.33%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.8102 | Train Accuracy: 88.11% Test Accuracy: 95.83%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.5377 | Train Accuracy: 94.43% Test Accuracy: 97.08%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3929 | Train Accuracy: 95.57% Test Accuracy: 97.33%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3131 | Train Accuracy: 96.21% Test Accuracy: 97.50%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2578 | Train Accuracy: 96.82% Test Accuracy: 97.42%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2196 | Train Accuracy: 97.07% Test Accuracy: 97.50%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1912 | Train Accuracy: 97.11% Test Accuracy: 97.83%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1683 | Train Accuracy: 97.29% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1501 | Train Accuracy: 97.32% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1367 | Train Accuracy: 97.46% Test Accuracy: 97.83%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1249 | Train Accuracy: 97.43% Test Accuracy: 97.83%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1157 | Train Accuracy: 97.61% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1072 | Train Accuracy: 97.50% Test Accuracy: 98.00%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1000 | Train Accuracy: 97.71% Test Accuracy: 98.08%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0940 | Train Accuracy: 97.71% Test Accuracy: 98.25%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0885 | Train Accuracy: 97.79% Test Accuracy: 98.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0847 | Train Accuracy: 97.93% Test Accuracy: 98.42%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0815 | Train Accuracy: 97.96% Test Accuracy: 98.50%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0781 | Train Accuracy: 97.93% Test Accuracy: 98.50%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.5564 | Train Accuracy: 24.96% Test Accuracy: 96.25%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.5040 | Train Accuracy: 92.64% Test Accuracy: 97.50%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.3102 | Train Accuracy: 96.50% Test Accuracy: 97.67%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2146 | Train Accuracy: 97.43% Test Accuracy: 97.67%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1664 | Train Accuracy: 97.71% Test Accuracy: 98.00%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1403 | Train Accuracy: 97.68% Test Accuracy: 98.08%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1230 | Train Accuracy: 97.64% Test Accuracy: 98.08%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1062 | Train Accuracy: 97.86% Test Accuracy: 98.17%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1022 | Train Accuracy: 97.68% Test Accuracy: 98.25%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0855 | Train Accuracy: 97.93% Test Accuracy: 98.50%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0826 | Train Accuracy: 98.21% Test Accuracy: 98.58%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0766 | Train Accuracy: 98.39% Test Accuracy: 98.83%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0687 | Train Accuracy: 98.50% Test Accuracy: 98.83%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0662 | Train Accuracy: 98.54% Test Accuracy: 99.08%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0609 | Train Accuracy: 98.61% Test Accuracy: 99.17%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0567 | Train Accuracy: 98.71% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0576 | Train Accuracy: 98.64% Test Accuracy: 99.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0533 | Train Accuracy: 98.93% Test Accuracy: 99.33%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0518 | Train Accuracy: 98.86% Test Accuracy: 99.42%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0489 | Train Accuracy: 98.96% Test Accuracy: 99.50%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 1.4281 | Train Accuracy: 28.68% Test Accuracy: 62.50%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.6007 | Train Accuracy: 81.93% Test Accuracy: 66.92%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1826 | Train Accuracy: 95.54% Test Accuracy: 93.17%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1155 | Train Accuracy: 97.25% Test Accuracy: 95.42%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0943 | Train Accuracy: 97.46% Test Accuracy: 96.67%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0875 | Train Accuracy: 97.68% Test Accuracy: 97.42%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0704 | Train Accuracy: 98.00% Test Accuracy: 97.58%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0734 | Train Accuracy: 97.93% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0703 | Train Accuracy: 98.18% Test Accuracy: 98.08%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0571 | Train Accuracy: 98.50% Test Accuracy: 98.33%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0557 | Train Accuracy: 98.32% Test Accuracy: 98.67%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0492 | Train Accuracy: 98.39% Test Accuracy: 98.83%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0439 | Train Accuracy: 98.64% Test Accuracy: 99.17%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0519 | Train Accuracy: 98.46% Test Accuracy: 99.33%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0474 | Train Accuracy: 98.39% Test Accuracy: 99.25%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0455 | Train Accuracy: 98.93% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0383 | Train Accuracy: 98.82% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0326 | Train Accuracy: 99.07% Test Accuracy: 99.17%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0393 | Train Accuracy: 98.93% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0318 | Train Accuracy: 99.14% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.5993 | Train Accuracy: 19.93% Test Accuracy: 87.00%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.9886 | Train Accuracy: 66.21% Test Accuracy: 97.00%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.6997 | Train Accuracy: 86.21% Test Accuracy: 97.83%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5368 | Train Accuracy: 93.04% Test Accuracy: 98.00%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4483 | Train Accuracy: 95.39% Test Accuracy: 97.92%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3942 | Train Accuracy: 95.89% Test Accuracy: 97.92%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3532 | Train Accuracy: 96.68% Test Accuracy: 98.00%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3212 | Train Accuracy: 97.18% Test Accuracy: 98.08%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3007 | Train Accuracy: 97.25% Test Accuracy: 98.08%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2733 | Train Accuracy: 97.46% Test Accuracy: 98.08%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2535 | Train Accuracy: 97.71% Test Accuracy: 98.25%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2368 | Train Accuracy: 97.82% Test Accuracy: 98.50%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2258 | Train Accuracy: 98.00% Test Accuracy: 98.58%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2170 | Train Accuracy: 97.75% Test Accuracy: 98.58%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2038 | Train Accuracy: 97.96% Test Accuracy: 98.58%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1930 | Train Accuracy: 98.18% Test Accuracy: 99.00%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1836 | Train Accuracy: 98.07% Test Accuracy: 99.08%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1763 | Train Accuracy: 98.11% Test Accuracy: 99.08%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1703 | Train Accuracy: 98.29% Test Accuracy: 99.08%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1630 | Train Accuracy: 98.29% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4318 | Train Accuracy: 26.36% Test Accuracy: 97.17%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9878 | Train Accuracy: 75.36% Test Accuracy: 97.25%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8659 | Train Accuracy: 85.82% Test Accuracy: 96.50%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7710 | Train Accuracy: 88.39% Test Accuracy: 97.00%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6856 | Train Accuracy: 92.00% Test Accuracy: 97.50%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6323 | Train Accuracy: 93.43% Test Accuracy: 97.83%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5668 | Train Accuracy: 94.71% Test Accuracy: 97.92%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5319 | Train Accuracy: 95.68% Test Accuracy: 98.25%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4901 | Train Accuracy: 96.36% Test Accuracy: 98.25%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4512 | Train Accuracy: 96.36% Test Accuracy: 98.42%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4277 | Train Accuracy: 96.71% Test Accuracy: 98.50%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4051 | Train Accuracy: 96.75% Test Accuracy: 98.50%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3816 | Train Accuracy: 97.04% Test Accuracy: 98.42%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3660 | Train Accuracy: 96.68% Test Accuracy: 98.50%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3438 | Train Accuracy: 97.18% Test Accuracy: 98.50%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3287 | Train Accuracy: 97.00% Test Accuracy: 98.50%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3187 | Train Accuracy: 97.36% Test Accuracy: 98.50%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3001 | Train Accuracy: 97.21% Test Accuracy: 98.50%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2831 | Train Accuracy: 97.46% Test Accuracy: 98.50%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2771 | Train Accuracy: 97.64% Test Accuracy: 98.58%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4507 | Train Accuracy: 24.86% Test Accuracy: 48.33%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4086 | Train Accuracy: 45.14% Test Accuracy: 82.58%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7474 | Train Accuracy: 81.89% Test Accuracy: 53.00%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7186 | Train Accuracy: 67.57% Test Accuracy: 59.50%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6480 | Train Accuracy: 71.93% Test Accuracy: 97.25%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4924 | Train Accuracy: 90.21% Test Accuracy: 97.67%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4039 | Train Accuracy: 95.36% Test Accuracy: 96.92%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3885 | Train Accuracy: 92.68% Test Accuracy: 97.00%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3716 | Train Accuracy: 91.00% Test Accuracy: 97.50%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3161 | Train Accuracy: 93.68% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2572 | Train Accuracy: 95.89% Test Accuracy: 98.25%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2291 | Train Accuracy: 96.46% Test Accuracy: 98.08%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2013 | Train Accuracy: 97.00% Test Accuracy: 98.17%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1992 | Train Accuracy: 96.79% Test Accuracy: 98.17%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1873 | Train Accuracy: 97.18% Test Accuracy: 98.17%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1712 | Train Accuracy: 96.96% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1545 | Train Accuracy: 97.46% Test Accuracy: 98.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1393 | Train Accuracy: 97.61% Test Accuracy: 98.42%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1244 | Train Accuracy: 97.93% Test Accuracy: 98.50%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1172 | Train Accuracy: 97.68% Test Accuracy: 98.50%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4410 | Train Accuracy: 27.68% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2758 | Train Accuracy: 42.89% Test Accuracy: 48.50%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1635 | Train Accuracy: 54.29% Test Accuracy: 50.00%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0831 | Train Accuracy: 62.46% Test Accuracy: 59.17%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0352 | Train Accuracy: 66.14% Test Accuracy: 74.92%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9934 | Train Accuracy: 70.00% Test Accuracy: 74.83%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9688 | Train Accuracy: 73.14% Test Accuracy: 77.42%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9428 | Train Accuracy: 75.68% Test Accuracy: 84.00%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9204 | Train Accuracy: 78.64% Test Accuracy: 90.75%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8965 | Train Accuracy: 81.00% Test Accuracy: 93.83%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8659 | Train Accuracy: 85.07% Test Accuracy: 95.50%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8584 | Train Accuracy: 85.61% Test Accuracy: 96.67%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8475 | Train Accuracy: 85.96% Test Accuracy: 96.92%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8233 | Train Accuracy: 87.29% Test Accuracy: 96.92%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8143 | Train Accuracy: 88.96% Test Accuracy: 97.00%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7967 | Train Accuracy: 89.32% Test Accuracy: 97.00%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7923 | Train Accuracy: 89.68% Test Accuracy: 97.08%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7759 | Train Accuracy: 90.71% Test Accuracy: 97.42%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7587 | Train Accuracy: 91.71% Test Accuracy: 97.50%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7556 | Train Accuracy: 92.00% Test Accuracy: 97.58%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 1.5781 | Train Accuracy: 18.46% Test Accuracy: 90.42%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.3438 | Train Accuracy: 92.21% Test Accuracy: 97.67%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2327 | Train Accuracy: 96.96% Test Accuracy: 97.92%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1852 | Train Accuracy: 97.54% Test Accuracy: 98.00%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1425 | Train Accuracy: 97.71% Test Accuracy: 97.92%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1235 | Train Accuracy: 97.54% Test Accuracy: 98.00%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1136 | Train Accuracy: 97.32% Test Accuracy: 98.25%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1009 | Train Accuracy: 97.64% Test Accuracy: 98.50%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0921 | Train Accuracy: 97.54% Test Accuracy: 98.50%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0832 | Train Accuracy: 97.86% Test Accuracy: 98.50%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0787 | Train Accuracy: 98.07% Test Accuracy: 98.42%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0748 | Train Accuracy: 98.04% Test Accuracy: 98.58%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0676 | Train Accuracy: 98.14% Test Accuracy: 98.67%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0660 | Train Accuracy: 98.14% Test Accuracy: 98.75%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0654 | Train Accuracy: 98.43% Test Accuracy: 98.75%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0622 | Train Accuracy: 98.36% Test Accuracy: 99.00%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0596 | Train Accuracy: 98.29% Test Accuracy: 99.00%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0577 | Train Accuracy: 98.57% Test Accuracy: 99.08%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0560 | Train Accuracy: 98.82% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0531 | Train Accuracy: 98.68% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 1.3805 | Train Accuracy: 32.00% Test Accuracy: 77.75%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.4737 | Train Accuracy: 84.93% Test Accuracy: 73.42%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.7540 | Train Accuracy: 75.32% Test Accuracy: 85.17%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1951 | Train Accuracy: 94.43% Test Accuracy: 97.50%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1735 | Train Accuracy: 96.64% Test Accuracy: 96.67%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1977 | Train Accuracy: 95.64% Test Accuracy: 97.75%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1707 | Train Accuracy: 96.46% Test Accuracy: 97.83%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1281 | Train Accuracy: 97.14% Test Accuracy: 98.08%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0943 | Train Accuracy: 97.64% Test Accuracy: 98.33%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0803 | Train Accuracy: 97.86% Test Accuracy: 98.50%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0769 | Train Accuracy: 97.79% Test Accuracy: 98.67%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0746 | Train Accuracy: 97.89% Test Accuracy: 98.83%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0753 | Train Accuracy: 97.82% Test Accuracy: 98.92%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0732 | Train Accuracy: 97.89% Test Accuracy: 98.92%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0722 | Train Accuracy: 98.00% Test Accuracy: 99.00%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0725 | Train Accuracy: 98.07% Test Accuracy: 99.08%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0612 | Train Accuracy: 98.68% Test Accuracy: 99.08%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0635 | Train Accuracy: 98.25% Test Accuracy: 98.92%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0607 | Train Accuracy: 98.18% Test Accuracy: 98.75%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0552 | Train Accuracy: 98.43% Test Accuracy: 98.83%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.5324 | Train Accuracy: 21.75% Test Accuracy: 94.58%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.7108 | Train Accuracy: 79.68% Test Accuracy: 96.17%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.4421 | Train Accuracy: 91.86% Test Accuracy: 97.00%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3219 | Train Accuracy: 95.04% Test Accuracy: 97.17%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2537 | Train Accuracy: 96.11% Test Accuracy: 97.83%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2142 | Train Accuracy: 96.93% Test Accuracy: 97.83%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1915 | Train Accuracy: 96.93% Test Accuracy: 98.00%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1689 | Train Accuracy: 97.50% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1505 | Train Accuracy: 97.50% Test Accuracy: 98.17%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1408 | Train Accuracy: 97.64% Test Accuracy: 98.25%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1285 | Train Accuracy: 97.54% Test Accuracy: 98.33%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1225 | Train Accuracy: 97.68% Test Accuracy: 98.50%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1148 | Train Accuracy: 97.71% Test Accuracy: 98.58%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1097 | Train Accuracy: 97.86% Test Accuracy: 98.58%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1042 | Train Accuracy: 97.96% Test Accuracy: 98.42%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0994 | Train Accuracy: 98.07% Test Accuracy: 98.50%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0955 | Train Accuracy: 98.04% Test Accuracy: 98.58%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0907 | Train Accuracy: 98.36% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0886 | Train Accuracy: 98.29% Test Accuracy: 98.58%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0865 | Train Accuracy: 98.21% Test Accuracy: 98.67%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.4114 | Train Accuracy: 23.96% Test Accuracy: 67.00%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.6009 | Train Accuracy: 71.36% Test Accuracy: 84.58%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.5465 | Train Accuracy: 82.68% Test Accuracy: 97.58%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1294 | Train Accuracy: 96.46% Test Accuracy: 98.33%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1298 | Train Accuracy: 96.71% Test Accuracy: 98.92%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1336 | Train Accuracy: 96.36% Test Accuracy: 99.08%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0909 | Train Accuracy: 97.86% Test Accuracy: 99.08%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0629 | Train Accuracy: 98.57% Test Accuracy: 99.08%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0698 | Train Accuracy: 98.43% Test Accuracy: 99.08%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0490 | Train Accuracy: 98.89% Test Accuracy: 99.08%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0641 | Train Accuracy: 98.57% Test Accuracy: 99.08%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0582 | Train Accuracy: 98.71% Test Accuracy: 99.08%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0525 | Train Accuracy: 98.93% Test Accuracy: 99.08%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0490 | Train Accuracy: 98.93% Test Accuracy: 99.08%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0533 | Train Accuracy: 98.79% Test Accuracy: 99.08%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0464 | Train Accuracy: 98.96% Test Accuracy: 99.08%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0505 | Train Accuracy: 98.82% Test Accuracy: 99.08%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0387 | Train Accuracy: 99.29% Test Accuracy: 99.08%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0305 | Train Accuracy: 99.25% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0272 | Train Accuracy: 99.29% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.3835 | Train Accuracy: 27.61% Test Accuracy: 63.42%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 10.5485 | Train Accuracy: 62.11% Test Accuracy: 48.33%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 154.3324 | Train Accuracy: 48.11% Test Accuracy: 49.33%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 14.1905 | Train Accuracy: 49.93% Test Accuracy: 92.25%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.7725 | Train Accuracy: 80.86% Test Accuracy: 54.08%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.2273 | Train Accuracy: 57.93% Test Accuracy: 52.17%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.8199 | Train Accuracy: 62.11% Test Accuracy: 96.17%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.6505 | Train Accuracy: 74.86% Test Accuracy: 96.92%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.7882 | Train Accuracy: 72.79% Test Accuracy: 96.50%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.6622 | Train Accuracy: 75.07% Test Accuracy: 97.00%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5403 | Train Accuracy: 79.11% Test Accuracy: 97.08%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5182 | Train Accuracy: 79.68% Test Accuracy: 97.50%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5628 | Train Accuracy: 79.89% Test Accuracy: 97.58%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5023 | Train Accuracy: 80.43% Test Accuracy: 97.42%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.4816 | Train Accuracy: 90.14% Test Accuracy: 97.42%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.4434 | Train Accuracy: 89.64% Test Accuracy: 97.25%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.4450 | Train Accuracy: 89.79% Test Accuracy: 97.00%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5034 | Train Accuracy: 87.18% Test Accuracy: 96.92%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.4842 | Train Accuracy: 87.46% Test Accuracy: 97.00%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.4661 | Train Accuracy: 87.93% Test Accuracy: 97.25%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.4340 | Train Accuracy: 22.82% Test Accuracy: 92.75%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1345 | Train Accuracy: 66.79% Test Accuracy: 95.25%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.9116 | Train Accuracy: 83.50% Test Accuracy: 96.17%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.7366 | Train Accuracy: 88.43% Test Accuracy: 96.42%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.6082 | Train Accuracy: 91.57% Test Accuracy: 96.92%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.5002 | Train Accuracy: 92.61% Test Accuracy: 97.17%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.4184 | Train Accuracy: 94.21% Test Accuracy: 97.25%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3571 | Train Accuracy: 95.36% Test Accuracy: 97.42%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2973 | Train Accuracy: 95.61% Test Accuracy: 97.42%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2528 | Train Accuracy: 96.11% Test Accuracy: 97.58%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2215 | Train Accuracy: 96.57% Test Accuracy: 97.67%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1915 | Train Accuracy: 96.57% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1732 | Train Accuracy: 96.89% Test Accuracy: 97.83%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1560 | Train Accuracy: 97.04% Test Accuracy: 97.83%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1335 | Train Accuracy: 97.11% Test Accuracy: 97.92%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1280 | Train Accuracy: 97.36% Test Accuracy: 98.08%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1089 | Train Accuracy: 97.36% Test Accuracy: 98.17%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1020 | Train Accuracy: 97.64% Test Accuracy: 98.25%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0920 | Train Accuracy: 97.75% Test Accuracy: 98.33%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0893 | Train Accuracy: 97.68% Test Accuracy: 98.50%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4166 | Train Accuracy: 25.68% Test Accuracy: 60.92%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1115 | Train Accuracy: 58.07% Test Accuracy: 97.17%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9610 | Train Accuracy: 71.50% Test Accuracy: 97.42%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8429 | Train Accuracy: 80.32% Test Accuracy: 97.17%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7278 | Train Accuracy: 86.89% Test Accuracy: 97.42%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6312 | Train Accuracy: 91.75% Test Accuracy: 97.58%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5514 | Train Accuracy: 94.50% Test Accuracy: 97.67%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4868 | Train Accuracy: 95.50% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4298 | Train Accuracy: 96.32% Test Accuracy: 97.75%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3785 | Train Accuracy: 96.96% Test Accuracy: 97.75%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3289 | Train Accuracy: 97.21% Test Accuracy: 97.75%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2874 | Train Accuracy: 97.32% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2554 | Train Accuracy: 97.36% Test Accuracy: 97.92%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2257 | Train Accuracy: 97.43% Test Accuracy: 98.00%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2010 | Train Accuracy: 97.54% Test Accuracy: 98.00%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1789 | Train Accuracy: 97.61% Test Accuracy: 98.08%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1585 | Train Accuracy: 97.89% Test Accuracy: 98.25%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1455 | Train Accuracy: 97.79% Test Accuracy: 98.50%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1269 | Train Accuracy: 98.04% Test Accuracy: 98.83%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1123 | Train Accuracy: 98.32% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4569 | Train Accuracy: 23.64% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 2.7941 | Train Accuracy: 25.32% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.5583 | Train Accuracy: 25.04% Test Accuracy: 68.00%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7962 | Train Accuracy: 71.14% Test Accuracy: 79.50%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7335 | Train Accuracy: 75.07% Test Accuracy: 78.25%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7483 | Train Accuracy: 75.68% Test Accuracy: 96.83%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6964 | Train Accuracy: 88.89% Test Accuracy: 97.17%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6291 | Train Accuracy: 93.39% Test Accuracy: 97.25%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5535 | Train Accuracy: 94.04% Test Accuracy: 97.50%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4597 | Train Accuracy: 96.00% Test Accuracy: 97.50%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3686 | Train Accuracy: 96.96% Test Accuracy: 97.42%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2921 | Train Accuracy: 97.04% Test Accuracy: 97.25%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2433 | Train Accuracy: 97.14% Test Accuracy: 97.33%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2014 | Train Accuracy: 97.07% Test Accuracy: 97.33%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1780 | Train Accuracy: 97.11% Test Accuracy: 97.33%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1512 | Train Accuracy: 97.11% Test Accuracy: 97.33%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1384 | Train Accuracy: 97.18% Test Accuracy: 97.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1257 | Train Accuracy: 97.14% Test Accuracy: 97.33%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1182 | Train Accuracy: 97.14% Test Accuracy: 97.33%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1117 | Train Accuracy: 97.14% Test Accuracy: 97.42%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4677 | Train Accuracy: 24.93% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4141 | Train Accuracy: 28.86% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3578 | Train Accuracy: 32.93% Test Accuracy: 40.33%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3098 | Train Accuracy: 36.68% Test Accuracy: 49.17%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2505 | Train Accuracy: 44.89% Test Accuracy: 54.58%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2254 | Train Accuracy: 47.54% Test Accuracy: 63.33%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1809 | Train Accuracy: 51.89% Test Accuracy: 68.17%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1568 | Train Accuracy: 55.86% Test Accuracy: 72.25%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1266 | Train Accuracy: 57.89% Test Accuracy: 77.42%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0915 | Train Accuracy: 61.64% Test Accuracy: 81.08%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0730 | Train Accuracy: 63.57% Test Accuracy: 84.92%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0517 | Train Accuracy: 66.00% Test Accuracy: 89.58%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0291 | Train Accuracy: 68.18% Test Accuracy: 92.67%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0052 | Train Accuracy: 69.71% Test Accuracy: 94.67%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9891 | Train Accuracy: 72.32% Test Accuracy: 96.08%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9721 | Train Accuracy: 73.46% Test Accuracy: 96.83%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9517 | Train Accuracy: 75.04% Test Accuracy: 97.17%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9338 | Train Accuracy: 77.18% Test Accuracy: 97.17%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9128 | Train Accuracy: 78.71% Test Accuracy: 97.17%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8901 | Train Accuracy: 81.18% Test Accuracy: 97.42%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 1.3245 | Train Accuracy: 40.79% Test Accuracy: 97.08%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.4837 | Train Accuracy: 85.36% Test Accuracy: 94.75%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.3391 | Train Accuracy: 91.82% Test Accuracy: 97.08%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.2199 | Train Accuracy: 96.04% Test Accuracy: 97.67%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1512 | Train Accuracy: 97.25% Test Accuracy: 98.00%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1213 | Train Accuracy: 97.50% Test Accuracy: 98.00%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1065 | Train Accuracy: 97.46% Test Accuracy: 98.17%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0957 | Train Accuracy: 97.68% Test Accuracy: 98.17%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0870 | Train Accuracy: 97.75% Test Accuracy: 98.33%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0775 | Train Accuracy: 97.86% Test Accuracy: 98.83%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0713 | Train Accuracy: 98.04% Test Accuracy: 99.00%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0642 | Train Accuracy: 98.25% Test Accuracy: 99.17%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0604 | Train Accuracy: 98.32% Test Accuracy: 99.17%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0609 | Train Accuracy: 97.96% Test Accuracy: 99.17%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0585 | Train Accuracy: 98.29% Test Accuracy: 99.17%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0487 | Train Accuracy: 98.61% Test Accuracy: 99.17%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0484 | Train Accuracy: 98.50% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0473 | Train Accuracy: 98.64% Test Accuracy: 99.17%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0491 | Train Accuracy: 98.57% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0404 | Train Accuracy: 98.96% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.4523 | Train Accuracy: 19.71% Test Accuracy: 79.92%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.6764 | Train Accuracy: 69.75% Test Accuracy: 52.00%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 2.5925 | Train Accuracy: 46.54% Test Accuracy: 72.17%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.6128 | Train Accuracy: 70.96% Test Accuracy: 76.25%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.5736 | Train Accuracy: 75.57% Test Accuracy: 73.67%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.6687 | Train Accuracy: 73.18% Test Accuracy: 88.67%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3769 | Train Accuracy: 86.00% Test Accuracy: 97.50%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3025 | Train Accuracy: 94.39% Test Accuracy: 97.50%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2936 | Train Accuracy: 90.86% Test Accuracy: 97.75%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2309 | Train Accuracy: 95.50% Test Accuracy: 97.92%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1867 | Train Accuracy: 97.11% Test Accuracy: 98.08%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1688 | Train Accuracy: 96.96% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1587 | Train Accuracy: 96.79% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1466 | Train Accuracy: 96.96% Test Accuracy: 98.08%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1178 | Train Accuracy: 97.43% Test Accuracy: 98.08%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1017 | Train Accuracy: 97.75% Test Accuracy: 98.42%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.0784 | Train Accuracy: 98.36% Test Accuracy: 98.42%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.0839 | Train Accuracy: 98.00% Test Accuracy: 98.42%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.0707 | Train Accuracy: 98.14% Test Accuracy: 98.75%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.0692 | Train Accuracy: 98.14% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.4596 | Train Accuracy: 18.61% Test Accuracy: 92.25%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.9156 | Train Accuracy: 78.50% Test Accuracy: 95.42%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.6478 | Train Accuracy: 89.79% Test Accuracy: 96.92%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.5205 | Train Accuracy: 92.75% Test Accuracy: 97.00%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.4193 | Train Accuracy: 94.93% Test Accuracy: 97.17%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3631 | Train Accuracy: 95.50% Test Accuracy: 97.17%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3117 | Train Accuracy: 96.21% Test Accuracy: 97.50%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2724 | Train Accuracy: 96.57% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2471 | Train Accuracy: 96.50% Test Accuracy: 97.67%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2168 | Train Accuracy: 96.50% Test Accuracy: 97.75%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1966 | Train Accuracy: 96.96% Test Accuracy: 97.83%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1754 | Train Accuracy: 97.18% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1622 | Train Accuracy: 97.11% Test Accuracy: 97.75%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1515 | Train Accuracy: 97.39% Test Accuracy: 97.83%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1360 | Train Accuracy: 97.54% Test Accuracy: 97.92%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1286 | Train Accuracy: 97.50% Test Accuracy: 98.00%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1190 | Train Accuracy: 97.79% Test Accuracy: 98.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1146 | Train Accuracy: 97.64% Test Accuracy: 98.42%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1073 | Train Accuracy: 97.86% Test Accuracy: 98.42%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1025 | Train Accuracy: 97.71% Test Accuracy: 98.50%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.6850 | Train Accuracy: 24.29% Test Accuracy: 96.67%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.9311 | Train Accuracy: 64.46% Test Accuracy: 97.08%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.6950 | Train Accuracy: 78.04% Test Accuracy: 97.50%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.5471 | Train Accuracy: 86.57% Test Accuracy: 97.75%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.4534 | Train Accuracy: 90.71% Test Accuracy: 97.83%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.3687 | Train Accuracy: 93.18% Test Accuracy: 97.92%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.3260 | Train Accuracy: 94.54% Test Accuracy: 97.83%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2789 | Train Accuracy: 95.86% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2466 | Train Accuracy: 96.25% Test Accuracy: 98.00%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2209 | Train Accuracy: 96.89% Test Accuracy: 98.08%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1969 | Train Accuracy: 97.00% Test Accuracy: 98.25%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1819 | Train Accuracy: 97.11% Test Accuracy: 98.33%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1666 | Train Accuracy: 97.29% Test Accuracy: 98.33%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1532 | Train Accuracy: 97.68% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1396 | Train Accuracy: 97.71% Test Accuracy: 98.58%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1352 | Train Accuracy: 97.68% Test Accuracy: 98.67%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1284 | Train Accuracy: 97.82% Test Accuracy: 98.67%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1172 | Train Accuracy: 98.00% Test Accuracy: 98.75%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1113 | Train Accuracy: 98.00% Test Accuracy: 98.92%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1013 | Train Accuracy: 98.11% Test Accuracy: 98.92%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 1.6595 | Train Accuracy: 25.07% Test Accuracy: 72.83%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.9567 | Train Accuracy: 59.64% Test Accuracy: 95.25%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.3835 | Train Accuracy: 90.21% Test Accuracy: 96.17%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.2478 | Train Accuracy: 95.00% Test Accuracy: 97.33%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1970 | Train Accuracy: 95.82% Test Accuracy: 97.50%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1583 | Train Accuracy: 96.54% Test Accuracy: 97.58%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1399 | Train Accuracy: 97.18% Test Accuracy: 97.58%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1286 | Train Accuracy: 97.21% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1168 | Train Accuracy: 97.11% Test Accuracy: 97.75%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1038 | Train Accuracy: 97.57% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1044 | Train Accuracy: 97.50% Test Accuracy: 98.00%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1061 | Train Accuracy: 97.39% Test Accuracy: 98.08%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1005 | Train Accuracy: 97.43% Test Accuracy: 98.17%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0861 | Train Accuracy: 97.61% Test Accuracy: 98.67%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0801 | Train Accuracy: 98.00% Test Accuracy: 98.67%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0819 | Train Accuracy: 97.54% Test Accuracy: 98.92%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0668 | Train Accuracy: 97.96% Test Accuracy: 98.75%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0736 | Train Accuracy: 98.18% Test Accuracy: 98.92%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0714 | Train Accuracy: 98.18% Test Accuracy: 99.08%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0640 | Train Accuracy: 98.04% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.6851 | Train Accuracy: 23.68% Test Accuracy: 97.33%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.3100 | Train Accuracy: 41.43% Test Accuracy: 97.58%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.0827 | Train Accuracy: 54.07% Test Accuracy: 97.58%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.9389 | Train Accuracy: 63.32% Test Accuracy: 97.58%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.8487 | Train Accuracy: 69.43% Test Accuracy: 97.67%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.7840 | Train Accuracy: 73.11% Test Accuracy: 97.83%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.7549 | Train Accuracy: 74.14% Test Accuracy: 97.75%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.7057 | Train Accuracy: 77.32% Test Accuracy: 97.83%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.6552 | Train Accuracy: 80.96% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.6361 | Train Accuracy: 81.39% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5930 | Train Accuracy: 84.00% Test Accuracy: 97.92%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5835 | Train Accuracy: 84.11% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5621 | Train Accuracy: 84.64% Test Accuracy: 97.92%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5206 | Train Accuracy: 87.61% Test Accuracy: 98.00%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5119 | Train Accuracy: 87.96% Test Accuracy: 98.00%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4997 | Train Accuracy: 89.39% Test Accuracy: 98.17%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4645 | Train Accuracy: 90.04% Test Accuracy: 98.25%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4629 | Train Accuracy: 89.93% Test Accuracy: 98.42%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4457 | Train Accuracy: 91.07% Test Accuracy: 98.33%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4209 | Train Accuracy: 91.96% Test Accuracy: 98.33%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.5692 | Train Accuracy: 24.39% Test Accuracy: 70.58%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2660 | Train Accuracy: 41.11% Test Accuracy: 95.75%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2063 | Train Accuracy: 45.32% Test Accuracy: 95.83%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1257 | Train Accuracy: 51.57% Test Accuracy: 94.58%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0534 | Train Accuracy: 56.21% Test Accuracy: 94.33%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0151 | Train Accuracy: 60.18% Test Accuracy: 95.25%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9611 | Train Accuracy: 62.93% Test Accuracy: 96.00%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9080 | Train Accuracy: 66.39% Test Accuracy: 96.50%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8755 | Train Accuracy: 70.71% Test Accuracy: 96.75%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8311 | Train Accuracy: 73.00% Test Accuracy: 97.25%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7868 | Train Accuracy: 75.89% Test Accuracy: 97.75%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7556 | Train Accuracy: 76.75% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7449 | Train Accuracy: 77.25% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7066 | Train Accuracy: 80.43% Test Accuracy: 98.00%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6841 | Train Accuracy: 80.86% Test Accuracy: 98.08%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6626 | Train Accuracy: 81.86% Test Accuracy: 98.08%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6400 | Train Accuracy: 82.46% Test Accuracy: 98.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6260 | Train Accuracy: 83.07% Test Accuracy: 98.42%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6042 | Train Accuracy: 84.39% Test Accuracy: 98.42%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5766 | Train Accuracy: 85.71% Test Accuracy: 98.42%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.5442 | Train Accuracy: 24.96% Test Accuracy: 47.50%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4961 | Train Accuracy: 32.61% Test Accuracy: 86.92%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9970 | Train Accuracy: 59.00% Test Accuracy: 58.42%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9476 | Train Accuracy: 60.57% Test Accuracy: 80.67%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8668 | Train Accuracy: 66.54% Test Accuracy: 96.83%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7644 | Train Accuracy: 71.79% Test Accuracy: 97.67%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6748 | Train Accuracy: 77.57% Test Accuracy: 97.58%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6251 | Train Accuracy: 79.21% Test Accuracy: 97.42%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5867 | Train Accuracy: 80.82% Test Accuracy: 97.42%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5472 | Train Accuracy: 83.79% Test Accuracy: 97.58%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4925 | Train Accuracy: 85.61% Test Accuracy: 97.25%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4485 | Train Accuracy: 88.25% Test Accuracy: 97.17%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4308 | Train Accuracy: 86.64% Test Accuracy: 97.33%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4052 | Train Accuracy: 87.79% Test Accuracy: 97.42%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3775 | Train Accuracy: 88.54% Test Accuracy: 97.58%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3501 | Train Accuracy: 89.89% Test Accuracy: 97.83%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3351 | Train Accuracy: 90.04% Test Accuracy: 97.92%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3145 | Train Accuracy: 90.75% Test Accuracy: 98.00%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3000 | Train Accuracy: 91.07% Test Accuracy: 98.08%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2903 | Train Accuracy: 91.57% Test Accuracy: 98.17%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5666 | Train Accuracy: 23.39% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4488 | Train Accuracy: 30.00% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3772 | Train Accuracy: 34.00% Test Accuracy: 26.17%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3384 | Train Accuracy: 37.32% Test Accuracy: 60.50%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3016 | Train Accuracy: 38.54% Test Accuracy: 75.58%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2754 | Train Accuracy: 40.50% Test Accuracy: 85.00%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2484 | Train Accuracy: 43.18% Test Accuracy: 89.50%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2267 | Train Accuracy: 44.39% Test Accuracy: 92.75%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2026 | Train Accuracy: 45.68% Test Accuracy: 94.25%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2014 | Train Accuracy: 45.11% Test Accuracy: 95.33%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1683 | Train Accuracy: 49.00% Test Accuracy: 95.75%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1585 | Train Accuracy: 49.54% Test Accuracy: 96.17%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1666 | Train Accuracy: 48.57% Test Accuracy: 96.25%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1605 | Train Accuracy: 48.29% Test Accuracy: 96.33%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1231 | Train Accuracy: 52.93% Test Accuracy: 96.33%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1345 | Train Accuracy: 50.96% Test Accuracy: 96.67%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1256 | Train Accuracy: 50.75% Test Accuracy: 96.83%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1113 | Train Accuracy: 52.46% Test Accuracy: 96.92%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1119 | Train Accuracy: 52.93% Test Accuracy: 97.00%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0845 | Train Accuracy: 53.89% Test Accuracy: 97.00%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 1.5886 | Train Accuracy: 25.57% Test Accuracy: 93.33%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.6058 | Train Accuracy: 80.14% Test Accuracy: 97.42%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.4395 | Train Accuracy: 89.07% Test Accuracy: 97.58%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.3423 | Train Accuracy: 93.04% Test Accuracy: 97.50%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2767 | Train Accuracy: 94.71% Test Accuracy: 97.67%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2185 | Train Accuracy: 95.75% Test Accuracy: 97.58%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1924 | Train Accuracy: 96.21% Test Accuracy: 97.58%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1593 | Train Accuracy: 96.86% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1461 | Train Accuracy: 97.29% Test Accuracy: 97.75%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1326 | Train Accuracy: 97.32% Test Accuracy: 98.00%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1191 | Train Accuracy: 97.32% Test Accuracy: 98.17%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1090 | Train Accuracy: 97.54% Test Accuracy: 98.33%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1028 | Train Accuracy: 97.71% Test Accuracy: 98.33%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0945 | Train Accuracy: 97.43% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0906 | Train Accuracy: 97.89% Test Accuracy: 98.33%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0854 | Train Accuracy: 97.89% Test Accuracy: 98.42%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0911 | Train Accuracy: 97.75% Test Accuracy: 98.42%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0869 | Train Accuracy: 97.89% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0824 | Train Accuracy: 98.00% Test Accuracy: 98.75%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0756 | Train Accuracy: 98.25% Test Accuracy: 98.83%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 1.5655 | Train Accuracy: 27.04% Test Accuracy: 94.92%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.7919 | Train Accuracy: 68.68% Test Accuracy: 86.00%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.3708 | Train Accuracy: 87.04% Test Accuracy: 97.08%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2860 | Train Accuracy: 91.54% Test Accuracy: 97.58%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2312 | Train Accuracy: 94.21% Test Accuracy: 97.50%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1811 | Train Accuracy: 95.54% Test Accuracy: 97.50%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1449 | Train Accuracy: 96.04% Test Accuracy: 97.58%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1419 | Train Accuracy: 96.75% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1354 | Train Accuracy: 97.07% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1233 | Train Accuracy: 96.96% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1138 | Train Accuracy: 97.00% Test Accuracy: 97.83%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1069 | Train Accuracy: 97.29% Test Accuracy: 98.00%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0962 | Train Accuracy: 97.21% Test Accuracy: 98.08%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1010 | Train Accuracy: 97.32% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0934 | Train Accuracy: 97.68% Test Accuracy: 98.33%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1004 | Train Accuracy: 97.43% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0853 | Train Accuracy: 98.00% Test Accuracy: 98.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0823 | Train Accuracy: 97.86% Test Accuracy: 98.50%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0883 | Train Accuracy: 97.82% Test Accuracy: 98.50%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0846 | Train Accuracy: 97.86% Test Accuracy: 98.50%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.5832 | Train Accuracy: 26.50% Test Accuracy: 91.92%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.0281 | Train Accuracy: 56.93% Test Accuracy: 96.00%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.7672 | Train Accuracy: 71.54% Test Accuracy: 97.08%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.6231 | Train Accuracy: 79.04% Test Accuracy: 97.50%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.5034 | Train Accuracy: 86.43% Test Accuracy: 97.67%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.4463 | Train Accuracy: 88.64% Test Accuracy: 97.75%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.4098 | Train Accuracy: 90.82% Test Accuracy: 97.75%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3769 | Train Accuracy: 92.32% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3378 | Train Accuracy: 93.96% Test Accuracy: 97.75%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3046 | Train Accuracy: 94.82% Test Accuracy: 97.75%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3001 | Train Accuracy: 95.14% Test Accuracy: 97.83%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2716 | Train Accuracy: 95.50% Test Accuracy: 98.00%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2686 | Train Accuracy: 95.61% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2511 | Train Accuracy: 96.04% Test Accuracy: 98.08%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2452 | Train Accuracy: 95.89% Test Accuracy: 98.17%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2255 | Train Accuracy: 96.75% Test Accuracy: 98.17%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2132 | Train Accuracy: 96.82% Test Accuracy: 98.08%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2072 | Train Accuracy: 97.07% Test Accuracy: 98.08%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1934 | Train Accuracy: 97.07% Test Accuracy: 98.25%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1982 | Train Accuracy: 96.82% Test Accuracy: 98.33%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.4383 | Train Accuracy: 25.46% Test Accuracy: 88.67%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.9476 | Train Accuracy: 61.89% Test Accuracy: 96.67%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.6637 | Train Accuracy: 77.46% Test Accuracy: 97.75%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.4171 | Train Accuracy: 86.61% Test Accuracy: 97.83%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.2712 | Train Accuracy: 91.86% Test Accuracy: 98.08%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1966 | Train Accuracy: 94.54% Test Accuracy: 98.17%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1702 | Train Accuracy: 96.21% Test Accuracy: 98.58%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1512 | Train Accuracy: 96.32% Test Accuracy: 98.67%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1148 | Train Accuracy: 97.43% Test Accuracy: 98.92%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1280 | Train Accuracy: 97.57% Test Accuracy: 99.00%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1175 | Train Accuracy: 97.75% Test Accuracy: 99.00%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1049 | Train Accuracy: 97.57% Test Accuracy: 99.00%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1080 | Train Accuracy: 98.00% Test Accuracy: 99.08%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1015 | Train Accuracy: 97.96% Test Accuracy: 99.08%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0805 | Train Accuracy: 98.25% Test Accuracy: 99.08%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0682 | Train Accuracy: 98.57% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0584 | Train Accuracy: 98.82% Test Accuracy: 99.25%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0655 | Train Accuracy: 98.43% Test Accuracy: 99.17%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0718 | Train Accuracy: 98.61% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0661 | Train Accuracy: 98.64% Test Accuracy: 99.17%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.4990 | Train Accuracy: 23.71% Test Accuracy: 38.17%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 29.8478 | Train Accuracy: 31.14% Test Accuracy: 58.83%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 23.0216 | Train Accuracy: 60.39% Test Accuracy: 64.25%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 14.7087 | Train Accuracy: 69.36% Test Accuracy: 96.67%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.3859 | Train Accuracy: 85.25% Test Accuracy: 96.67%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.9277 | Train Accuracy: 85.07% Test Accuracy: 95.92%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.5991 | Train Accuracy: 85.25% Test Accuracy: 97.67%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 2.4106 | Train Accuracy: 87.75% Test Accuracy: 98.17%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.3992 | Train Accuracy: 90.89% Test Accuracy: 98.42%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.7911 | Train Accuracy: 93.07% Test Accuracy: 98.58%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.9191 | Train Accuracy: 94.50% Test Accuracy: 98.50%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.9794 | Train Accuracy: 93.75% Test Accuracy: 98.33%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.8065 | Train Accuracy: 94.43% Test Accuracy: 98.17%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.8180 | Train Accuracy: 92.68% Test Accuracy: 97.75%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.0803 | Train Accuracy: 93.04% Test Accuracy: 97.83%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.8255 | Train Accuracy: 93.54% Test Accuracy: 97.92%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.9063 | Train Accuracy: 94.89% Test Accuracy: 97.92%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.7081 | Train Accuracy: 94.50% Test Accuracy: 97.83%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.6460 | Train Accuracy: 94.39% Test Accuracy: 98.08%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5039 | Train Accuracy: 95.00% Test Accuracy: 98.25%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.4757 | Train Accuracy: 25.00% Test Accuracy: 76.08%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.2259 | Train Accuracy: 46.00% Test Accuracy: 82.75%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.0556 | Train Accuracy: 59.46% Test Accuracy: 88.08%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.9608 | Train Accuracy: 63.61% Test Accuracy: 91.50%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.8528 | Train Accuracy: 68.43% Test Accuracy: 95.08%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.7895 | Train Accuracy: 70.71% Test Accuracy: 96.58%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.7044 | Train Accuracy: 74.07% Test Accuracy: 97.00%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.6706 | Train Accuracy: 75.75% Test Accuracy: 97.33%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.6026 | Train Accuracy: 78.64% Test Accuracy: 97.50%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.5469 | Train Accuracy: 82.11% Test Accuracy: 97.67%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.5115 | Train Accuracy: 83.61% Test Accuracy: 97.67%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.4669 | Train Accuracy: 85.14% Test Accuracy: 97.75%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.4121 | Train Accuracy: 87.00% Test Accuracy: 97.75%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3907 | Train Accuracy: 88.21% Test Accuracy: 97.83%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3627 | Train Accuracy: 88.64% Test Accuracy: 97.83%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3450 | Train Accuracy: 89.89% Test Accuracy: 97.92%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3099 | Train Accuracy: 91.29% Test Accuracy: 97.92%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2876 | Train Accuracy: 91.86% Test Accuracy: 98.00%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2803 | Train Accuracy: 92.57% Test Accuracy: 98.00%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2496 | Train Accuracy: 93.18% Test Accuracy: 98.08%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.5463 | Train Accuracy: 25.57% Test Accuracy: 93.67%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2467 | Train Accuracy: 41.07% Test Accuracy: 90.83%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1074 | Train Accuracy: 52.68% Test Accuracy: 95.17%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9911 | Train Accuracy: 59.68% Test Accuracy: 96.92%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9084 | Train Accuracy: 65.93% Test Accuracy: 97.42%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8086 | Train Accuracy: 72.46% Test Accuracy: 97.58%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7525 | Train Accuracy: 76.00% Test Accuracy: 97.67%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6764 | Train Accuracy: 81.04% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6125 | Train Accuracy: 83.00% Test Accuracy: 97.67%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5530 | Train Accuracy: 86.54% Test Accuracy: 97.75%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5129 | Train Accuracy: 87.93% Test Accuracy: 97.75%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4715 | Train Accuracy: 90.14% Test Accuracy: 97.75%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4200 | Train Accuracy: 91.82% Test Accuracy: 97.83%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3913 | Train Accuracy: 93.82% Test Accuracy: 98.00%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3620 | Train Accuracy: 93.96% Test Accuracy: 98.00%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3317 | Train Accuracy: 94.82% Test Accuracy: 98.00%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3120 | Train Accuracy: 95.21% Test Accuracy: 98.08%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2760 | Train Accuracy: 95.75% Test Accuracy: 98.08%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2515 | Train Accuracy: 96.89% Test Accuracy: 98.17%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2371 | Train Accuracy: 96.96% Test Accuracy: 98.25%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.5259 | Train Accuracy: 26.64% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 2.1093 | Train Accuracy: 28.75% Test Accuracy: 49.75%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.1013 | Train Accuracy: 52.93% Test Accuracy: 72.67%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9211 | Train Accuracy: 59.39% Test Accuracy: 47.83%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8460 | Train Accuracy: 51.57% Test Accuracy: 72.83%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7371 | Train Accuracy: 63.00% Test Accuracy: 95.00%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6603 | Train Accuracy: 77.82% Test Accuracy: 77.33%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6246 | Train Accuracy: 75.86% Test Accuracy: 84.00%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5793 | Train Accuracy: 78.36% Test Accuracy: 97.00%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4878 | Train Accuracy: 88.07% Test Accuracy: 97.42%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4268 | Train Accuracy: 91.75% Test Accuracy: 97.67%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3920 | Train Accuracy: 91.82% Test Accuracy: 97.67%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3514 | Train Accuracy: 91.61% Test Accuracy: 97.58%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3045 | Train Accuracy: 94.14% Test Accuracy: 97.58%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2635 | Train Accuracy: 95.57% Test Accuracy: 97.42%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2296 | Train Accuracy: 96.11% Test Accuracy: 97.42%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2088 | Train Accuracy: 96.25% Test Accuracy: 97.42%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1902 | Train Accuracy: 96.14% Test Accuracy: 97.42%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1739 | Train Accuracy: 96.43% Test Accuracy: 97.42%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1656 | Train Accuracy: 96.18% Test Accuracy: 97.42%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5230 | Train Accuracy: 24.57% Test Accuracy: 49.67%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4704 | Train Accuracy: 27.54% Test Accuracy: 49.75%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4241 | Train Accuracy: 31.11% Test Accuracy: 49.75%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3767 | Train Accuracy: 34.07% Test Accuracy: 49.83%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3348 | Train Accuracy: 36.29% Test Accuracy: 54.42%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3097 | Train Accuracy: 37.36% Test Accuracy: 84.42%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2832 | Train Accuracy: 40.18% Test Accuracy: 93.50%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2493 | Train Accuracy: 42.39% Test Accuracy: 95.67%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2363 | Train Accuracy: 44.14% Test Accuracy: 97.17%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2121 | Train Accuracy: 43.93% Test Accuracy: 97.42%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1731 | Train Accuracy: 46.75% Test Accuracy: 97.42%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1509 | Train Accuracy: 49.32% Test Accuracy: 97.58%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1393 | Train Accuracy: 48.96% Test Accuracy: 97.58%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1357 | Train Accuracy: 49.14% Test Accuracy: 97.67%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1126 | Train Accuracy: 51.86% Test Accuracy: 97.75%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0907 | Train Accuracy: 53.61% Test Accuracy: 97.75%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0685 | Train Accuracy: 54.29% Test Accuracy: 97.75%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0500 | Train Accuracy: 55.54% Test Accuracy: 97.75%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0540 | Train Accuracy: 56.36% Test Accuracy: 97.75%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0320 | Train Accuracy: 58.50% Test Accuracy: 97.75%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 1.4161 | Train Accuracy: 31.11% Test Accuracy: 87.92%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.6493 | Train Accuracy: 73.79% Test Accuracy: 97.58%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.4621 | Train Accuracy: 85.43% Test Accuracy: 97.58%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.3383 | Train Accuracy: 92.21% Test Accuracy: 97.58%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.2457 | Train Accuracy: 95.14% Test Accuracy: 97.67%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1924 | Train Accuracy: 96.50% Test Accuracy: 97.67%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1674 | Train Accuracy: 96.71% Test Accuracy: 97.75%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1489 | Train Accuracy: 96.75% Test Accuracy: 97.83%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1255 | Train Accuracy: 96.93% Test Accuracy: 98.00%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1180 | Train Accuracy: 97.07% Test Accuracy: 98.00%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1080 | Train Accuracy: 97.29% Test Accuracy: 98.00%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0914 | Train Accuracy: 97.79% Test Accuracy: 98.08%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0990 | Train Accuracy: 97.50% Test Accuracy: 98.25%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0827 | Train Accuracy: 97.89% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0865 | Train Accuracy: 97.68% Test Accuracy: 98.58%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0757 | Train Accuracy: 97.96% Test Accuracy: 98.75%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0719 | Train Accuracy: 98.04% Test Accuracy: 99.08%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0669 | Train Accuracy: 98.32% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0736 | Train Accuracy: 98.00% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0701 | Train Accuracy: 97.93% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.4594 | Train Accuracy: 29.46% Test Accuracy: 83.08%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.0266 | Train Accuracy: 56.61% Test Accuracy: 55.58%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.9871 | Train Accuracy: 63.86% Test Accuracy: 52.17%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.7937 | Train Accuracy: 67.64% Test Accuracy: 86.25%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.5954 | Train Accuracy: 77.57% Test Accuracy: 96.75%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3440 | Train Accuracy: 90.46% Test Accuracy: 96.92%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2997 | Train Accuracy: 92.54% Test Accuracy: 97.42%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2645 | Train Accuracy: 94.14% Test Accuracy: 97.58%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2265 | Train Accuracy: 95.50% Test Accuracy: 97.67%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1923 | Train Accuracy: 95.82% Test Accuracy: 97.50%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1624 | Train Accuracy: 96.57% Test Accuracy: 97.50%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1543 | Train Accuracy: 96.71% Test Accuracy: 97.42%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1507 | Train Accuracy: 96.61% Test Accuracy: 97.58%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1382 | Train Accuracy: 96.18% Test Accuracy: 98.00%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1370 | Train Accuracy: 96.11% Test Accuracy: 98.17%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1488 | Train Accuracy: 96.18% Test Accuracy: 98.17%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1324 | Train Accuracy: 96.57% Test Accuracy: 98.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1332 | Train Accuracy: 96.36% Test Accuracy: 97.92%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1261 | Train Accuracy: 96.96% Test Accuracy: 97.75%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1185 | Train Accuracy: 97.18% Test Accuracy: 97.75%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.4969 | Train Accuracy: 25.54% Test Accuracy: 94.75%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.0074 | Train Accuracy: 58.96% Test Accuracy: 96.33%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.7821 | Train Accuracy: 70.61% Test Accuracy: 96.83%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.6184 | Train Accuracy: 79.86% Test Accuracy: 97.00%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.5483 | Train Accuracy: 83.75% Test Accuracy: 97.17%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.4722 | Train Accuracy: 87.07% Test Accuracy: 97.33%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.4296 | Train Accuracy: 88.89% Test Accuracy: 97.67%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3926 | Train Accuracy: 90.86% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3442 | Train Accuracy: 93.11% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3136 | Train Accuracy: 93.68% Test Accuracy: 98.00%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2952 | Train Accuracy: 94.14% Test Accuracy: 98.00%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2663 | Train Accuracy: 95.32% Test Accuracy: 98.08%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2475 | Train Accuracy: 95.93% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2285 | Train Accuracy: 96.21% Test Accuracy: 98.00%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2138 | Train Accuracy: 96.64% Test Accuracy: 98.08%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2027 | Train Accuracy: 96.50% Test Accuracy: 98.17%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1924 | Train Accuracy: 96.68% Test Accuracy: 98.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1907 | Train Accuracy: 96.64% Test Accuracy: 98.42%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1769 | Train Accuracy: 97.04% Test Accuracy: 98.42%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1649 | Train Accuracy: 97.36% Test Accuracy: 98.58%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.3813 | Train Accuracy: 28.61% Test Accuracy: 73.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.6185 | Train Accuracy: 96.39% Test Accuracy: 97.83%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.3716 | Train Accuracy: 97.61% Test Accuracy: 97.92%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2901 | Train Accuracy: 97.50% Test Accuracy: 97.92%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2382 | Train Accuracy: 97.82% Test Accuracy: 97.92%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2029 | Train Accuracy: 97.71% Test Accuracy: 97.92%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1789 | Train Accuracy: 97.79% Test Accuracy: 97.92%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1625 | Train Accuracy: 97.96% Test Accuracy: 97.92%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1491 | Train Accuracy: 97.86% Test Accuracy: 98.08%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1369 | Train Accuracy: 98.04% Test Accuracy: 98.17%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1249 | Train Accuracy: 98.14% Test Accuracy: 98.17%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1159 | Train Accuracy: 98.21% Test Accuracy: 98.25%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1066 | Train Accuracy: 98.29% Test Accuracy: 98.33%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1009 | Train Accuracy: 98.50% Test Accuracy: 98.42%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0939 | Train Accuracy: 98.50% Test Accuracy: 98.67%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0867 | Train Accuracy: 98.68% Test Accuracy: 98.75%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0835 | Train Accuracy: 98.68% Test Accuracy: 98.75%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0768 | Train Accuracy: 98.96% Test Accuracy: 98.92%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0724 | Train Accuracy: 99.14% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0668 | Train Accuracy: 99.29% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 1.4022 | Train Accuracy: 27.68% Test Accuracy: 49.92%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.6272 | Train Accuracy: 86.57% Test Accuracy: 71.67%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.2063 | Train Accuracy: 96.54% Test Accuracy: 72.00%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1599 | Train Accuracy: 96.93% Test Accuracy: 72.08%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1258 | Train Accuracy: 97.29% Test Accuracy: 72.00%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1042 | Train Accuracy: 97.36% Test Accuracy: 72.00%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0878 | Train Accuracy: 97.50% Test Accuracy: 72.33%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0764 | Train Accuracy: 97.82% Test Accuracy: 92.17%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0688 | Train Accuracy: 97.82% Test Accuracy: 96.58%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0585 | Train Accuracy: 98.11% Test Accuracy: 97.42%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0538 | Train Accuracy: 98.07% Test Accuracy: 97.75%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0453 | Train Accuracy: 98.54% Test Accuracy: 98.00%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0425 | Train Accuracy: 98.79% Test Accuracy: 98.25%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0428 | Train Accuracy: 98.93% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0395 | Train Accuracy: 98.89% Test Accuracy: 98.42%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0381 | Train Accuracy: 98.96% Test Accuracy: 98.83%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0329 | Train Accuracy: 99.07% Test Accuracy: 98.83%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0316 | Train Accuracy: 99.21% Test Accuracy: 98.92%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0304 | Train Accuracy: 99.18% Test Accuracy: 98.92%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0278 | Train Accuracy: 99.21% Test Accuracy: 98.92%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.3904 | Train Accuracy: 31.75% Test Accuracy: 78.17%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.8699 | Train Accuracy: 84.39% Test Accuracy: 93.17%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.6601 | Train Accuracy: 94.25% Test Accuracy: 96.75%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5509 | Train Accuracy: 96.75% Test Accuracy: 97.17%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4939 | Train Accuracy: 96.96% Test Accuracy: 97.50%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4413 | Train Accuracy: 97.36% Test Accuracy: 97.50%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4096 | Train Accuracy: 97.64% Test Accuracy: 97.67%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3829 | Train Accuracy: 97.71% Test Accuracy: 97.92%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3574 | Train Accuracy: 97.89% Test Accuracy: 98.08%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3415 | Train Accuracy: 97.86% Test Accuracy: 98.17%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3247 | Train Accuracy: 97.75% Test Accuracy: 98.25%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3116 | Train Accuracy: 98.11% Test Accuracy: 98.25%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2978 | Train Accuracy: 97.89% Test Accuracy: 98.25%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2850 | Train Accuracy: 98.14% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2785 | Train Accuracy: 98.07% Test Accuracy: 98.42%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2644 | Train Accuracy: 97.96% Test Accuracy: 98.42%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2582 | Train Accuracy: 98.14% Test Accuracy: 98.67%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2492 | Train Accuracy: 98.43% Test Accuracy: 98.67%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2412 | Train Accuracy: 98.21% Test Accuracy: 98.83%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2331 | Train Accuracy: 98.29% Test Accuracy: 98.83%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.5102 | Train Accuracy: 21.29% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1310 | Train Accuracy: 49.43% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0122 | Train Accuracy: 59.11% Test Accuracy: 25.00%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9235 | Train Accuracy: 75.64% Test Accuracy: 25.00%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8569 | Train Accuracy: 86.61% Test Accuracy: 27.42%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7965 | Train Accuracy: 92.75% Test Accuracy: 74.42%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7520 | Train Accuracy: 94.96% Test Accuracy: 93.42%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7201 | Train Accuracy: 95.61% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6886 | Train Accuracy: 97.00% Test Accuracy: 97.92%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6624 | Train Accuracy: 96.79% Test Accuracy: 98.08%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6410 | Train Accuracy: 96.93% Test Accuracy: 98.08%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6186 | Train Accuracy: 97.36% Test Accuracy: 98.33%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5986 | Train Accuracy: 97.39% Test Accuracy: 98.33%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5820 | Train Accuracy: 97.39% Test Accuracy: 98.50%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5683 | Train Accuracy: 97.54% Test Accuracy: 98.50%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5540 | Train Accuracy: 97.82% Test Accuracy: 98.42%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5442 | Train Accuracy: 97.50% Test Accuracy: 98.42%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5269 | Train Accuracy: 97.50% Test Accuracy: 98.42%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5161 | Train Accuracy: 97.79% Test Accuracy: 98.42%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5002 | Train Accuracy: 97.68% Test Accuracy: 98.58%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.3914 | Train Accuracy: 26.61% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.1000 | Train Accuracy: 51.18% Test Accuracy: 75.08%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7349 | Train Accuracy: 92.39% Test Accuracy: 91.00%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6234 | Train Accuracy: 94.86% Test Accuracy: 95.92%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5254 | Train Accuracy: 96.71% Test Accuracy: 96.92%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4443 | Train Accuracy: 97.46% Test Accuracy: 97.17%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3750 | Train Accuracy: 97.54% Test Accuracy: 97.08%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3197 | Train Accuracy: 96.82% Test Accuracy: 97.17%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2772 | Train Accuracy: 96.96% Test Accuracy: 97.33%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2383 | Train Accuracy: 97.43% Test Accuracy: 97.58%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2092 | Train Accuracy: 97.25% Test Accuracy: 97.92%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1824 | Train Accuracy: 97.43% Test Accuracy: 98.08%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1653 | Train Accuracy: 97.18% Test Accuracy: 98.17%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1460 | Train Accuracy: 97.79% Test Accuracy: 98.42%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1356 | Train Accuracy: 97.64% Test Accuracy: 98.50%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1212 | Train Accuracy: 97.79% Test Accuracy: 98.58%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1091 | Train Accuracy: 97.68% Test Accuracy: 98.75%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1006 | Train Accuracy: 97.71% Test Accuracy: 98.83%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.0966 | Train Accuracy: 97.68% Test Accuracy: 98.75%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.0895 | Train Accuracy: 98.14% Test Accuracy: 98.67%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4120 | Train Accuracy: 25.68% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2390 | Train Accuracy: 45.11% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1428 | Train Accuracy: 52.96% Test Accuracy: 25.00%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0805 | Train Accuracy: 58.68% Test Accuracy: 25.00%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0434 | Train Accuracy: 63.57% Test Accuracy: 25.00%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0154 | Train Accuracy: 67.75% Test Accuracy: 25.00%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9892 | Train Accuracy: 72.82% Test Accuracy: 25.00%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9747 | Train Accuracy: 73.68% Test Accuracy: 25.00%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9574 | Train Accuracy: 76.64% Test Accuracy: 25.00%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9423 | Train Accuracy: 79.25% Test Accuracy: 25.00%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9240 | Train Accuracy: 82.11% Test Accuracy: 39.33%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9116 | Train Accuracy: 82.96% Test Accuracy: 47.42%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9012 | Train Accuracy: 84.00% Test Accuracy: 49.08%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8840 | Train Accuracy: 85.29% Test Accuracy: 49.83%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8797 | Train Accuracy: 86.71% Test Accuracy: 50.75%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8580 | Train Accuracy: 88.21% Test Accuracy: 60.75%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8527 | Train Accuracy: 89.50% Test Accuracy: 65.83%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8381 | Train Accuracy: 89.64% Test Accuracy: 70.75%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8367 | Train Accuracy: 90.04% Test Accuracy: 77.00%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8246 | Train Accuracy: 91.43% Test Accuracy: 83.00%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 1.5060 | Train Accuracy: 23.11% Test Accuracy: 88.17%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.4047 | Train Accuracy: 96.68% Test Accuracy: 96.50%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2702 | Train Accuracy: 96.39% Test Accuracy: 97.08%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2079 | Train Accuracy: 97.07% Test Accuracy: 97.75%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1697 | Train Accuracy: 97.54% Test Accuracy: 97.83%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1473 | Train Accuracy: 97.57% Test Accuracy: 97.92%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1304 | Train Accuracy: 97.79% Test Accuracy: 98.17%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1204 | Train Accuracy: 97.89% Test Accuracy: 98.33%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1092 | Train Accuracy: 98.07% Test Accuracy: 98.50%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1003 | Train Accuracy: 98.00% Test Accuracy: 98.58%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0934 | Train Accuracy: 98.18% Test Accuracy: 98.67%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0867 | Train Accuracy: 98.25% Test Accuracy: 98.58%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0829 | Train Accuracy: 98.11% Test Accuracy: 98.67%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0757 | Train Accuracy: 98.43% Test Accuracy: 98.67%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0742 | Train Accuracy: 98.50% Test Accuracy: 98.67%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0690 | Train Accuracy: 98.68% Test Accuracy: 98.67%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0667 | Train Accuracy: 98.64% Test Accuracy: 98.75%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0631 | Train Accuracy: 98.64% Test Accuracy: 98.92%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0633 | Train Accuracy: 98.93% Test Accuracy: 99.00%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0573 | Train Accuracy: 99.07% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 1.4577 | Train Accuracy: 22.00% Test Accuracy: 55.92%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.5462 | Train Accuracy: 84.04% Test Accuracy: 71.92%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.5505 | Train Accuracy: 81.68% Test Accuracy: 75.92%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2693 | Train Accuracy: 94.93% Test Accuracy: 78.08%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2431 | Train Accuracy: 96.54% Test Accuracy: 96.42%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1928 | Train Accuracy: 97.25% Test Accuracy: 97.42%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1502 | Train Accuracy: 97.18% Test Accuracy: 97.58%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1303 | Train Accuracy: 97.32% Test Accuracy: 97.58%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1192 | Train Accuracy: 97.39% Test Accuracy: 97.58%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1110 | Train Accuracy: 97.36% Test Accuracy: 97.75%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1000 | Train Accuracy: 97.46% Test Accuracy: 97.92%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0929 | Train Accuracy: 97.57% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0898 | Train Accuracy: 97.71% Test Accuracy: 97.92%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0837 | Train Accuracy: 97.71% Test Accuracy: 98.00%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0809 | Train Accuracy: 97.82% Test Accuracy: 98.00%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0731 | Train Accuracy: 98.00% Test Accuracy: 98.25%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0701 | Train Accuracy: 98.04% Test Accuracy: 98.25%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0686 | Train Accuracy: 98.00% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0649 | Train Accuracy: 98.00% Test Accuracy: 98.67%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0653 | Train Accuracy: 98.04% Test Accuracy: 98.92%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.4052 | Train Accuracy: 27.43% Test Accuracy: 85.25%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.7029 | Train Accuracy: 88.32% Test Accuracy: 95.83%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.4739 | Train Accuracy: 95.68% Test Accuracy: 97.25%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3689 | Train Accuracy: 96.86% Test Accuracy: 97.75%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3132 | Train Accuracy: 97.32% Test Accuracy: 97.75%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2749 | Train Accuracy: 97.68% Test Accuracy: 97.83%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2530 | Train Accuracy: 97.54% Test Accuracy: 97.92%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2322 | Train Accuracy: 97.93% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2158 | Train Accuracy: 97.68% Test Accuracy: 98.17%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2040 | Train Accuracy: 97.86% Test Accuracy: 98.25%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1932 | Train Accuracy: 97.96% Test Accuracy: 98.33%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1834 | Train Accuracy: 97.82% Test Accuracy: 98.42%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1752 | Train Accuracy: 97.96% Test Accuracy: 98.42%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1699 | Train Accuracy: 98.07% Test Accuracy: 98.42%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1629 | Train Accuracy: 98.00% Test Accuracy: 98.50%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1561 | Train Accuracy: 98.07% Test Accuracy: 98.50%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1510 | Train Accuracy: 98.36% Test Accuracy: 98.50%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1461 | Train Accuracy: 98.18% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1443 | Train Accuracy: 98.00% Test Accuracy: 98.67%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1391 | Train Accuracy: 98.11% Test Accuracy: 98.67%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.3758 | Train Accuracy: 35.93% Test Accuracy: 90.75%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.7748 | Train Accuracy: 85.57% Test Accuracy: 97.25%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.3150 | Train Accuracy: 95.82% Test Accuracy: 97.67%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1622 | Train Accuracy: 96.64% Test Accuracy: 98.00%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0961 | Train Accuracy: 97.39% Test Accuracy: 99.08%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0756 | Train Accuracy: 98.00% Test Accuracy: 99.17%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0746 | Train Accuracy: 98.11% Test Accuracy: 99.00%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0619 | Train Accuracy: 98.25% Test Accuracy: 99.08%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0486 | Train Accuracy: 98.46% Test Accuracy: 99.33%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0426 | Train Accuracy: 98.89% Test Accuracy: 99.25%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0396 | Train Accuracy: 99.00% Test Accuracy: 99.25%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0449 | Train Accuracy: 99.07% Test Accuracy: 99.33%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0327 | Train Accuracy: 99.36% Test Accuracy: 99.17%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0300 | Train Accuracy: 99.43% Test Accuracy: 99.08%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0343 | Train Accuracy: 99.39% Test Accuracy: 99.00%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0330 | Train Accuracy: 99.46% Test Accuracy: 99.00%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0236 | Train Accuracy: 99.54% Test Accuracy: 99.00%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0243 | Train Accuracy: 99.64% Test Accuracy: 99.00%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0260 | Train Accuracy: 99.39% Test Accuracy: 99.00%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0225 | Train Accuracy: 99.57% Test Accuracy: 99.00%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.3839 | Train Accuracy: 24.36% Test Accuracy: 49.75%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 19.0940 | Train Accuracy: 46.43% Test Accuracy: 48.25%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 72.8297 | Train Accuracy: 47.93% Test Accuracy: 40.67%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 9.3468 | Train Accuracy: 39.29% Test Accuracy: 47.33%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.0315 | Train Accuracy: 43.75% Test Accuracy: 73.42%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.1377 | Train Accuracy: 61.21% Test Accuracy: 95.42%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5855 | Train Accuracy: 79.68% Test Accuracy: 82.17%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.6827 | Train Accuracy: 76.04% Test Accuracy: 95.67%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.4800 | Train Accuracy: 84.75% Test Accuracy: 97.58%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.3294 | Train Accuracy: 91.46% Test Accuracy: 97.92%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.3302 | Train Accuracy: 90.71% Test Accuracy: 98.08%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2953 | Train Accuracy: 90.96% Test Accuracy: 97.67%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2712 | Train Accuracy: 93.04% Test Accuracy: 97.83%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2247 | Train Accuracy: 94.57% Test Accuracy: 97.92%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2239 | Train Accuracy: 94.57% Test Accuracy: 97.92%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2004 | Train Accuracy: 94.75% Test Accuracy: 98.08%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2027 | Train Accuracy: 94.82% Test Accuracy: 98.25%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.1858 | Train Accuracy: 94.79% Test Accuracy: 98.08%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.1889 | Train Accuracy: 94.79% Test Accuracy: 97.92%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.1875 | Train Accuracy: 95.07% Test Accuracy: 98.00%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.3853 | Train Accuracy: 26.25% Test Accuracy: 94.83%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.2848 | Train Accuracy: 78.29% Test Accuracy: 96.67%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1970 | Train Accuracy: 92.54% Test Accuracy: 97.42%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1061 | Train Accuracy: 94.68% Test Accuracy: 97.50%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.0133 | Train Accuracy: 95.43% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.9166 | Train Accuracy: 95.75% Test Accuracy: 97.50%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.8221 | Train Accuracy: 95.68% Test Accuracy: 97.50%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.7314 | Train Accuracy: 96.21% Test Accuracy: 97.50%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.6451 | Train Accuracy: 96.46% Test Accuracy: 97.50%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.5666 | Train Accuracy: 96.50% Test Accuracy: 97.58%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.4897 | Train Accuracy: 96.50% Test Accuracy: 97.58%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.4206 | Train Accuracy: 96.71% Test Accuracy: 97.67%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3629 | Train Accuracy: 96.93% Test Accuracy: 97.67%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3092 | Train Accuracy: 97.04% Test Accuracy: 97.67%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2653 | Train Accuracy: 97.04% Test Accuracy: 97.75%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2268 | Train Accuracy: 97.18% Test Accuracy: 97.75%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1996 | Train Accuracy: 96.93% Test Accuracy: 97.75%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1789 | Train Accuracy: 97.07% Test Accuracy: 97.75%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1611 | Train Accuracy: 97.00% Test Accuracy: 97.75%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1394 | Train Accuracy: 97.21% Test Accuracy: 97.75%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4190 | Train Accuracy: 25.61% Test Accuracy: 47.33%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3500 | Train Accuracy: 35.14% Test Accuracy: 49.75%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3147 | Train Accuracy: 43.29% Test Accuracy: 49.83%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2841 | Train Accuracy: 47.32% Test Accuracy: 49.83%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2437 | Train Accuracy: 51.29% Test Accuracy: 49.83%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1970 | Train Accuracy: 55.29% Test Accuracy: 52.58%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1463 | Train Accuracy: 59.39% Test Accuracy: 71.67%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0903 | Train Accuracy: 64.04% Test Accuracy: 97.42%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0330 | Train Accuracy: 70.04% Test Accuracy: 97.42%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9884 | Train Accuracy: 71.21% Test Accuracy: 97.33%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9363 | Train Accuracy: 75.54% Test Accuracy: 94.75%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8971 | Train Accuracy: 74.00% Test Accuracy: 81.83%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8578 | Train Accuracy: 74.68% Test Accuracy: 83.33%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8238 | Train Accuracy: 75.79% Test Accuracy: 95.83%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7876 | Train Accuracy: 79.11% Test Accuracy: 97.33%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7601 | Train Accuracy: 81.43% Test Accuracy: 97.50%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7268 | Train Accuracy: 86.36% Test Accuracy: 97.58%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6953 | Train Accuracy: 89.68% Test Accuracy: 97.75%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6594 | Train Accuracy: 93.29% Test Accuracy: 97.75%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6305 | Train Accuracy: 95.18% Test Accuracy: 97.75%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4524 | Train Accuracy: 24.96% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.7298 | Train Accuracy: 29.39% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4671 | Train Accuracy: 37.00% Test Accuracy: 72.67%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.1892 | Train Accuracy: 55.11% Test Accuracy: 68.00%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.0251 | Train Accuracy: 58.61% Test Accuracy: 65.83%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9218 | Train Accuracy: 52.57% Test Accuracy: 57.33%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8444 | Train Accuracy: 52.50% Test Accuracy: 70.67%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7882 | Train Accuracy: 55.89% Test Accuracy: 76.92%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7554 | Train Accuracy: 62.89% Test Accuracy: 75.00%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7367 | Train Accuracy: 62.04% Test Accuracy: 74.92%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7213 | Train Accuracy: 63.68% Test Accuracy: 75.42%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6868 | Train Accuracy: 72.29% Test Accuracy: 97.33%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6405 | Train Accuracy: 89.18% Test Accuracy: 97.67%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5975 | Train Accuracy: 94.93% Test Accuracy: 97.67%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5507 | Train Accuracy: 95.29% Test Accuracy: 97.75%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4886 | Train Accuracy: 96.64% Test Accuracy: 97.67%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4200 | Train Accuracy: 97.29% Test Accuracy: 97.67%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3575 | Train Accuracy: 97.32% Test Accuracy: 97.67%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3001 | Train Accuracy: 97.36% Test Accuracy: 97.67%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2458 | Train Accuracy: 97.46% Test Accuracy: 97.67%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4337 | Train Accuracy: 25.68% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4212 | Train Accuracy: 26.36% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4085 | Train Accuracy: 25.86% Test Accuracy: 25.00%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3948 | Train Accuracy: 28.25% Test Accuracy: 25.00%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3848 | Train Accuracy: 28.96% Test Accuracy: 25.00%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3785 | Train Accuracy: 29.18% Test Accuracy: 25.00%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3717 | Train Accuracy: 30.29% Test Accuracy: 25.00%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3619 | Train Accuracy: 31.21% Test Accuracy: 25.25%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3532 | Train Accuracy: 32.75% Test Accuracy: 31.92%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3430 | Train Accuracy: 34.50% Test Accuracy: 39.33%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3356 | Train Accuracy: 36.79% Test Accuracy: 44.75%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3294 | Train Accuracy: 37.39% Test Accuracy: 46.33%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3274 | Train Accuracy: 38.14% Test Accuracy: 47.17%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3233 | Train Accuracy: 39.68% Test Accuracy: 47.50%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3193 | Train Accuracy: 40.54% Test Accuracy: 47.75%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3098 | Train Accuracy: 43.86% Test Accuracy: 55.42%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3026 | Train Accuracy: 46.32% Test Accuracy: 72.25%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2984 | Train Accuracy: 46.54% Test Accuracy: 73.00%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2957 | Train Accuracy: 48.04% Test Accuracy: 97.42%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2898 | Train Accuracy: 49.11% Test Accuracy: 97.58%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 1.4143 | Train Accuracy: 22.21% Test Accuracy: 96.17%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.6305 | Train Accuracy: 92.29% Test Accuracy: 96.58%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.4599 | Train Accuracy: 95.50% Test Accuracy: 97.25%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.3195 | Train Accuracy: 96.82% Test Accuracy: 97.50%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.2315 | Train Accuracy: 97.07% Test Accuracy: 97.50%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1779 | Train Accuracy: 97.14% Test Accuracy: 97.50%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1473 | Train Accuracy: 97.18% Test Accuracy: 97.50%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1226 | Train Accuracy: 97.36% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1056 | Train Accuracy: 97.50% Test Accuracy: 97.75%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0945 | Train Accuracy: 97.75% Test Accuracy: 98.25%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0838 | Train Accuracy: 97.89% Test Accuracy: 98.75%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0742 | Train Accuracy: 98.32% Test Accuracy: 99.17%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0677 | Train Accuracy: 98.39% Test Accuracy: 99.17%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0618 | Train Accuracy: 98.46% Test Accuracy: 99.17%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0569 | Train Accuracy: 98.71% Test Accuracy: 99.17%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0519 | Train Accuracy: 98.75% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0471 | Train Accuracy: 98.82% Test Accuracy: 99.25%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0444 | Train Accuracy: 99.11% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0401 | Train Accuracy: 99.11% Test Accuracy: 99.33%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0394 | Train Accuracy: 99.14% Test Accuracy: 99.33%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.3737 | Train Accuracy: 36.43% Test Accuracy: 54.83%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.8156 | Train Accuracy: 58.68% Test Accuracy: 48.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.8396 | Train Accuracy: 47.82% Test Accuracy: 57.25%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.8400 | Train Accuracy: 54.64% Test Accuracy: 49.92%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.8829 | Train Accuracy: 50.25% Test Accuracy: 49.92%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.8675 | Train Accuracy: 53.96% Test Accuracy: 65.17%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.7017 | Train Accuracy: 64.96% Test Accuracy: 88.08%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.6175 | Train Accuracy: 82.18% Test Accuracy: 85.17%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.5332 | Train Accuracy: 84.32% Test Accuracy: 96.08%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.4494 | Train Accuracy: 93.79% Test Accuracy: 96.42%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3691 | Train Accuracy: 95.36% Test Accuracy: 96.42%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3075 | Train Accuracy: 95.75% Test Accuracy: 96.58%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2533 | Train Accuracy: 96.11% Test Accuracy: 96.83%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2158 | Train Accuracy: 96.25% Test Accuracy: 96.83%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1949 | Train Accuracy: 96.32% Test Accuracy: 96.83%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1713 | Train Accuracy: 96.25% Test Accuracy: 96.92%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1534 | Train Accuracy: 96.54% Test Accuracy: 96.75%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1378 | Train Accuracy: 96.39% Test Accuracy: 96.83%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1240 | Train Accuracy: 96.71% Test Accuracy: 97.08%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1102 | Train Accuracy: 96.86% Test Accuracy: 97.08%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.4435 | Train Accuracy: 13.61% Test Accuracy: 92.17%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.0707 | Train Accuracy: 84.79% Test Accuracy: 96.33%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.8470 | Train Accuracy: 93.71% Test Accuracy: 97.25%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.7107 | Train Accuracy: 95.50% Test Accuracy: 97.42%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.6254 | Train Accuracy: 96.00% Test Accuracy: 97.25%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.5587 | Train Accuracy: 96.54% Test Accuracy: 97.58%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.5054 | Train Accuracy: 96.82% Test Accuracy: 97.58%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.4636 | Train Accuracy: 96.96% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.4229 | Train Accuracy: 97.00% Test Accuracy: 97.75%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3918 | Train Accuracy: 97.18% Test Accuracy: 97.92%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3636 | Train Accuracy: 97.18% Test Accuracy: 97.92%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3381 | Train Accuracy: 97.21% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3149 | Train Accuracy: 97.39% Test Accuracy: 97.92%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2956 | Train Accuracy: 97.32% Test Accuracy: 97.92%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2789 | Train Accuracy: 97.43% Test Accuracy: 97.92%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2631 | Train Accuracy: 97.46% Test Accuracy: 98.00%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2495 | Train Accuracy: 97.54% Test Accuracy: 98.00%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2384 | Train Accuracy: 97.64% Test Accuracy: 98.08%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2256 | Train Accuracy: 97.68% Test Accuracy: 98.08%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2171 | Train Accuracy: 97.71% Test Accuracy: 98.17%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.5475 | Train Accuracy: 25.29% Test Accuracy: 95.33%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.8991 | Train Accuracy: 72.61% Test Accuracy: 97.58%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.6473 | Train Accuracy: 88.36% Test Accuracy: 97.83%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.5197 | Train Accuracy: 94.43% Test Accuracy: 97.83%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.4141 | Train Accuracy: 96.46% Test Accuracy: 97.92%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.3451 | Train Accuracy: 96.75% Test Accuracy: 98.00%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2998 | Train Accuracy: 97.18% Test Accuracy: 98.08%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2622 | Train Accuracy: 97.64% Test Accuracy: 98.17%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2333 | Train Accuracy: 97.68% Test Accuracy: 98.17%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2089 | Train Accuracy: 97.82% Test Accuracy: 98.17%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1874 | Train Accuracy: 97.79% Test Accuracy: 98.17%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1728 | Train Accuracy: 97.86% Test Accuracy: 98.25%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1611 | Train Accuracy: 98.25% Test Accuracy: 98.25%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1463 | Train Accuracy: 97.96% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1361 | Train Accuracy: 98.32% Test Accuracy: 98.50%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1266 | Train Accuracy: 98.46% Test Accuracy: 98.67%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1200 | Train Accuracy: 98.36% Test Accuracy: 98.83%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1117 | Train Accuracy: 98.57% Test Accuracy: 99.00%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1063 | Train Accuracy: 98.50% Test Accuracy: 99.08%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0946 | Train Accuracy: 98.89% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 1.5364 | Train Accuracy: 22.29% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 1.0673 | Train Accuracy: 54.93% Test Accuracy: 52.92%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.3501 | Train Accuracy: 96.14% Test Accuracy: 59.92%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.2393 | Train Accuracy: 97.25% Test Accuracy: 67.42%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1804 | Train Accuracy: 97.36% Test Accuracy: 70.75%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1424 | Train Accuracy: 97.50% Test Accuracy: 83.83%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1120 | Train Accuracy: 97.64% Test Accuracy: 95.75%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0972 | Train Accuracy: 97.75% Test Accuracy: 96.75%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0814 | Train Accuracy: 97.93% Test Accuracy: 97.50%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0780 | Train Accuracy: 98.07% Test Accuracy: 97.58%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0633 | Train Accuracy: 98.21% Test Accuracy: 97.67%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0606 | Train Accuracy: 98.36% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0551 | Train Accuracy: 98.57% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0531 | Train Accuracy: 98.43% Test Accuracy: 98.42%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0470 | Train Accuracy: 98.61% Test Accuracy: 98.42%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0429 | Train Accuracy: 98.79% Test Accuracy: 98.50%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0439 | Train Accuracy: 98.96% Test Accuracy: 98.67%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0508 | Train Accuracy: 98.75% Test Accuracy: 98.83%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0410 | Train Accuracy: 99.18% Test Accuracy: 98.83%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0417 | Train Accuracy: 98.79% Test Accuracy: 98.83%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.4727 | Train Accuracy: 25.68% Test Accuracy: 69.58%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.1363 | Train Accuracy: 49.11% Test Accuracy: 93.75%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.9651 | Train Accuracy: 64.75% Test Accuracy: 96.50%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.8647 | Train Accuracy: 73.00% Test Accuracy: 97.25%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.7856 | Train Accuracy: 79.04% Test Accuracy: 97.25%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.7304 | Train Accuracy: 83.96% Test Accuracy: 97.50%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.6882 | Train Accuracy: 86.96% Test Accuracy: 97.58%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.6612 | Train Accuracy: 88.71% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.6311 | Train Accuracy: 91.50% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.6070 | Train Accuracy: 91.79% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5855 | Train Accuracy: 93.11% Test Accuracy: 98.08%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5580 | Train Accuracy: 94.43% Test Accuracy: 98.17%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5442 | Train Accuracy: 94.36% Test Accuracy: 98.17%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5287 | Train Accuracy: 95.07% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5029 | Train Accuracy: 95.64% Test Accuracy: 98.33%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4964 | Train Accuracy: 95.46% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4837 | Train Accuracy: 96.57% Test Accuracy: 98.42%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4625 | Train Accuracy: 96.82% Test Accuracy: 98.42%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4536 | Train Accuracy: 97.00% Test Accuracy: 98.50%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4385 | Train Accuracy: 96.79% Test Accuracy: 98.50%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4516 | Train Accuracy: 24.32% Test Accuracy: 49.83%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2805 | Train Accuracy: 40.39% Test Accuracy: 49.83%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2073 | Train Accuracy: 48.68% Test Accuracy: 87.58%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1449 | Train Accuracy: 58.04% Test Accuracy: 97.08%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0826 | Train Accuracy: 64.54% Test Accuracy: 97.42%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0235 | Train Accuracy: 70.68% Test Accuracy: 97.33%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9845 | Train Accuracy: 72.89% Test Accuracy: 97.33%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9346 | Train Accuracy: 76.50% Test Accuracy: 97.42%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8962 | Train Accuracy: 79.29% Test Accuracy: 97.58%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8571 | Train Accuracy: 81.36% Test Accuracy: 97.50%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8297 | Train Accuracy: 83.75% Test Accuracy: 97.67%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7971 | Train Accuracy: 85.18% Test Accuracy: 98.00%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7772 | Train Accuracy: 85.64% Test Accuracy: 98.17%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7451 | Train Accuracy: 88.32% Test Accuracy: 98.17%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7157 | Train Accuracy: 89.64% Test Accuracy: 98.17%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6963 | Train Accuracy: 90.50% Test Accuracy: 98.25%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6735 | Train Accuracy: 90.39% Test Accuracy: 98.25%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6504 | Train Accuracy: 92.36% Test Accuracy: 98.25%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6430 | Train Accuracy: 91.71% Test Accuracy: 98.33%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6158 | Train Accuracy: 93.04% Test Accuracy: 98.42%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4967 | Train Accuracy: 25.75% Test Accuracy: 25.25%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.3347 | Train Accuracy: 34.96% Test Accuracy: 62.17%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.0204 | Train Accuracy: 61.14% Test Accuracy: 95.83%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8466 | Train Accuracy: 78.43% Test Accuracy: 97.58%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7223 | Train Accuracy: 86.04% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6250 | Train Accuracy: 90.39% Test Accuracy: 97.67%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5605 | Train Accuracy: 92.68% Test Accuracy: 97.58%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4966 | Train Accuracy: 92.82% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4544 | Train Accuracy: 93.25% Test Accuracy: 97.75%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4041 | Train Accuracy: 93.79% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3656 | Train Accuracy: 94.61% Test Accuracy: 98.08%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3227 | Train Accuracy: 95.36% Test Accuracy: 98.33%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2927 | Train Accuracy: 95.43% Test Accuracy: 98.33%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2768 | Train Accuracy: 95.29% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2416 | Train Accuracy: 95.93% Test Accuracy: 98.42%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2306 | Train Accuracy: 95.79% Test Accuracy: 98.50%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2136 | Train Accuracy: 95.82% Test Accuracy: 98.58%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1939 | Train Accuracy: 96.46% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1776 | Train Accuracy: 96.64% Test Accuracy: 98.58%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1768 | Train Accuracy: 96.00% Test Accuracy: 98.67%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4575 | Train Accuracy: 24.68% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3855 | Train Accuracy: 30.36% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3326 | Train Accuracy: 33.82% Test Accuracy: 25.00%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3060 | Train Accuracy: 39.04% Test Accuracy: 25.00%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2851 | Train Accuracy: 39.61% Test Accuracy: 25.00%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2623 | Train Accuracy: 42.61% Test Accuracy: 25.25%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2500 | Train Accuracy: 44.43% Test Accuracy: 39.25%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2325 | Train Accuracy: 46.89% Test Accuracy: 60.50%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2146 | Train Accuracy: 49.29% Test Accuracy: 66.00%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2123 | Train Accuracy: 48.93% Test Accuracy: 69.17%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1981 | Train Accuracy: 51.07% Test Accuracy: 71.00%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1906 | Train Accuracy: 51.36% Test Accuracy: 71.83%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1943 | Train Accuracy: 51.86% Test Accuracy: 72.50%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1622 | Train Accuracy: 54.93% Test Accuracy: 72.58%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1641 | Train Accuracy: 55.46% Test Accuracy: 73.00%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1569 | Train Accuracy: 56.18% Test Accuracy: 73.08%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1509 | Train Accuracy: 56.32% Test Accuracy: 73.25%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1267 | Train Accuracy: 59.93% Test Accuracy: 97.42%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1236 | Train Accuracy: 60.79% Test Accuracy: 98.50%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1159 | Train Accuracy: 61.04% Test Accuracy: 98.58%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 1.5187 | Train Accuracy: 21.14% Test Accuracy: 97.50%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.5959 | Train Accuracy: 89.50% Test Accuracy: 96.75%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.4404 | Train Accuracy: 93.36% Test Accuracy: 97.08%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.3352 | Train Accuracy: 95.64% Test Accuracy: 97.42%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2715 | Train Accuracy: 96.43% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2222 | Train Accuracy: 97.14% Test Accuracy: 97.75%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1865 | Train Accuracy: 97.32% Test Accuracy: 97.92%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1681 | Train Accuracy: 97.57% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1470 | Train Accuracy: 97.61% Test Accuracy: 98.17%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1315 | Train Accuracy: 97.86% Test Accuracy: 98.25%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1246 | Train Accuracy: 97.61% Test Accuracy: 98.33%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1138 | Train Accuracy: 97.82% Test Accuracy: 98.50%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1042 | Train Accuracy: 97.96% Test Accuracy: 98.67%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0980 | Train Accuracy: 97.93% Test Accuracy: 98.75%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0941 | Train Accuracy: 98.07% Test Accuracy: 98.83%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0871 | Train Accuracy: 98.29% Test Accuracy: 98.83%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0822 | Train Accuracy: 98.57% Test Accuracy: 98.83%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0842 | Train Accuracy: 98.29% Test Accuracy: 98.92%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0770 | Train Accuracy: 98.54% Test Accuracy: 98.92%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0752 | Train Accuracy: 98.46% Test Accuracy: 99.00%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 1.4635 | Train Accuracy: 23.93% Test Accuracy: 72.25%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.9365 | Train Accuracy: 61.68% Test Accuracy: 52.83%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.5754 | Train Accuracy: 71.39% Test Accuracy: 96.75%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.3402 | Train Accuracy: 93.96% Test Accuracy: 80.92%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.3074 | Train Accuracy: 90.93% Test Accuracy: 88.58%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2459 | Train Accuracy: 93.54% Test Accuracy: 97.17%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1814 | Train Accuracy: 96.14% Test Accuracy: 97.50%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1500 | Train Accuracy: 97.04% Test Accuracy: 97.50%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1334 | Train Accuracy: 97.07% Test Accuracy: 97.58%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1242 | Train Accuracy: 97.36% Test Accuracy: 97.67%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1172 | Train Accuracy: 97.50% Test Accuracy: 97.67%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1070 | Train Accuracy: 97.46% Test Accuracy: 97.75%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1036 | Train Accuracy: 97.43% Test Accuracy: 97.83%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0980 | Train Accuracy: 97.75% Test Accuracy: 97.75%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0892 | Train Accuracy: 97.75% Test Accuracy: 97.92%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0856 | Train Accuracy: 97.79% Test Accuracy: 98.00%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0816 | Train Accuracy: 97.71% Test Accuracy: 98.25%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0796 | Train Accuracy: 97.86% Test Accuracy: 98.25%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0793 | Train Accuracy: 97.75% Test Accuracy: 98.42%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0784 | Train Accuracy: 97.96% Test Accuracy: 98.58%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.5041 | Train Accuracy: 23.29% Test Accuracy: 93.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.9387 | Train Accuracy: 69.18% Test Accuracy: 95.67%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.6922 | Train Accuracy: 85.36% Test Accuracy: 96.83%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.5664 | Train Accuracy: 91.68% Test Accuracy: 97.25%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.5120 | Train Accuracy: 93.39% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.4595 | Train Accuracy: 95.43% Test Accuracy: 97.75%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.4188 | Train Accuracy: 95.75% Test Accuracy: 97.83%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3886 | Train Accuracy: 96.64% Test Accuracy: 97.92%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3674 | Train Accuracy: 96.86% Test Accuracy: 97.92%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3396 | Train Accuracy: 97.29% Test Accuracy: 98.08%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3237 | Train Accuracy: 97.14% Test Accuracy: 98.17%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3051 | Train Accuracy: 97.50% Test Accuracy: 98.25%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2964 | Train Accuracy: 97.43% Test Accuracy: 98.42%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2801 | Train Accuracy: 97.43% Test Accuracy: 98.50%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2651 | Train Accuracy: 97.64% Test Accuracy: 98.50%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2586 | Train Accuracy: 97.61% Test Accuracy: 98.50%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2515 | Train Accuracy: 97.64% Test Accuracy: 98.50%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2425 | Train Accuracy: 97.86% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2329 | Train Accuracy: 97.82% Test Accuracy: 98.75%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2253 | Train Accuracy: 97.89% Test Accuracy: 98.67%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.4093 | Train Accuracy: 21.00% Test Accuracy: 79.25%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.9893 | Train Accuracy: 64.46% Test Accuracy: 97.08%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.5328 | Train Accuracy: 83.21% Test Accuracy: 97.50%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.3042 | Train Accuracy: 90.89% Test Accuracy: 97.75%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1739 | Train Accuracy: 95.21% Test Accuracy: 97.92%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1425 | Train Accuracy: 96.71% Test Accuracy: 98.33%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1104 | Train Accuracy: 97.36% Test Accuracy: 99.00%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1114 | Train Accuracy: 97.25% Test Accuracy: 99.17%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1022 | Train Accuracy: 97.54% Test Accuracy: 99.17%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0856 | Train Accuracy: 98.29% Test Accuracy: 99.25%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0804 | Train Accuracy: 98.57% Test Accuracy: 99.33%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0683 | Train Accuracy: 98.64% Test Accuracy: 99.33%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0578 | Train Accuracy: 98.82% Test Accuracy: 99.25%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0487 | Train Accuracy: 99.00% Test Accuracy: 99.33%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0522 | Train Accuracy: 99.04% Test Accuracy: 99.17%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0363 | Train Accuracy: 99.18% Test Accuracy: 99.17%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0330 | Train Accuracy: 99.36% Test Accuracy: 99.25%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0370 | Train Accuracy: 99.11% Test Accuracy: 99.33%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0309 | Train Accuracy: 99.39% Test Accuracy: 99.42%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0231 | Train Accuracy: 99.43% Test Accuracy: 99.42%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.3926 | Train Accuracy: 29.11% Test Accuracy: 49.83%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 15.6005 | Train Accuracy: 46.00% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 47.5409 | Train Accuracy: 33.93% Test Accuracy: 32.50%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 5.2453 | Train Accuracy: 43.89% Test Accuracy: 87.50%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.1620 | Train Accuracy: 66.68% Test Accuracy: 72.33%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.2931 | Train Accuracy: 62.50% Test Accuracy: 77.83%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.0466 | Train Accuracy: 68.04% Test Accuracy: 97.83%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.7321 | Train Accuracy: 76.57% Test Accuracy: 97.83%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5931 | Train Accuracy: 83.43% Test Accuracy: 97.58%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.3776 | Train Accuracy: 89.64% Test Accuracy: 97.50%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.3291 | Train Accuracy: 92.00% Test Accuracy: 97.50%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.3098 | Train Accuracy: 91.43% Test Accuracy: 97.50%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2426 | Train Accuracy: 92.14% Test Accuracy: 97.83%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2366 | Train Accuracy: 93.39% Test Accuracy: 98.17%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.3115 | Train Accuracy: 91.79% Test Accuracy: 98.25%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2969 | Train Accuracy: 92.46% Test Accuracy: 97.75%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2323 | Train Accuracy: 92.79% Test Accuracy: 97.42%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2380 | Train Accuracy: 94.00% Test Accuracy: 97.33%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.2035 | Train Accuracy: 94.04% Test Accuracy: 97.33%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.1987 | Train Accuracy: 95.32% Test Accuracy: 97.42%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.3817 | Train Accuracy: 31.00% Test Accuracy: 68.33%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.2908 | Train Accuracy: 53.86% Test Accuracy: 74.67%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.2103 | Train Accuracy: 63.54% Test Accuracy: 76.83%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1339 | Train Accuracy: 67.71% Test Accuracy: 80.42%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.0523 | Train Accuracy: 72.79% Test Accuracy: 84.33%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.9825 | Train Accuracy: 73.71% Test Accuracy: 87.00%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.9173 | Train Accuracy: 76.71% Test Accuracy: 89.67%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.8531 | Train Accuracy: 77.82% Test Accuracy: 92.58%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.7848 | Train Accuracy: 80.43% Test Accuracy: 94.08%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.7248 | Train Accuracy: 82.50% Test Accuracy: 95.67%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.6583 | Train Accuracy: 84.68% Test Accuracy: 96.58%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.6089 | Train Accuracy: 86.29% Test Accuracy: 97.00%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.5486 | Train Accuracy: 88.11% Test Accuracy: 97.08%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.5130 | Train Accuracy: 88.96% Test Accuracy: 97.17%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.4732 | Train Accuracy: 90.43% Test Accuracy: 97.33%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.4271 | Train Accuracy: 91.68% Test Accuracy: 97.50%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3818 | Train Accuracy: 92.75% Test Accuracy: 97.67%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3502 | Train Accuracy: 93.75% Test Accuracy: 97.67%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3180 | Train Accuracy: 93.82% Test Accuracy: 97.67%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2900 | Train Accuracy: 94.61% Test Accuracy: 97.75%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4543 | Train Accuracy: 24.39% Test Accuracy: 49.58%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3824 | Train Accuracy: 29.61% Test Accuracy: 65.83%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3473 | Train Accuracy: 33.61% Test Accuracy: 48.25%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3214 | Train Accuracy: 37.61% Test Accuracy: 50.83%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2880 | Train Accuracy: 42.11% Test Accuracy: 72.92%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2588 | Train Accuracy: 45.68% Test Accuracy: 73.08%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2118 | Train Accuracy: 50.68% Test Accuracy: 73.00%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1619 | Train Accuracy: 56.32% Test Accuracy: 94.75%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1234 | Train Accuracy: 60.71% Test Accuracy: 97.50%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0674 | Train Accuracy: 66.11% Test Accuracy: 97.67%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0235 | Train Accuracy: 70.04% Test Accuracy: 97.67%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9775 | Train Accuracy: 71.64% Test Accuracy: 97.67%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9366 | Train Accuracy: 72.96% Test Accuracy: 97.75%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8926 | Train Accuracy: 76.18% Test Accuracy: 97.75%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8512 | Train Accuracy: 77.14% Test Accuracy: 97.83%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8165 | Train Accuracy: 78.32% Test Accuracy: 97.92%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7772 | Train Accuracy: 81.68% Test Accuracy: 97.83%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7399 | Train Accuracy: 85.21% Test Accuracy: 97.92%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7072 | Train Accuracy: 86.46% Test Accuracy: 97.92%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6604 | Train Accuracy: 89.29% Test Accuracy: 98.08%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4868 | Train Accuracy: 24.04% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.7486 | Train Accuracy: 25.86% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.5120 | Train Accuracy: 30.50% Test Accuracy: 50.00%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.2760 | Train Accuracy: 38.18% Test Accuracy: 73.00%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.1113 | Train Accuracy: 53.93% Test Accuracy: 49.83%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.0174 | Train Accuracy: 56.21% Test Accuracy: 49.75%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9330 | Train Accuracy: 57.39% Test Accuracy: 74.75%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8786 | Train Accuracy: 59.89% Test Accuracy: 76.08%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8259 | Train Accuracy: 64.86% Test Accuracy: 97.33%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7672 | Train Accuracy: 71.32% Test Accuracy: 97.58%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7128 | Train Accuracy: 78.61% Test Accuracy: 97.58%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6527 | Train Accuracy: 84.21% Test Accuracy: 97.67%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5906 | Train Accuracy: 87.21% Test Accuracy: 97.67%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5167 | Train Accuracy: 93.50% Test Accuracy: 97.67%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4536 | Train Accuracy: 95.86% Test Accuracy: 97.67%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3966 | Train Accuracy: 96.89% Test Accuracy: 97.67%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3408 | Train Accuracy: 97.14% Test Accuracy: 97.67%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2962 | Train Accuracy: 97.21% Test Accuracy: 97.67%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2633 | Train Accuracy: 97.32% Test Accuracy: 97.67%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2287 | Train Accuracy: 97.25% Test Accuracy: 97.67%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4271 | Train Accuracy: 24.75% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4168 | Train Accuracy: 25.57% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4085 | Train Accuracy: 26.82% Test Accuracy: 25.00%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3954 | Train Accuracy: 27.32% Test Accuracy: 25.00%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3946 | Train Accuracy: 28.21% Test Accuracy: 26.75%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3849 | Train Accuracy: 28.57% Test Accuracy: 66.25%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3824 | Train Accuracy: 28.57% Test Accuracy: 94.00%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3741 | Train Accuracy: 30.82% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3770 | Train Accuracy: 30.29% Test Accuracy: 97.08%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3728 | Train Accuracy: 30.71% Test Accuracy: 95.75%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3630 | Train Accuracy: 31.18% Test Accuracy: 93.67%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3544 | Train Accuracy: 32.79% Test Accuracy: 92.08%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3543 | Train Accuracy: 33.29% Test Accuracy: 91.17%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3495 | Train Accuracy: 33.82% Test Accuracy: 91.00%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3423 | Train Accuracy: 34.61% Test Accuracy: 92.00%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3345 | Train Accuracy: 35.54% Test Accuracy: 93.08%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3344 | Train Accuracy: 35.61% Test Accuracy: 94.25%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3349 | Train Accuracy: 35.29% Test Accuracy: 95.00%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3262 | Train Accuracy: 36.86% Test Accuracy: 96.00%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3221 | Train Accuracy: 37.79% Test Accuracy: 96.33%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 1.3606 | Train Accuracy: 30.93% Test Accuracy: 88.83%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.7018 | Train Accuracy: 78.86% Test Accuracy: 96.83%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.5334 | Train Accuracy: 91.50% Test Accuracy: 97.33%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.3747 | Train Accuracy: 96.29% Test Accuracy: 97.50%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.2799 | Train Accuracy: 96.93% Test Accuracy: 97.42%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.2181 | Train Accuracy: 97.07% Test Accuracy: 97.42%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1773 | Train Accuracy: 97.18% Test Accuracy: 97.50%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1510 | Train Accuracy: 97.14% Test Accuracy: 97.58%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1310 | Train Accuracy: 97.36% Test Accuracy: 97.58%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1114 | Train Accuracy: 97.43% Test Accuracy: 97.75%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0976 | Train Accuracy: 97.82% Test Accuracy: 98.42%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0888 | Train Accuracy: 98.25% Test Accuracy: 98.75%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0820 | Train Accuracy: 98.14% Test Accuracy: 98.92%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0718 | Train Accuracy: 98.61% Test Accuracy: 99.00%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0684 | Train Accuracy: 98.43% Test Accuracy: 99.25%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0639 | Train Accuracy: 98.54% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0558 | Train Accuracy: 98.82% Test Accuracy: 99.25%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0510 | Train Accuracy: 98.79% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0495 | Train Accuracy: 98.75% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0455 | Train Accuracy: 99.14% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.3913 | Train Accuracy: 25.93% Test Accuracy: 50.25%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.0054 | Train Accuracy: 51.54% Test Accuracy: 54.92%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.9384 | Train Accuracy: 53.75% Test Accuracy: 49.83%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.9832 | Train Accuracy: 50.46% Test Accuracy: 65.17%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.8489 | Train Accuracy: 58.96% Test Accuracy: 90.17%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.7542 | Train Accuracy: 62.14% Test Accuracy: 72.17%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.6692 | Train Accuracy: 70.96% Test Accuracy: 72.25%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.5845 | Train Accuracy: 74.96% Test Accuracy: 96.67%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.4612 | Train Accuracy: 85.11% Test Accuracy: 97.25%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3712 | Train Accuracy: 93.36% Test Accuracy: 97.33%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3051 | Train Accuracy: 95.79% Test Accuracy: 97.33%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2590 | Train Accuracy: 96.93% Test Accuracy: 97.33%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2259 | Train Accuracy: 97.00% Test Accuracy: 97.33%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1991 | Train Accuracy: 97.07% Test Accuracy: 97.33%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1800 | Train Accuracy: 97.18% Test Accuracy: 97.33%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1579 | Train Accuracy: 97.18% Test Accuracy: 97.33%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1531 | Train Accuracy: 97.07% Test Accuracy: 97.33%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1433 | Train Accuracy: 97.14% Test Accuracy: 97.25%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1411 | Train Accuracy: 97.07% Test Accuracy: 97.33%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1412 | Train Accuracy: 97.11% Test Accuracy: 97.33%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.4301 | Train Accuracy: 20.96% Test Accuracy: 88.25%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.0915 | Train Accuracy: 67.54% Test Accuracy: 94.25%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.8998 | Train Accuracy: 79.43% Test Accuracy: 96.17%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.7831 | Train Accuracy: 85.43% Test Accuracy: 96.83%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.7041 | Train Accuracy: 88.07% Test Accuracy: 97.00%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.6450 | Train Accuracy: 91.50% Test Accuracy: 97.17%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.5963 | Train Accuracy: 92.46% Test Accuracy: 97.17%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.5529 | Train Accuracy: 94.21% Test Accuracy: 97.25%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.5163 | Train Accuracy: 95.18% Test Accuracy: 97.25%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.4850 | Train Accuracy: 95.68% Test Accuracy: 97.33%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.4555 | Train Accuracy: 96.21% Test Accuracy: 97.67%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.4276 | Train Accuracy: 96.57% Test Accuracy: 97.75%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3983 | Train Accuracy: 96.79% Test Accuracy: 97.83%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3776 | Train Accuracy: 97.14% Test Accuracy: 97.92%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3567 | Train Accuracy: 97.07% Test Accuracy: 97.92%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3412 | Train Accuracy: 97.04% Test Accuracy: 97.92%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3249 | Train Accuracy: 97.29% Test Accuracy: 97.92%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3084 | Train Accuracy: 97.32% Test Accuracy: 98.00%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2933 | Train Accuracy: 97.21% Test Accuracy: 98.33%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2753 | Train Accuracy: 97.43% Test Accuracy: 98.33%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.6666 | Train Accuracy: 25.46% Test Accuracy: 95.75%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.4721 | Train Accuracy: 33.36% Test Accuracy: 98.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.3172 | Train Accuracy: 39.18% Test Accuracy: 98.08%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.2188 | Train Accuracy: 43.93% Test Accuracy: 98.08%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.1000 | Train Accuracy: 51.71% Test Accuracy: 98.08%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.0140 | Train Accuracy: 56.75% Test Accuracy: 98.08%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.9156 | Train Accuracy: 63.79% Test Accuracy: 98.08%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.8471 | Train Accuracy: 69.14% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.7910 | Train Accuracy: 72.14% Test Accuracy: 98.00%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.7160 | Train Accuracy: 78.11% Test Accuracy: 98.08%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.6576 | Train Accuracy: 81.00% Test Accuracy: 98.08%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.6114 | Train Accuracy: 83.79% Test Accuracy: 98.17%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.5862 | Train Accuracy: 85.57% Test Accuracy: 98.25%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.5467 | Train Accuracy: 87.11% Test Accuracy: 98.25%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.4965 | Train Accuracy: 89.54% Test Accuracy: 98.25%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.4583 | Train Accuracy: 90.46% Test Accuracy: 98.42%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.4494 | Train Accuracy: 91.21% Test Accuracy: 98.42%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.4200 | Train Accuracy: 92.61% Test Accuracy: 98.42%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.3994 | Train Accuracy: 93.54% Test Accuracy: 98.42%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.3750 | Train Accuracy: 93.75% Test Accuracy: 98.42%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 1.6684 | Train Accuracy: 23.46% Test Accuracy: 54.67%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 1.3673 | Train Accuracy: 34.39% Test Accuracy: 49.83%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.8919 | Train Accuracy: 68.93% Test Accuracy: 49.83%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.6936 | Train Accuracy: 82.32% Test Accuracy: 50.17%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.5698 | Train Accuracy: 88.36% Test Accuracy: 53.58%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.4710 | Train Accuracy: 91.21% Test Accuracy: 60.17%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.3993 | Train Accuracy: 92.29% Test Accuracy: 66.58%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.3279 | Train Accuracy: 93.43% Test Accuracy: 71.08%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.2889 | Train Accuracy: 94.57% Test Accuracy: 90.17%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.2409 | Train Accuracy: 95.18% Test Accuracy: 95.58%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.2028 | Train Accuracy: 95.64% Test Accuracy: 96.42%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1938 | Train Accuracy: 96.14% Test Accuracy: 97.17%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1700 | Train Accuracy: 96.39% Test Accuracy: 97.33%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1522 | Train Accuracy: 96.39% Test Accuracy: 97.50%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1517 | Train Accuracy: 96.64% Test Accuracy: 97.58%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1412 | Train Accuracy: 97.07% Test Accuracy: 97.75%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1355 | Train Accuracy: 96.71% Test Accuracy: 98.08%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1352 | Train Accuracy: 96.93% Test Accuracy: 98.17%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1057 | Train Accuracy: 97.46% Test Accuracy: 98.25%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1161 | Train Accuracy: 97.14% Test Accuracy: 98.50%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.6109 | Train Accuracy: 25.93% Test Accuracy: 49.58%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.5315 | Train Accuracy: 29.36% Test Accuracy: 50.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.4516 | Train Accuracy: 32.71% Test Accuracy: 50.17%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.3968 | Train Accuracy: 34.39% Test Accuracy: 51.42%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.3569 | Train Accuracy: 35.25% Test Accuracy: 55.00%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.3288 | Train Accuracy: 36.61% Test Accuracy: 59.58%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.3096 | Train Accuracy: 38.00% Test Accuracy: 63.42%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.2762 | Train Accuracy: 38.96% Test Accuracy: 75.67%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.2887 | Train Accuracy: 39.39% Test Accuracy: 89.33%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.2664 | Train Accuracy: 39.14% Test Accuracy: 92.17%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.2440 | Train Accuracy: 41.14% Test Accuracy: 93.58%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.2298 | Train Accuracy: 41.18% Test Accuracy: 94.42%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.2060 | Train Accuracy: 41.68% Test Accuracy: 95.08%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.2145 | Train Accuracy: 42.89% Test Accuracy: 95.50%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.1680 | Train Accuracy: 46.21% Test Accuracy: 96.08%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.1567 | Train Accuracy: 46.79% Test Accuracy: 96.42%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.1483 | Train Accuracy: 45.82% Test Accuracy: 96.58%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.1248 | Train Accuracy: 49.50% Test Accuracy: 96.75%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.1266 | Train Accuracy: 48.75% Test Accuracy: 96.75%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.0991 | Train Accuracy: 49.61% Test Accuracy: 96.92%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.5693 | Train Accuracy: 24.57% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.5110 | Train Accuracy: 26.93% Test Accuracy: 50.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4866 | Train Accuracy: 27.54% Test Accuracy: 49.83%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4380 | Train Accuracy: 30.71% Test Accuracy: 49.75%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4294 | Train Accuracy: 31.68% Test Accuracy: 74.67%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4270 | Train Accuracy: 31.36% Test Accuracy: 74.25%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3974 | Train Accuracy: 31.89% Test Accuracy: 71.42%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3725 | Train Accuracy: 33.71% Test Accuracy: 68.92%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3428 | Train Accuracy: 36.57% Test Accuracy: 71.67%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3249 | Train Accuracy: 36.96% Test Accuracy: 78.83%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3182 | Train Accuracy: 37.14% Test Accuracy: 83.17%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2928 | Train Accuracy: 39.68% Test Accuracy: 86.92%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2744 | Train Accuracy: 40.54% Test Accuracy: 90.50%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2428 | Train Accuracy: 41.82% Test Accuracy: 93.08%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2303 | Train Accuracy: 43.39% Test Accuracy: 94.75%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1947 | Train Accuracy: 45.39% Test Accuracy: 95.58%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1836 | Train Accuracy: 46.89% Test Accuracy: 96.42%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1661 | Train Accuracy: 46.96% Test Accuracy: 96.92%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1473 | Train Accuracy: 49.57% Test Accuracy: 97.25%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1398 | Train Accuracy: 50.07% Test Accuracy: 97.50%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.5316 | Train Accuracy: 24.46% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4939 | Train Accuracy: 27.32% Test Accuracy: 56.42%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.3760 | Train Accuracy: 32.32% Test Accuracy: 65.17%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.2649 | Train Accuracy: 41.14% Test Accuracy: 58.00%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.1987 | Train Accuracy: 44.18% Test Accuracy: 60.58%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.1219 | Train Accuracy: 49.57% Test Accuracy: 80.25%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.0586 | Train Accuracy: 55.00% Test Accuracy: 55.83%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.0061 | Train Accuracy: 58.04% Test Accuracy: 57.33%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9709 | Train Accuracy: 57.61% Test Accuracy: 58.58%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9323 | Train Accuracy: 59.93% Test Accuracy: 61.50%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9088 | Train Accuracy: 61.14% Test Accuracy: 67.67%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8533 | Train Accuracy: 65.86% Test Accuracy: 91.58%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8508 | Train Accuracy: 65.89% Test Accuracy: 96.17%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8072 | Train Accuracy: 69.21% Test Accuracy: 95.50%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7757 | Train Accuracy: 71.18% Test Accuracy: 96.83%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7433 | Train Accuracy: 71.46% Test Accuracy: 97.42%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7147 | Train Accuracy: 72.57% Test Accuracy: 97.42%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6929 | Train Accuracy: 73.86% Test Accuracy: 97.58%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6701 | Train Accuracy: 73.29% Test Accuracy: 97.67%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6419 | Train Accuracy: 75.04% Test Accuracy: 97.67%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5637 | Train Accuracy: 24.57% Test Accuracy: 24.92%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5429 | Train Accuracy: 25.32% Test Accuracy: 49.42%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5262 | Train Accuracy: 26.39% Test Accuracy: 49.17%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5085 | Train Accuracy: 27.46% Test Accuracy: 49.08%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4974 | Train Accuracy: 28.29% Test Accuracy: 48.83%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4892 | Train Accuracy: 27.93% Test Accuracy: 48.83%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4850 | Train Accuracy: 28.32% Test Accuracy: 48.83%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4947 | Train Accuracy: 27.39% Test Accuracy: 48.83%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4944 | Train Accuracy: 27.57% Test Accuracy: 48.83%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4910 | Train Accuracy: 27.43% Test Accuracy: 48.83%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4668 | Train Accuracy: 29.71% Test Accuracy: 48.83%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4883 | Train Accuracy: 28.04% Test Accuracy: 48.83%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4668 | Train Accuracy: 27.89% Test Accuracy: 48.67%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4913 | Train Accuracy: 26.71% Test Accuracy: 48.67%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4664 | Train Accuracy: 29.21% Test Accuracy: 50.42%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4692 | Train Accuracy: 29.64% Test Accuracy: 53.17%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4714 | Train Accuracy: 28.21% Test Accuracy: 56.58%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4730 | Train Accuracy: 27.71% Test Accuracy: 60.17%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4414 | Train Accuracy: 29.68% Test Accuracy: 63.25%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4599 | Train Accuracy: 29.29% Test Accuracy: 65.92%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 1.6211 | Train Accuracy: 25.43% Test Accuracy: 83.25%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 1.1143 | Train Accuracy: 51.43% Test Accuracy: 94.42%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.9644 | Train Accuracy: 60.86% Test Accuracy: 97.08%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.8203 | Train Accuracy: 70.07% Test Accuracy: 97.17%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.6915 | Train Accuracy: 77.75% Test Accuracy: 97.17%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.6099 | Train Accuracy: 81.39% Test Accuracy: 97.42%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.5209 | Train Accuracy: 86.68% Test Accuracy: 97.50%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.4503 | Train Accuracy: 89.25% Test Accuracy: 97.58%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.4018 | Train Accuracy: 91.39% Test Accuracy: 97.67%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.3557 | Train Accuracy: 93.36% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.3242 | Train Accuracy: 93.89% Test Accuracy: 97.83%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2806 | Train Accuracy: 94.93% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2529 | Train Accuracy: 96.21% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2356 | Train Accuracy: 96.39% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2179 | Train Accuracy: 96.61% Test Accuracy: 98.33%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2033 | Train Accuracy: 96.71% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1773 | Train Accuracy: 97.39% Test Accuracy: 98.33%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1706 | Train Accuracy: 97.57% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1559 | Train Accuracy: 97.57% Test Accuracy: 98.50%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1507 | Train Accuracy: 97.54% Test Accuracy: 98.50%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 1.6160 | Train Accuracy: 25.11% Test Accuracy: 79.50%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 1.1385 | Train Accuracy: 48.82% Test Accuracy: 85.92%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.6916 | Train Accuracy: 70.07% Test Accuracy: 83.17%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.5528 | Train Accuracy: 78.96% Test Accuracy: 97.17%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.4192 | Train Accuracy: 87.71% Test Accuracy: 97.25%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.3128 | Train Accuracy: 93.68% Test Accuracy: 97.42%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2443 | Train Accuracy: 95.46% Test Accuracy: 97.42%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2033 | Train Accuracy: 96.61% Test Accuracy: 97.42%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1899 | Train Accuracy: 96.46% Test Accuracy: 97.50%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1714 | Train Accuracy: 96.93% Test Accuracy: 97.50%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1571 | Train Accuracy: 96.89% Test Accuracy: 97.42%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1455 | Train Accuracy: 96.89% Test Accuracy: 97.42%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1348 | Train Accuracy: 96.93% Test Accuracy: 97.33%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1324 | Train Accuracy: 96.82% Test Accuracy: 97.50%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1310 | Train Accuracy: 96.79% Test Accuracy: 97.50%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1332 | Train Accuracy: 96.89% Test Accuracy: 97.58%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1137 | Train Accuracy: 97.18% Test Accuracy: 97.75%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1132 | Train Accuracy: 97.32% Test Accuracy: 97.83%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1122 | Train Accuracy: 97.36% Test Accuracy: 97.83%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1046 | Train Accuracy: 97.79% Test Accuracy: 97.92%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.6193 | Train Accuracy: 23.96% Test Accuracy: 92.58%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.3787 | Train Accuracy: 35.61% Test Accuracy: 96.50%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.1962 | Train Accuracy: 46.50% Test Accuracy: 97.08%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.1347 | Train Accuracy: 49.50% Test Accuracy: 97.33%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.0359 | Train Accuracy: 56.61% Test Accuracy: 97.33%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.0087 | Train Accuracy: 57.82% Test Accuracy: 97.50%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.9606 | Train Accuracy: 61.36% Test Accuracy: 97.67%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.9314 | Train Accuracy: 63.32% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.9096 | Train Accuracy: 65.75% Test Accuracy: 97.75%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.8824 | Train Accuracy: 67.04% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.8479 | Train Accuracy: 69.11% Test Accuracy: 97.83%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.8299 | Train Accuracy: 70.68% Test Accuracy: 97.83%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.8084 | Train Accuracy: 71.11% Test Accuracy: 97.83%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.7770 | Train Accuracy: 73.43% Test Accuracy: 97.83%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.7788 | Train Accuracy: 73.46% Test Accuracy: 97.83%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.7378 | Train Accuracy: 75.71% Test Accuracy: 97.92%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.7236 | Train Accuracy: 76.82% Test Accuracy: 97.92%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.7076 | Train Accuracy: 78.14% Test Accuracy: 97.92%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.6899 | Train Accuracy: 79.00% Test Accuracy: 97.92%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.6706 | Train Accuracy: 80.32% Test Accuracy: 98.00%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.4816 | Train Accuracy: 25.79% Test Accuracy: 47.75%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.7315 | Train Accuracy: 31.11% Test Accuracy: 97.58%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.5615 | Train Accuracy: 38.07% Test Accuracy: 96.67%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.4282 | Train Accuracy: 42.25% Test Accuracy: 96.67%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.3102 | Train Accuracy: 45.64% Test Accuracy: 97.00%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.2279 | Train Accuracy: 48.96% Test Accuracy: 97.17%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.0712 | Train Accuracy: 55.11% Test Accuracy: 97.33%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.9752 | Train Accuracy: 58.11% Test Accuracy: 97.33%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.8347 | Train Accuracy: 65.50% Test Accuracy: 97.42%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.7572 | Train Accuracy: 69.71% Test Accuracy: 97.50%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.6565 | Train Accuracy: 73.82% Test Accuracy: 97.67%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.5856 | Train Accuracy: 77.21% Test Accuracy: 97.83%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.5491 | Train Accuracy: 78.93% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.4550 | Train Accuracy: 83.54% Test Accuracy: 98.17%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.3997 | Train Accuracy: 85.11% Test Accuracy: 98.17%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.3344 | Train Accuracy: 88.32% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.3167 | Train Accuracy: 88.86% Test Accuracy: 98.58%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.3077 | Train Accuracy: 90.64% Test Accuracy: 98.75%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.2600 | Train Accuracy: 91.71% Test Accuracy: 98.92%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.2246 | Train Accuracy: 92.43% Test Accuracy: 98.92%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.4589 | Train Accuracy: 24.25% Test Accuracy: 46.08%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 13.3560 | Train Accuracy: 24.93% Test Accuracy: 50.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 8.0584 | Train Accuracy: 46.32% Test Accuracy: 71.00%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.7441 | Train Accuracy: 42.29% Test Accuracy: 94.33%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 2.1523 | Train Accuracy: 42.39% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.8637 | Train Accuracy: 43.39% Test Accuracy: 97.42%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.4614 | Train Accuracy: 52.32% Test Accuracy: 97.33%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.1592 | Train Accuracy: 55.32% Test Accuracy: 97.17%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.0562 | Train Accuracy: 59.07% Test Accuracy: 97.08%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.9504 | Train Accuracy: 63.57% Test Accuracy: 97.17%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.9312 | Train Accuracy: 64.18% Test Accuracy: 97.42%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.8602 | Train Accuracy: 66.04% Test Accuracy: 97.33%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.7687 | Train Accuracy: 69.36% Test Accuracy: 97.25%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.7024 | Train Accuracy: 73.29% Test Accuracy: 97.58%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.7054 | Train Accuracy: 75.36% Test Accuracy: 97.75%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5977 | Train Accuracy: 77.43% Test Accuracy: 97.75%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5829 | Train Accuracy: 80.54% Test Accuracy: 97.75%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5577 | Train Accuracy: 81.00% Test Accuracy: 98.17%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5583 | Train Accuracy: 81.82% Test Accuracy: 98.33%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.4934 | Train Accuracy: 83.21% Test Accuracy: 98.67%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.4713 | Train Accuracy: 25.14% Test Accuracy: 47.75%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.4003 | Train Accuracy: 28.29% Test Accuracy: 61.75%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.3475 | Train Accuracy: 32.64% Test Accuracy: 69.33%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.3385 | Train Accuracy: 34.36% Test Accuracy: 72.58%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.3017 | Train Accuracy: 37.14% Test Accuracy: 72.92%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.3012 | Train Accuracy: 38.11% Test Accuracy: 73.67%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.2792 | Train Accuracy: 39.68% Test Accuracy: 92.92%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.2662 | Train Accuracy: 39.25% Test Accuracy: 98.08%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.2491 | Train Accuracy: 41.36% Test Accuracy: 98.08%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.2391 | Train Accuracy: 41.79% Test Accuracy: 98.08%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.2228 | Train Accuracy: 43.54% Test Accuracy: 97.92%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1883 | Train Accuracy: 45.93% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1826 | Train Accuracy: 45.39% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1638 | Train Accuracy: 46.29% Test Accuracy: 97.92%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1392 | Train Accuracy: 47.93% Test Accuracy: 97.92%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1462 | Train Accuracy: 47.50% Test Accuracy: 97.92%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1318 | Train Accuracy: 48.25% Test Accuracy: 98.00%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1039 | Train Accuracy: 49.57% Test Accuracy: 97.92%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.0973 | Train Accuracy: 50.93% Test Accuracy: 97.92%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.0947 | Train Accuracy: 51.50% Test Accuracy: 97.92%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.5501 | Train Accuracy: 23.46% Test Accuracy: 49.67%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4874 | Train Accuracy: 27.93% Test Accuracy: 77.25%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4715 | Train Accuracy: 27.64% Test Accuracy: 48.25%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4266 | Train Accuracy: 29.14% Test Accuracy: 48.42%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3940 | Train Accuracy: 32.00% Test Accuracy: 48.33%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3836 | Train Accuracy: 31.14% Test Accuracy: 48.25%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3334 | Train Accuracy: 34.61% Test Accuracy: 51.58%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.3157 | Train Accuracy: 36.82% Test Accuracy: 93.33%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2673 | Train Accuracy: 40.96% Test Accuracy: 97.33%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2455 | Train Accuracy: 43.50% Test Accuracy: 97.67%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.2063 | Train Accuracy: 44.61% Test Accuracy: 97.50%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1703 | Train Accuracy: 48.71% Test Accuracy: 97.25%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1511 | Train Accuracy: 49.79% Test Accuracy: 97.08%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1132 | Train Accuracy: 51.96% Test Accuracy: 96.83%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0750 | Train Accuracy: 55.71% Test Accuracy: 96.75%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0471 | Train Accuracy: 55.68% Test Accuracy: 96.83%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0124 | Train Accuracy: 57.79% Test Accuracy: 97.00%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9983 | Train Accuracy: 57.96% Test Accuracy: 97.08%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9535 | Train Accuracy: 60.18% Test Accuracy: 97.25%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9390 | Train Accuracy: 59.32% Test Accuracy: 97.42%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.5269 | Train Accuracy: 25.18% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.6036 | Train Accuracy: 25.61% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4007 | Train Accuracy: 29.11% Test Accuracy: 49.83%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.2865 | Train Accuracy: 40.64% Test Accuracy: 51.75%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.1767 | Train Accuracy: 47.54% Test Accuracy: 50.00%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.0650 | Train Accuracy: 50.36% Test Accuracy: 50.00%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9711 | Train Accuracy: 51.46% Test Accuracy: 50.00%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8989 | Train Accuracy: 50.86% Test Accuracy: 50.08%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8486 | Train Accuracy: 52.89% Test Accuracy: 49.83%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8240 | Train Accuracy: 53.68% Test Accuracy: 47.83%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8114 | Train Accuracy: 51.39% Test Accuracy: 47.83%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8061 | Train Accuracy: 54.39% Test Accuracy: 48.33%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7948 | Train Accuracy: 55.29% Test Accuracy: 72.75%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7807 | Train Accuracy: 57.32% Test Accuracy: 51.42%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7663 | Train Accuracy: 59.14% Test Accuracy: 74.75%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7692 | Train Accuracy: 59.46% Test Accuracy: 74.83%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7459 | Train Accuracy: 61.00% Test Accuracy: 96.50%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7269 | Train Accuracy: 66.18% Test Accuracy: 97.42%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7098 | Train Accuracy: 70.07% Test Accuracy: 97.50%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6596 | Train Accuracy: 75.36% Test Accuracy: 97.50%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5467 | Train Accuracy: 25.89% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5488 | Train Accuracy: 26.18% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5389 | Train Accuracy: 26.64% Test Accuracy: 25.00%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5522 | Train Accuracy: 24.07% Test Accuracy: 25.00%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5249 | Train Accuracy: 25.25% Test Accuracy: 25.00%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5191 | Train Accuracy: 27.00% Test Accuracy: 25.00%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5077 | Train Accuracy: 25.68% Test Accuracy: 25.00%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5027 | Train Accuracy: 27.61% Test Accuracy: 25.00%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5050 | Train Accuracy: 25.68% Test Accuracy: 25.00%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5181 | Train Accuracy: 24.68% Test Accuracy: 25.00%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4909 | Train Accuracy: 27.29% Test Accuracy: 25.00%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4686 | Train Accuracy: 27.21% Test Accuracy: 25.00%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4744 | Train Accuracy: 28.29% Test Accuracy: 25.00%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4794 | Train Accuracy: 28.29% Test Accuracy: 25.00%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4642 | Train Accuracy: 27.36% Test Accuracy: 25.00%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4770 | Train Accuracy: 26.86% Test Accuracy: 25.00%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4626 | Train Accuracy: 28.07% Test Accuracy: 25.00%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4427 | Train Accuracy: 28.82% Test Accuracy: 25.00%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4388 | Train Accuracy: 29.54% Test Accuracy: 25.00%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4387 | Train Accuracy: 28.43% Test Accuracy: 25.00%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 1.5048 | Train Accuracy: 25.82% Test Accuracy: 92.92%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 1.1036 | Train Accuracy: 51.43% Test Accuracy: 96.92%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.9532 | Train Accuracy: 60.82% Test Accuracy: 97.17%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.8436 | Train Accuracy: 66.61% Test Accuracy: 97.17%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.7322 | Train Accuracy: 72.36% Test Accuracy: 97.17%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.6339 | Train Accuracy: 78.57% Test Accuracy: 97.17%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.5559 | Train Accuracy: 81.64% Test Accuracy: 97.17%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.4813 | Train Accuracy: 86.07% Test Accuracy: 97.25%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.4260 | Train Accuracy: 89.18% Test Accuracy: 97.25%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.3812 | Train Accuracy: 90.96% Test Accuracy: 97.33%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.3452 | Train Accuracy: 92.43% Test Accuracy: 97.33%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.3012 | Train Accuracy: 94.04% Test Accuracy: 97.33%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.2710 | Train Accuracy: 94.54% Test Accuracy: 97.33%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.2410 | Train Accuracy: 94.96% Test Accuracy: 97.33%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.2356 | Train Accuracy: 95.57% Test Accuracy: 97.33%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.2128 | Train Accuracy: 95.89% Test Accuracy: 97.33%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.2054 | Train Accuracy: 95.96% Test Accuracy: 97.25%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1903 | Train Accuracy: 96.21% Test Accuracy: 97.33%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1683 | Train Accuracy: 96.75% Test Accuracy: 97.42%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1685 | Train Accuracy: 96.46% Test Accuracy: 97.58%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.4940 | Train Accuracy: 26.64% Test Accuracy: 86.17%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.3051 | Train Accuracy: 39.29% Test Accuracy: 58.67%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.8992 | Train Accuracy: 55.36% Test Accuracy: 72.83%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.9065 | Train Accuracy: 54.36% Test Accuracy: 97.33%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.7696 | Train Accuracy: 62.32% Test Accuracy: 94.08%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.6663 | Train Accuracy: 70.25% Test Accuracy: 97.08%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.5561 | Train Accuracy: 79.11% Test Accuracy: 97.50%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.4408 | Train Accuracy: 88.79% Test Accuracy: 97.50%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3598 | Train Accuracy: 92.25% Test Accuracy: 97.50%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2935 | Train Accuracy: 94.61% Test Accuracy: 97.50%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2429 | Train Accuracy: 95.96% Test Accuracy: 97.50%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2237 | Train Accuracy: 96.18% Test Accuracy: 97.50%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1884 | Train Accuracy: 96.39% Test Accuracy: 97.58%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1865 | Train Accuracy: 96.36% Test Accuracy: 97.42%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1771 | Train Accuracy: 96.64% Test Accuracy: 97.42%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1689 | Train Accuracy: 96.61% Test Accuracy: 97.42%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1798 | Train Accuracy: 96.43% Test Accuracy: 97.33%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1784 | Train Accuracy: 96.14% Test Accuracy: 97.33%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1756 | Train Accuracy: 96.57% Test Accuracy: 97.33%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1717 | Train Accuracy: 96.64% Test Accuracy: 97.33%\n",
      "Epoch [1/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.5180 | Train Accuracy: 24.18% Test Accuracy: 93.92%\n",
      "Epoch [2/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.3284 | Train Accuracy: 36.11% Test Accuracy: 93.75%\n",
      "Epoch [3/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.1723 | Train Accuracy: 47.61% Test Accuracy: 94.75%\n",
      "Epoch [4/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.0972 | Train Accuracy: 53.04% Test Accuracy: 95.17%\n",
      "Epoch [5/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.0368 | Train Accuracy: 56.57% Test Accuracy: 96.08%\n",
      "Epoch [6/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.0005 | Train Accuracy: 59.43% Test Accuracy: 96.75%\n",
      "Epoch [7/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.9678 | Train Accuracy: 60.93% Test Accuracy: 97.00%\n",
      "Epoch [8/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.9493 | Train Accuracy: 62.61% Test Accuracy: 97.08%\n",
      "Epoch [9/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.9024 | Train Accuracy: 66.36% Test Accuracy: 97.25%\n",
      "Epoch [10/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.8913 | Train Accuracy: 65.93% Test Accuracy: 97.33%\n",
      "Epoch [11/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.8607 | Train Accuracy: 68.86% Test Accuracy: 97.50%\n",
      "Epoch [12/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.8199 | Train Accuracy: 72.21% Test Accuracy: 97.67%\n",
      "Epoch [13/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.8153 | Train Accuracy: 72.54% Test Accuracy: 97.83%\n",
      "Epoch [14/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.7861 | Train Accuracy: 74.21% Test Accuracy: 97.83%\n",
      "Epoch [15/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.7572 | Train Accuracy: 75.75% Test Accuracy: 97.83%\n",
      "Epoch [16/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.7385 | Train Accuracy: 76.11% Test Accuracy: 97.83%\n",
      "Epoch [17/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.7303 | Train Accuracy: 78.71% Test Accuracy: 97.83%\n",
      "Epoch [18/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.7043 | Train Accuracy: 80.54% Test Accuracy: 97.83%\n",
      "Epoch [19/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.6921 | Train Accuracy: 80.11% Test Accuracy: 97.83%\n",
      "Epoch [20/20] | Hidden: [512, 256, 128] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.6812 | Train Accuracy: 80.25% Test Accuracy: 97.92%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.5729 | Train Accuracy: 20.50% Test Accuracy: 97.50%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2078 | Train Accuracy: 96.71% Test Accuracy: 72.50%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1007 | Train Accuracy: 97.68% Test Accuracy: 73.58%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0695 | Train Accuracy: 98.21% Test Accuracy: 94.58%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0558 | Train Accuracy: 98.54% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0481 | Train Accuracy: 98.89% Test Accuracy: 98.42%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0432 | Train Accuracy: 98.96% Test Accuracy: 98.92%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0396 | Train Accuracy: 98.93% Test Accuracy: 98.92%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0363 | Train Accuracy: 99.18% Test Accuracy: 99.00%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0330 | Train Accuracy: 99.18% Test Accuracy: 99.00%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0308 | Train Accuracy: 99.36% Test Accuracy: 99.00%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0273 | Train Accuracy: 99.39% Test Accuracy: 99.08%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0268 | Train Accuracy: 99.43% Test Accuracy: 99.17%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0248 | Train Accuracy: 99.46% Test Accuracy: 99.17%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0223 | Train Accuracy: 99.46% Test Accuracy: 99.25%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0221 | Train Accuracy: 99.46% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0206 | Train Accuracy: 99.54% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0195 | Train Accuracy: 99.57% Test Accuracy: 99.17%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0185 | Train Accuracy: 99.68% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0180 | Train Accuracy: 99.64% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 1.4665 | Train Accuracy: 21.39% Test Accuracy: 72.50%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.4914 | Train Accuracy: 80.25% Test Accuracy: 53.08%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.2017 | Train Accuracy: 93.04% Test Accuracy: 82.92%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1157 | Train Accuracy: 96.43% Test Accuracy: 87.75%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0814 | Train Accuracy: 97.61% Test Accuracy: 80.58%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0669 | Train Accuracy: 98.14% Test Accuracy: 77.75%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0634 | Train Accuracy: 98.21% Test Accuracy: 82.83%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0586 | Train Accuracy: 98.32% Test Accuracy: 89.83%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0575 | Train Accuracy: 98.21% Test Accuracy: 94.83%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0510 | Train Accuracy: 98.46% Test Accuracy: 97.08%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0478 | Train Accuracy: 98.32% Test Accuracy: 97.92%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0398 | Train Accuracy: 98.54% Test Accuracy: 98.58%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0344 | Train Accuracy: 98.89% Test Accuracy: 98.92%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0343 | Train Accuracy: 98.89% Test Accuracy: 99.00%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0309 | Train Accuracy: 99.14% Test Accuracy: 99.25%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0296 | Train Accuracy: 99.14% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0293 | Train Accuracy: 99.04% Test Accuracy: 99.25%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0297 | Train Accuracy: 99.04% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0267 | Train Accuracy: 99.18% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0252 | Train Accuracy: 99.29% Test Accuracy: 99.17%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.3322 | Train Accuracy: 31.61% Test Accuracy: 97.25%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4015 | Train Accuracy: 97.36% Test Accuracy: 97.58%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1893 | Train Accuracy: 97.96% Test Accuracy: 97.75%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1271 | Train Accuracy: 98.14% Test Accuracy: 97.92%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0975 | Train Accuracy: 98.25% Test Accuracy: 98.17%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0805 | Train Accuracy: 98.64% Test Accuracy: 98.42%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0692 | Train Accuracy: 98.82% Test Accuracy: 98.67%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0614 | Train Accuracy: 98.96% Test Accuracy: 98.83%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0576 | Train Accuracy: 99.04% Test Accuracy: 98.92%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0515 | Train Accuracy: 99.14% Test Accuracy: 98.92%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0477 | Train Accuracy: 99.14% Test Accuracy: 99.08%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0454 | Train Accuracy: 99.18% Test Accuracy: 99.17%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0428 | Train Accuracy: 99.18% Test Accuracy: 99.17%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0398 | Train Accuracy: 99.21% Test Accuracy: 99.25%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0372 | Train Accuracy: 99.39% Test Accuracy: 99.25%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0365 | Train Accuracy: 99.29% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0329 | Train Accuracy: 99.39% Test Accuracy: 99.25%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0323 | Train Accuracy: 99.43% Test Accuracy: 99.33%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0302 | Train Accuracy: 99.50% Test Accuracy: 99.33%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0286 | Train Accuracy: 99.50% Test Accuracy: 99.33%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.5124 | Train Accuracy: 21.21% Test Accuracy: 78.25%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6122 | Train Accuracy: 95.11% Test Accuracy: 95.25%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4402 | Train Accuracy: 96.86% Test Accuracy: 97.42%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3562 | Train Accuracy: 97.29% Test Accuracy: 97.75%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3097 | Train Accuracy: 97.11% Test Accuracy: 98.17%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2788 | Train Accuracy: 97.21% Test Accuracy: 98.25%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2547 | Train Accuracy: 97.39% Test Accuracy: 98.42%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2330 | Train Accuracy: 97.54% Test Accuracy: 98.42%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2138 | Train Accuracy: 97.71% Test Accuracy: 98.25%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1975 | Train Accuracy: 97.86% Test Accuracy: 98.25%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1865 | Train Accuracy: 97.71% Test Accuracy: 98.33%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1742 | Train Accuracy: 97.86% Test Accuracy: 98.25%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1654 | Train Accuracy: 97.82% Test Accuracy: 98.33%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1555 | Train Accuracy: 97.71% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1481 | Train Accuracy: 97.89% Test Accuracy: 98.33%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1412 | Train Accuracy: 98.00% Test Accuracy: 98.42%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1369 | Train Accuracy: 97.86% Test Accuracy: 98.58%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1316 | Train Accuracy: 97.82% Test Accuracy: 98.67%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1230 | Train Accuracy: 98.18% Test Accuracy: 98.75%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1188 | Train Accuracy: 98.04% Test Accuracy: 98.75%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4353 | Train Accuracy: 25.50% Test Accuracy: 48.42%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.5356 | Train Accuracy: 49.57% Test Accuracy: 53.25%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6953 | Train Accuracy: 69.96% Test Accuracy: 72.17%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5482 | Train Accuracy: 78.21% Test Accuracy: 67.75%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5199 | Train Accuracy: 74.32% Test Accuracy: 77.33%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3501 | Train Accuracy: 87.39% Test Accuracy: 87.92%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2567 | Train Accuracy: 97.29% Test Accuracy: 98.25%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2629 | Train Accuracy: 97.50% Test Accuracy: 98.42%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2481 | Train Accuracy: 97.04% Test Accuracy: 98.08%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1966 | Train Accuracy: 97.50% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1512 | Train Accuracy: 97.46% Test Accuracy: 97.58%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1306 | Train Accuracy: 97.39% Test Accuracy: 97.58%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1194 | Train Accuracy: 97.29% Test Accuracy: 97.50%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1164 | Train Accuracy: 97.21% Test Accuracy: 97.67%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1153 | Train Accuracy: 97.04% Test Accuracy: 97.83%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1093 | Train Accuracy: 97.32% Test Accuracy: 97.92%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1000 | Train Accuracy: 97.68% Test Accuracy: 98.00%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.0901 | Train Accuracy: 97.75% Test Accuracy: 98.33%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.0762 | Train Accuracy: 98.14% Test Accuracy: 98.42%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.0718 | Train Accuracy: 98.07% Test Accuracy: 98.67%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4445 | Train Accuracy: 24.32% Test Accuracy: 50.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0283 | Train Accuracy: 69.14% Test Accuracy: 50.08%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8062 | Train Accuracy: 88.18% Test Accuracy: 71.67%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6840 | Train Accuracy: 94.18% Test Accuracy: 91.58%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6043 | Train Accuracy: 95.82% Test Accuracy: 94.83%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5464 | Train Accuracy: 96.11% Test Accuracy: 96.50%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5018 | Train Accuracy: 96.54% Test Accuracy: 97.17%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.4654 | Train Accuracy: 96.86% Test Accuracy: 97.50%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.4398 | Train Accuracy: 96.86% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.4140 | Train Accuracy: 96.82% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.3942 | Train Accuracy: 97.36% Test Accuracy: 98.25%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.3783 | Train Accuracy: 97.18% Test Accuracy: 98.42%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.3608 | Train Accuracy: 97.29% Test Accuracy: 98.42%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.3472 | Train Accuracy: 97.36% Test Accuracy: 98.42%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.3356 | Train Accuracy: 97.36% Test Accuracy: 98.42%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.3223 | Train Accuracy: 97.68% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.3149 | Train Accuracy: 97.54% Test Accuracy: 98.33%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.3029 | Train Accuracy: 97.61% Test Accuracy: 98.33%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.2950 | Train Accuracy: 97.57% Test Accuracy: 98.33%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.2874 | Train Accuracy: 97.68% Test Accuracy: 98.33%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 1.5899 | Train Accuracy: 11.43% Test Accuracy: 96.83%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1687 | Train Accuracy: 96.64% Test Accuracy: 95.75%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1188 | Train Accuracy: 97.43% Test Accuracy: 97.75%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0897 | Train Accuracy: 97.89% Test Accuracy: 97.92%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0727 | Train Accuracy: 98.25% Test Accuracy: 98.42%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0696 | Train Accuracy: 98.36% Test Accuracy: 98.67%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0651 | Train Accuracy: 98.68% Test Accuracy: 98.67%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0595 | Train Accuracy: 98.71% Test Accuracy: 98.67%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0554 | Train Accuracy: 98.43% Test Accuracy: 98.75%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0524 | Train Accuracy: 98.57% Test Accuracy: 98.75%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0483 | Train Accuracy: 98.57% Test Accuracy: 98.83%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0467 | Train Accuracy: 98.79% Test Accuracy: 98.83%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0442 | Train Accuracy: 98.93% Test Accuracy: 98.92%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0419 | Train Accuracy: 98.96% Test Accuracy: 99.00%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0411 | Train Accuracy: 99.07% Test Accuracy: 99.08%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0402 | Train Accuracy: 99.14% Test Accuracy: 99.17%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0369 | Train Accuracy: 99.14% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0365 | Train Accuracy: 99.14% Test Accuracy: 99.17%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0357 | Train Accuracy: 99.07% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0338 | Train Accuracy: 99.14% Test Accuracy: 99.17%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 1.4327 | Train Accuracy: 29.14% Test Accuracy: 59.42%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.7775 | Train Accuracy: 75.14% Test Accuracy: 51.83%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 1.4681 | Train Accuracy: 67.82% Test Accuracy: 72.25%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2254 | Train Accuracy: 93.93% Test Accuracy: 88.25%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1432 | Train Accuracy: 96.54% Test Accuracy: 82.33%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2500 | Train Accuracy: 91.68% Test Accuracy: 87.67%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1757 | Train Accuracy: 94.21% Test Accuracy: 97.42%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1000 | Train Accuracy: 97.61% Test Accuracy: 97.92%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0773 | Train Accuracy: 97.86% Test Accuracy: 98.00%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0773 | Train Accuracy: 98.04% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0801 | Train Accuracy: 97.96% Test Accuracy: 97.83%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0739 | Train Accuracy: 98.04% Test Accuracy: 97.83%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0721 | Train Accuracy: 98.11% Test Accuracy: 97.83%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0665 | Train Accuracy: 98.07% Test Accuracy: 97.92%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0604 | Train Accuracy: 98.39% Test Accuracy: 98.17%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0570 | Train Accuracy: 98.50% Test Accuracy: 98.42%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0567 | Train Accuracy: 98.57% Test Accuracy: 98.83%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0555 | Train Accuracy: 98.75% Test Accuracy: 99.08%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0524 | Train Accuracy: 98.93% Test Accuracy: 99.08%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0511 | Train Accuracy: 98.93% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.3236 | Train Accuracy: 36.14% Test Accuracy: 93.17%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3071 | Train Accuracy: 94.18% Test Accuracy: 97.08%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1581 | Train Accuracy: 96.96% Test Accuracy: 97.75%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1134 | Train Accuracy: 97.29% Test Accuracy: 97.92%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0958 | Train Accuracy: 97.61% Test Accuracy: 97.92%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0837 | Train Accuracy: 97.75% Test Accuracy: 97.83%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0732 | Train Accuracy: 97.89% Test Accuracy: 98.00%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0671 | Train Accuracy: 97.96% Test Accuracy: 97.92%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0631 | Train Accuracy: 98.11% Test Accuracy: 98.42%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0602 | Train Accuracy: 98.11% Test Accuracy: 98.58%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0576 | Train Accuracy: 98.32% Test Accuracy: 98.67%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0529 | Train Accuracy: 98.50% Test Accuracy: 98.92%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0510 | Train Accuracy: 98.64% Test Accuracy: 99.00%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0492 | Train Accuracy: 98.68% Test Accuracy: 99.00%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0474 | Train Accuracy: 98.89% Test Accuracy: 99.00%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0455 | Train Accuracy: 98.93% Test Accuracy: 99.00%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0439 | Train Accuracy: 99.04% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0434 | Train Accuracy: 99.07% Test Accuracy: 99.17%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0408 | Train Accuracy: 99.11% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0414 | Train Accuracy: 98.96% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.4227 | Train Accuracy: 15.14% Test Accuracy: 66.08%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.4781 | Train Accuracy: 72.86% Test Accuracy: 52.67%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 2.7514 | Train Accuracy: 51.68% Test Accuracy: 96.75%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1316 | Train Accuracy: 96.18% Test Accuracy: 93.67%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.2701 | Train Accuracy: 93.46% Test Accuracy: 91.08%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.4297 | Train Accuracy: 86.61% Test Accuracy: 97.25%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1539 | Train Accuracy: 96.57% Test Accuracy: 98.58%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0892 | Train Accuracy: 98.21% Test Accuracy: 98.67%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0775 | Train Accuracy: 98.61% Test Accuracy: 98.67%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0753 | Train Accuracy: 98.54% Test Accuracy: 98.92%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0771 | Train Accuracy: 98.71% Test Accuracy: 99.00%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0590 | Train Accuracy: 99.00% Test Accuracy: 99.00%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0550 | Train Accuracy: 98.96% Test Accuracy: 99.08%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0629 | Train Accuracy: 98.75% Test Accuracy: 98.50%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0746 | Train Accuracy: 97.86% Test Accuracy: 98.83%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0497 | Train Accuracy: 98.79% Test Accuracy: 99.08%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0414 | Train Accuracy: 99.18% Test Accuracy: 99.08%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0322 | Train Accuracy: 99.25% Test Accuracy: 99.08%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0356 | Train Accuracy: 99.32% Test Accuracy: 99.08%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0327 | Train Accuracy: 99.36% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.3930 | Train Accuracy: 22.50% Test Accuracy: 73.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 45.5073 | Train Accuracy: 70.46% Test Accuracy: 50.92%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 209.0233 | Train Accuracy: 50.86% Test Accuracy: 50.00%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 115.7419 | Train Accuracy: 48.86% Test Accuracy: 90.42%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 2.9461 | Train Accuracy: 88.89% Test Accuracy: 72.92%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.1816 | Train Accuracy: 78.36% Test Accuracy: 78.75%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 12.1972 | Train Accuracy: 77.54% Test Accuracy: 97.67%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.5963 | Train Accuracy: 96.14% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.5487 | Train Accuracy: 97.36% Test Accuracy: 98.58%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.1844 | Train Accuracy: 96.32% Test Accuracy: 98.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.8416 | Train Accuracy: 98.18% Test Accuracy: 98.08%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.6303 | Train Accuracy: 92.36% Test Accuracy: 98.92%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.7519 | Train Accuracy: 98.57% Test Accuracy: 98.58%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.9687 | Train Accuracy: 98.61% Test Accuracy: 98.08%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.7936 | Train Accuracy: 97.43% Test Accuracy: 98.33%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.7594 | Train Accuracy: 97.79% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.8287 | Train Accuracy: 98.32% Test Accuracy: 99.00%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.2270 | Train Accuracy: 98.89% Test Accuracy: 98.92%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.3732 | Train Accuracy: 98.25% Test Accuracy: 99.00%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.1627 | Train Accuracy: 99.00% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.3689 | Train Accuracy: 30.36% Test Accuracy: 92.92%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.9941 | Train Accuracy: 90.25% Test Accuracy: 96.50%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.7285 | Train Accuracy: 95.64% Test Accuracy: 97.33%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.5317 | Train Accuracy: 96.68% Test Accuracy: 97.50%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3852 | Train Accuracy: 96.93% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2793 | Train Accuracy: 97.11% Test Accuracy: 97.67%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2081 | Train Accuracy: 97.18% Test Accuracy: 97.75%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1603 | Train Accuracy: 97.21% Test Accuracy: 97.83%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1320 | Train Accuracy: 97.25% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1115 | Train Accuracy: 97.29% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0987 | Train Accuracy: 97.32% Test Accuracy: 97.92%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0891 | Train Accuracy: 97.46% Test Accuracy: 98.00%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0765 | Train Accuracy: 97.68% Test Accuracy: 98.08%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0699 | Train Accuracy: 97.93% Test Accuracy: 98.17%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0622 | Train Accuracy: 98.04% Test Accuracy: 98.58%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0524 | Train Accuracy: 98.21% Test Accuracy: 98.83%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0475 | Train Accuracy: 98.54% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0433 | Train Accuracy: 98.86% Test Accuracy: 99.17%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0408 | Train Accuracy: 99.07% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0392 | Train Accuracy: 99.14% Test Accuracy: 99.33%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4518 | Train Accuracy: 25.04% Test Accuracy: 74.50%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0971 | Train Accuracy: 67.00% Test Accuracy: 49.83%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8742 | Train Accuracy: 59.96% Test Accuracy: 96.50%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6477 | Train Accuracy: 92.36% Test Accuracy: 96.83%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5014 | Train Accuracy: 95.86% Test Accuracy: 97.33%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3933 | Train Accuracy: 96.93% Test Accuracy: 97.67%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3089 | Train Accuracy: 97.11% Test Accuracy: 97.83%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2434 | Train Accuracy: 97.36% Test Accuracy: 97.92%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1970 | Train Accuracy: 97.50% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1611 | Train Accuracy: 97.50% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1341 | Train Accuracy: 97.61% Test Accuracy: 97.83%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1184 | Train Accuracy: 97.57% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1028 | Train Accuracy: 97.71% Test Accuracy: 98.08%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0919 | Train Accuracy: 97.75% Test Accuracy: 98.17%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0833 | Train Accuracy: 97.89% Test Accuracy: 98.25%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0768 | Train Accuracy: 98.07% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0703 | Train Accuracy: 98.18% Test Accuracy: 98.58%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0650 | Train Accuracy: 98.14% Test Accuracy: 99.00%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0608 | Train Accuracy: 98.36% Test Accuracy: 99.00%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0571 | Train Accuracy: 98.46% Test Accuracy: 99.00%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4368 | Train Accuracy: 26.21% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 4.9944 | Train Accuracy: 25.29% Test Accuracy: 25.00%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 3.8941 | Train Accuracy: 25.07% Test Accuracy: 49.75%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.9692 | Train Accuracy: 49.75% Test Accuracy: 49.75%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8464 | Train Accuracy: 50.29% Test Accuracy: 48.00%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.1949 | Train Accuracy: 47.89% Test Accuracy: 48.08%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.5700 | Train Accuracy: 47.82% Test Accuracy: 48.00%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.5256 | Train Accuracy: 47.82% Test Accuracy: 48.00%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.2644 | Train Accuracy: 47.86% Test Accuracy: 48.00%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9489 | Train Accuracy: 47.93% Test Accuracy: 47.75%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7670 | Train Accuracy: 49.11% Test Accuracy: 49.92%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8282 | Train Accuracy: 49.96% Test Accuracy: 49.75%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9318 | Train Accuracy: 49.86% Test Accuracy: 49.75%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9375 | Train Accuracy: 49.86% Test Accuracy: 49.75%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8673 | Train Accuracy: 50.04% Test Accuracy: 74.67%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7617 | Train Accuracy: 70.86% Test Accuracy: 73.83%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6788 | Train Accuracy: 67.64% Test Accuracy: 73.92%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6412 | Train Accuracy: 73.61% Test Accuracy: 48.00%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6379 | Train Accuracy: 56.68% Test Accuracy: 56.08%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6368 | Train Accuracy: 59.79% Test Accuracy: 72.67%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4827 | Train Accuracy: 24.96% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3743 | Train Accuracy: 27.50% Test Accuracy: 41.50%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2770 | Train Accuracy: 38.39% Test Accuracy: 50.00%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2013 | Train Accuracy: 55.32% Test Accuracy: 77.33%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1391 | Train Accuracy: 67.75% Test Accuracy: 94.42%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0755 | Train Accuracy: 78.25% Test Accuracy: 97.33%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0268 | Train Accuracy: 80.39% Test Accuracy: 95.42%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9822 | Train Accuracy: 81.46% Test Accuracy: 76.50%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9407 | Train Accuracy: 81.32% Test Accuracy: 77.50%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9015 | Train Accuracy: 82.29% Test Accuracy: 93.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8642 | Train Accuracy: 83.11% Test Accuracy: 97.58%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8282 | Train Accuracy: 86.89% Test Accuracy: 97.83%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7946 | Train Accuracy: 88.18% Test Accuracy: 97.83%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7580 | Train Accuracy: 91.46% Test Accuracy: 97.92%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7270 | Train Accuracy: 93.96% Test Accuracy: 97.92%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6966 | Train Accuracy: 95.14% Test Accuracy: 98.00%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6653 | Train Accuracy: 96.07% Test Accuracy: 98.00%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6370 | Train Accuracy: 96.68% Test Accuracy: 97.83%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6112 | Train Accuracy: 96.64% Test Accuracy: 97.83%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5826 | Train Accuracy: 96.79% Test Accuracy: 97.92%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 1.4324 | Train Accuracy: 16.79% Test Accuracy: 87.92%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.3912 | Train Accuracy: 86.36% Test Accuracy: 63.42%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.5843 | Train Accuracy: 63.61% Test Accuracy: 97.33%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1298 | Train Accuracy: 97.04% Test Accuracy: 96.83%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1532 | Train Accuracy: 96.07% Test Accuracy: 96.67%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1777 | Train Accuracy: 95.93% Test Accuracy: 97.92%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1265 | Train Accuracy: 97.18% Test Accuracy: 98.17%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0914 | Train Accuracy: 97.46% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0815 | Train Accuracy: 97.36% Test Accuracy: 97.50%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0774 | Train Accuracy: 97.43% Test Accuracy: 97.58%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0759 | Train Accuracy: 97.57% Test Accuracy: 97.58%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0698 | Train Accuracy: 97.79% Test Accuracy: 97.67%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0622 | Train Accuracy: 98.04% Test Accuracy: 98.42%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0557 | Train Accuracy: 98.39% Test Accuracy: 98.83%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0502 | Train Accuracy: 98.61% Test Accuracy: 99.17%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0477 | Train Accuracy: 98.93% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0458 | Train Accuracy: 99.00% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0433 | Train Accuracy: 99.11% Test Accuracy: 99.17%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0418 | Train Accuracy: 99.07% Test Accuracy: 99.08%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0394 | Train Accuracy: 99.18% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.4232 | Train Accuracy: 20.75% Test Accuracy: 63.92%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.7454 | Train Accuracy: 65.57% Test Accuracy: 40.83%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 5.0706 | Train Accuracy: 34.68% Test Accuracy: 47.75%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 3.1140 | Train Accuracy: 47.68% Test Accuracy: 49.92%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.8521 | Train Accuracy: 50.57% Test Accuracy: 50.50%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.9784 | Train Accuracy: 50.29% Test Accuracy: 50.33%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 2.2600 | Train Accuracy: 50.21% Test Accuracy: 50.25%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.4554 | Train Accuracy: 51.79% Test Accuracy: 74.08%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.5689 | Train Accuracy: 75.71% Test Accuracy: 90.25%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.5451 | Train Accuracy: 83.96% Test Accuracy: 52.17%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.8479 | Train Accuracy: 58.07% Test Accuracy: 72.50%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.6461 | Train Accuracy: 75.25% Test Accuracy: 97.58%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.4019 | Train Accuracy: 94.07% Test Accuracy: 97.50%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2848 | Train Accuracy: 97.04% Test Accuracy: 97.08%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2522 | Train Accuracy: 96.61% Test Accuracy: 96.50%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2798 | Train Accuracy: 95.82% Test Accuracy: 95.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3151 | Train Accuracy: 93.64% Test Accuracy: 95.67%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3071 | Train Accuracy: 93.46% Test Accuracy: 96.75%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2583 | Train Accuracy: 95.82% Test Accuracy: 97.00%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2092 | Train Accuracy: 96.71% Test Accuracy: 97.17%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.3595 | Train Accuracy: 34.46% Test Accuracy: 96.42%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.6429 | Train Accuracy: 95.18% Test Accuracy: 97.42%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3884 | Train Accuracy: 96.36% Test Accuracy: 97.42%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2679 | Train Accuracy: 96.79% Test Accuracy: 97.50%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2058 | Train Accuracy: 96.82% Test Accuracy: 97.75%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1682 | Train Accuracy: 97.07% Test Accuracy: 97.83%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1403 | Train Accuracy: 97.21% Test Accuracy: 97.92%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1224 | Train Accuracy: 97.18% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1069 | Train Accuracy: 97.50% Test Accuracy: 98.00%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0945 | Train Accuracy: 97.61% Test Accuracy: 98.00%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0850 | Train Accuracy: 97.68% Test Accuracy: 98.08%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0765 | Train Accuracy: 97.86% Test Accuracy: 98.42%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0706 | Train Accuracy: 97.93% Test Accuracy: 98.50%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0655 | Train Accuracy: 98.04% Test Accuracy: 98.67%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0612 | Train Accuracy: 98.07% Test Accuracy: 98.83%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0574 | Train Accuracy: 98.29% Test Accuracy: 99.00%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0552 | Train Accuracy: 98.43% Test Accuracy: 99.00%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0532 | Train Accuracy: 98.75% Test Accuracy: 99.00%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0525 | Train Accuracy: 98.71% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.2 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0499 | Train Accuracy: 98.75% Test Accuracy: 99.33%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.5836 | Train Accuracy: 22.61% Test Accuracy: 69.33%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.3143 | Train Accuracy: 96.32% Test Accuracy: 97.50%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1561 | Train Accuracy: 97.07% Test Accuracy: 97.75%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1035 | Train Accuracy: 97.43% Test Accuracy: 98.00%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0804 | Train Accuracy: 97.89% Test Accuracy: 98.08%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0679 | Train Accuracy: 98.29% Test Accuracy: 98.50%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0563 | Train Accuracy: 98.57% Test Accuracy: 98.83%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0490 | Train Accuracy: 98.71% Test Accuracy: 99.00%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0438 | Train Accuracy: 98.89% Test Accuracy: 99.17%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0432 | Train Accuracy: 99.00% Test Accuracy: 99.17%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0383 | Train Accuracy: 99.18% Test Accuracy: 99.17%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0379 | Train Accuracy: 99.11% Test Accuracy: 99.25%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0358 | Train Accuracy: 99.14% Test Accuracy: 99.25%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0331 | Train Accuracy: 99.21% Test Accuracy: 99.33%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0302 | Train Accuracy: 99.21% Test Accuracy: 99.33%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0289 | Train Accuracy: 99.36% Test Accuracy: 99.42%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0258 | Train Accuracy: 99.43% Test Accuracy: 99.42%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0255 | Train Accuracy: 99.39% Test Accuracy: 99.42%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0263 | Train Accuracy: 99.36% Test Accuracy: 99.42%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0246 | Train Accuracy: 99.36% Test Accuracy: 99.42%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 1.5788 | Train Accuracy: 21.32% Test Accuracy: 55.83%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.4850 | Train Accuracy: 80.96% Test Accuracy: 56.00%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1688 | Train Accuracy: 94.54% Test Accuracy: 83.00%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1126 | Train Accuracy: 96.14% Test Accuracy: 73.08%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0841 | Train Accuracy: 97.32% Test Accuracy: 70.92%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0737 | Train Accuracy: 97.93% Test Accuracy: 71.75%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0694 | Train Accuracy: 97.82% Test Accuracy: 72.17%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0655 | Train Accuracy: 97.93% Test Accuracy: 73.67%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0613 | Train Accuracy: 98.14% Test Accuracy: 85.83%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0516 | Train Accuracy: 98.25% Test Accuracy: 94.75%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0473 | Train Accuracy: 98.50% Test Accuracy: 97.42%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0401 | Train Accuracy: 98.75% Test Accuracy: 98.58%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0396 | Train Accuracy: 98.71% Test Accuracy: 99.08%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0420 | Train Accuracy: 98.61% Test Accuracy: 99.25%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0388 | Train Accuracy: 98.75% Test Accuracy: 99.17%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0375 | Train Accuracy: 98.75% Test Accuracy: 99.17%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0361 | Train Accuracy: 98.71% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0349 | Train Accuracy: 98.89% Test Accuracy: 99.17%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0333 | Train Accuracy: 99.11% Test Accuracy: 99.08%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0324 | Train Accuracy: 99.00% Test Accuracy: 98.92%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.3228 | Train Accuracy: 35.82% Test Accuracy: 95.67%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5819 | Train Accuracy: 91.14% Test Accuracy: 97.50%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3432 | Train Accuracy: 97.07% Test Accuracy: 97.67%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2436 | Train Accuracy: 97.46% Test Accuracy: 98.00%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1953 | Train Accuracy: 97.57% Test Accuracy: 98.00%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1564 | Train Accuracy: 97.86% Test Accuracy: 98.08%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1392 | Train Accuracy: 98.04% Test Accuracy: 98.33%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1181 | Train Accuracy: 98.43% Test Accuracy: 98.50%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1074 | Train Accuracy: 98.25% Test Accuracy: 98.50%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0976 | Train Accuracy: 98.43% Test Accuracy: 98.67%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0905 | Train Accuracy: 98.43% Test Accuracy: 98.75%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0822 | Train Accuracy: 98.61% Test Accuracy: 98.92%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0778 | Train Accuracy: 98.71% Test Accuracy: 98.92%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0740 | Train Accuracy: 98.64% Test Accuracy: 98.92%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0701 | Train Accuracy: 98.86% Test Accuracy: 99.00%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0619 | Train Accuracy: 98.96% Test Accuracy: 99.08%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0622 | Train Accuracy: 99.00% Test Accuracy: 99.25%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0591 | Train Accuracy: 99.11% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0556 | Train Accuracy: 99.21% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.0506 | Train Accuracy: 99.11% Test Accuracy: 99.33%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4437 | Train Accuracy: 25.21% Test Accuracy: 95.25%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8216 | Train Accuracy: 85.89% Test Accuracy: 96.25%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6453 | Train Accuracy: 92.18% Test Accuracy: 97.00%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5160 | Train Accuracy: 94.61% Test Accuracy: 97.50%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4275 | Train Accuracy: 95.71% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3640 | Train Accuracy: 96.39% Test Accuracy: 97.67%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3174 | Train Accuracy: 96.71% Test Accuracy: 97.67%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2801 | Train Accuracy: 97.32% Test Accuracy: 97.67%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2481 | Train Accuracy: 97.29% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2293 | Train Accuracy: 97.64% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2175 | Train Accuracy: 97.21% Test Accuracy: 98.00%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1975 | Train Accuracy: 97.50% Test Accuracy: 98.17%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1857 | Train Accuracy: 97.68% Test Accuracy: 98.33%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1732 | Train Accuracy: 97.75% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1595 | Train Accuracy: 97.68% Test Accuracy: 98.33%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1555 | Train Accuracy: 97.89% Test Accuracy: 98.42%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1431 | Train Accuracy: 97.68% Test Accuracy: 98.42%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1383 | Train Accuracy: 98.00% Test Accuracy: 98.50%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1273 | Train Accuracy: 98.29% Test Accuracy: 98.58%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1249 | Train Accuracy: 98.04% Test Accuracy: 98.83%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4326 | Train Accuracy: 25.11% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.8309 | Train Accuracy: 31.00% Test Accuracy: 97.42%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8291 | Train Accuracy: 57.14% Test Accuracy: 64.08%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7261 | Train Accuracy: 63.61% Test Accuracy: 70.25%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7144 | Train Accuracy: 65.75% Test Accuracy: 94.00%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5036 | Train Accuracy: 79.86% Test Accuracy: 97.83%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3467 | Train Accuracy: 92.71% Test Accuracy: 97.75%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3107 | Train Accuracy: 93.32% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3343 | Train Accuracy: 89.29% Test Accuracy: 97.58%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3238 | Train Accuracy: 87.54% Test Accuracy: 97.58%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2623 | Train Accuracy: 92.29% Test Accuracy: 97.67%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1818 | Train Accuracy: 96.93% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1396 | Train Accuracy: 97.36% Test Accuracy: 97.67%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1302 | Train Accuracy: 97.14% Test Accuracy: 97.42%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1369 | Train Accuracy: 96.57% Test Accuracy: 97.33%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1470 | Train Accuracy: 96.14% Test Accuracy: 97.42%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1508 | Train Accuracy: 95.79% Test Accuracy: 97.58%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1488 | Train Accuracy: 95.68% Test Accuracy: 97.83%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1290 | Train Accuracy: 95.61% Test Accuracy: 98.17%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.1111 | Train Accuracy: 96.89% Test Accuracy: 98.17%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4413 | Train Accuracy: 25.93% Test Accuracy: 39.50%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1752 | Train Accuracy: 53.32% Test Accuracy: 49.83%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0054 | Train Accuracy: 68.64% Test Accuracy: 60.42%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8961 | Train Accuracy: 79.18% Test Accuracy: 71.17%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8231 | Train Accuracy: 84.46% Test Accuracy: 88.33%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7687 | Train Accuracy: 88.39% Test Accuracy: 93.92%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7312 | Train Accuracy: 90.32% Test Accuracy: 95.83%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6833 | Train Accuracy: 92.79% Test Accuracy: 96.17%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6585 | Train Accuracy: 93.64% Test Accuracy: 96.67%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6211 | Train Accuracy: 95.11% Test Accuracy: 97.25%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5946 | Train Accuracy: 94.75% Test Accuracy: 97.50%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5709 | Train Accuracy: 95.25% Test Accuracy: 97.50%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5463 | Train Accuracy: 96.29% Test Accuracy: 97.58%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5278 | Train Accuracy: 96.25% Test Accuracy: 97.67%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.5117 | Train Accuracy: 96.39% Test Accuracy: 97.92%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.4915 | Train Accuracy: 96.54% Test Accuracy: 98.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.4758 | Train Accuracy: 96.50% Test Accuracy: 98.25%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.4622 | Train Accuracy: 97.00% Test Accuracy: 98.25%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.4491 | Train Accuracy: 96.93% Test Accuracy: 98.25%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.4307 | Train Accuracy: 97.00% Test Accuracy: 98.25%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 1.3674 | Train Accuracy: 31.96% Test Accuracy: 90.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2472 | Train Accuracy: 93.75% Test Accuracy: 97.58%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1678 | Train Accuracy: 97.32% Test Accuracy: 97.92%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1192 | Train Accuracy: 97.68% Test Accuracy: 97.83%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0883 | Train Accuracy: 97.57% Test Accuracy: 98.33%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0750 | Train Accuracy: 98.25% Test Accuracy: 98.42%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0727 | Train Accuracy: 97.96% Test Accuracy: 98.58%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0665 | Train Accuracy: 98.46% Test Accuracy: 98.58%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0594 | Train Accuracy: 98.71% Test Accuracy: 98.75%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0528 | Train Accuracy: 98.79% Test Accuracy: 98.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0529 | Train Accuracy: 98.82% Test Accuracy: 98.83%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0501 | Train Accuracy: 98.64% Test Accuracy: 99.00%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0448 | Train Accuracy: 98.75% Test Accuracy: 99.00%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0468 | Train Accuracy: 98.75% Test Accuracy: 99.00%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0437 | Train Accuracy: 98.86% Test Accuracy: 99.08%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0424 | Train Accuracy: 99.00% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0416 | Train Accuracy: 99.04% Test Accuracy: 99.25%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0401 | Train Accuracy: 99.00% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0385 | Train Accuracy: 99.11% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0392 | Train Accuracy: 99.14% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 1.4414 | Train Accuracy: 28.46% Test Accuracy: 90.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.4338 | Train Accuracy: 84.36% Test Accuracy: 89.25%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2319 | Train Accuracy: 93.04% Test Accuracy: 92.92%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1065 | Train Accuracy: 97.29% Test Accuracy: 73.00%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1401 | Train Accuracy: 96.71% Test Accuracy: 98.08%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0756 | Train Accuracy: 98.21% Test Accuracy: 98.42%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0632 | Train Accuracy: 98.25% Test Accuracy: 98.58%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0681 | Train Accuracy: 98.07% Test Accuracy: 98.67%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0647 | Train Accuracy: 98.32% Test Accuracy: 98.58%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0606 | Train Accuracy: 98.21% Test Accuracy: 98.58%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0701 | Train Accuracy: 98.11% Test Accuracy: 98.75%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0616 | Train Accuracy: 98.57% Test Accuracy: 98.83%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0591 | Train Accuracy: 98.43% Test Accuracy: 98.92%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0601 | Train Accuracy: 98.46% Test Accuracy: 99.17%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0517 | Train Accuracy: 98.71% Test Accuracy: 99.17%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0502 | Train Accuracy: 98.86% Test Accuracy: 99.08%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0533 | Train Accuracy: 98.68% Test Accuracy: 99.00%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0458 | Train Accuracy: 98.96% Test Accuracy: 98.92%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0458 | Train Accuracy: 99.11% Test Accuracy: 99.00%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0506 | Train Accuracy: 98.79% Test Accuracy: 99.00%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.4125 | Train Accuracy: 29.11% Test Accuracy: 96.83%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.4304 | Train Accuracy: 92.29% Test Accuracy: 97.42%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2084 | Train Accuracy: 96.79% Test Accuracy: 97.75%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1458 | Train Accuracy: 97.43% Test Accuracy: 98.00%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1156 | Train Accuracy: 97.14% Test Accuracy: 97.92%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0993 | Train Accuracy: 97.57% Test Accuracy: 97.92%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0907 | Train Accuracy: 97.54% Test Accuracy: 98.08%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0840 | Train Accuracy: 97.68% Test Accuracy: 98.25%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0770 | Train Accuracy: 97.82% Test Accuracy: 98.50%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0712 | Train Accuracy: 97.96% Test Accuracy: 98.58%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0673 | Train Accuracy: 97.96% Test Accuracy: 98.67%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0633 | Train Accuracy: 98.14% Test Accuracy: 98.83%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0601 | Train Accuracy: 98.36% Test Accuracy: 98.92%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0581 | Train Accuracy: 98.29% Test Accuracy: 98.92%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0546 | Train Accuracy: 98.57% Test Accuracy: 98.92%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0552 | Train Accuracy: 98.61% Test Accuracy: 98.92%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0526 | Train Accuracy: 98.75% Test Accuracy: 99.08%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0497 | Train Accuracy: 98.82% Test Accuracy: 99.08%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0476 | Train Accuracy: 98.93% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0477 | Train Accuracy: 98.93% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.4296 | Train Accuracy: 21.57% Test Accuracy: 95.50%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.4022 | Train Accuracy: 83.25% Test Accuracy: 55.33%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 2.5434 | Train Accuracy: 55.43% Test Accuracy: 98.08%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0984 | Train Accuracy: 97.18% Test Accuracy: 94.83%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.3254 | Train Accuracy: 90.64% Test Accuracy: 94.67%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.3728 | Train Accuracy: 90.21% Test Accuracy: 98.00%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1578 | Train Accuracy: 96.57% Test Accuracy: 98.58%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1003 | Train Accuracy: 98.14% Test Accuracy: 98.83%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0959 | Train Accuracy: 98.18% Test Accuracy: 98.92%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0773 | Train Accuracy: 98.61% Test Accuracy: 98.92%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0841 | Train Accuracy: 98.68% Test Accuracy: 98.67%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0703 | Train Accuracy: 98.75% Test Accuracy: 98.75%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0721 | Train Accuracy: 98.68% Test Accuracy: 99.17%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0630 | Train Accuracy: 98.57% Test Accuracy: 98.83%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0609 | Train Accuracy: 98.64% Test Accuracy: 98.75%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0619 | Train Accuracy: 98.39% Test Accuracy: 99.08%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0586 | Train Accuracy: 98.61% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0325 | Train Accuracy: 99.36% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0348 | Train Accuracy: 99.18% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0360 | Train Accuracy: 99.46% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.3963 | Train Accuracy: 24.57% Test Accuracy: 56.08%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 25.0785 | Train Accuracy: 53.68% Test Accuracy: 48.25%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 423.0644 | Train Accuracy: 47.89% Test Accuracy: 59.25%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 37.2153 | Train Accuracy: 58.57% Test Accuracy: 25.33%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 26.2732 | Train Accuracy: 26.14% Test Accuracy: 52.67%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.1380 | Train Accuracy: 60.18% Test Accuracy: 98.08%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.8866 | Train Accuracy: 82.21% Test Accuracy: 97.92%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.0870 | Train Accuracy: 88.64% Test Accuracy: 96.67%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.1822 | Train Accuracy: 92.36% Test Accuracy: 95.00%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.9995 | Train Accuracy: 91.29% Test Accuracy: 92.08%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.9467 | Train Accuracy: 89.68% Test Accuracy: 96.50%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.9485 | Train Accuracy: 90.64% Test Accuracy: 97.83%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.7683 | Train Accuracy: 92.11% Test Accuracy: 97.58%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.6855 | Train Accuracy: 94.00% Test Accuracy: 97.75%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5880 | Train Accuracy: 94.11% Test Accuracy: 98.33%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5007 | Train Accuracy: 94.71% Test Accuracy: 98.50%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.8518 | Train Accuracy: 92.11% Test Accuracy: 97.83%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5303 | Train Accuracy: 94.89% Test Accuracy: 97.58%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.5713 | Train Accuracy: 93.75% Test Accuracy: 97.58%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 0.6405 | Train Accuracy: 94.32% Test Accuracy: 97.58%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.4212 | Train Accuracy: 21.54% Test Accuracy: 88.17%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.0417 | Train Accuracy: 76.57% Test Accuracy: 95.75%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.7828 | Train Accuracy: 89.21% Test Accuracy: 96.83%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.5921 | Train Accuracy: 93.21% Test Accuracy: 97.08%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.4521 | Train Accuracy: 95.21% Test Accuracy: 97.17%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3426 | Train Accuracy: 96.04% Test Accuracy: 97.17%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2680 | Train Accuracy: 96.54% Test Accuracy: 97.33%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2071 | Train Accuracy: 96.64% Test Accuracy: 97.42%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1688 | Train Accuracy: 96.89% Test Accuracy: 97.58%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1392 | Train Accuracy: 97.14% Test Accuracy: 97.75%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1168 | Train Accuracy: 97.43% Test Accuracy: 97.92%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0999 | Train Accuracy: 97.39% Test Accuracy: 98.08%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0887 | Train Accuracy: 97.54% Test Accuracy: 98.08%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0792 | Train Accuracy: 97.57% Test Accuracy: 98.25%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0707 | Train Accuracy: 97.86% Test Accuracy: 98.67%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0616 | Train Accuracy: 97.93% Test Accuracy: 98.92%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0536 | Train Accuracy: 98.29% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0536 | Train Accuracy: 98.57% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0466 | Train Accuracy: 98.68% Test Accuracy: 99.08%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0482 | Train Accuracy: 98.71% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.4316 | Train Accuracy: 24.64% Test Accuracy: 77.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.0607 | Train Accuracy: 55.71% Test Accuracy: 97.33%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7834 | Train Accuracy: 82.36% Test Accuracy: 97.50%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5801 | Train Accuracy: 92.93% Test Accuracy: 97.33%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4354 | Train Accuracy: 95.86% Test Accuracy: 97.42%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3302 | Train Accuracy: 96.71% Test Accuracy: 97.75%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2520 | Train Accuracy: 97.11% Test Accuracy: 97.75%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2008 | Train Accuracy: 97.25% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1645 | Train Accuracy: 97.11% Test Accuracy: 97.92%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1392 | Train Accuracy: 97.18% Test Accuracy: 98.00%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1174 | Train Accuracy: 97.29% Test Accuracy: 98.00%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1029 | Train Accuracy: 97.54% Test Accuracy: 98.08%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0930 | Train Accuracy: 97.75% Test Accuracy: 98.25%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0805 | Train Accuracy: 98.00% Test Accuracy: 98.42%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0759 | Train Accuracy: 98.07% Test Accuracy: 98.83%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0685 | Train Accuracy: 98.29% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0635 | Train Accuracy: 98.43% Test Accuracy: 99.25%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0593 | Train Accuracy: 98.54% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0549 | Train Accuracy: 98.75% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0528 | Train Accuracy: 98.86% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4487 | Train Accuracy: 24.96% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 5.5006 | Train Accuracy: 25.00% Test Accuracy: 50.00%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 2.7512 | Train Accuracy: 50.00% Test Accuracy: 50.00%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.4442 | Train Accuracy: 49.93% Test Accuracy: 46.42%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8836 | Train Accuracy: 53.46% Test Accuracy: 47.75%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.1254 | Train Accuracy: 47.64% Test Accuracy: 47.75%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.2113 | Train Accuracy: 47.64% Test Accuracy: 47.75%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.1239 | Train Accuracy: 47.64% Test Accuracy: 47.75%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9609 | Train Accuracy: 50.00% Test Accuracy: 53.67%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8416 | Train Accuracy: 57.00% Test Accuracy: 49.92%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7968 | Train Accuracy: 50.64% Test Accuracy: 50.17%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7817 | Train Accuracy: 50.89% Test Accuracy: 50.17%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7626 | Train Accuracy: 51.14% Test Accuracy: 53.92%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7433 | Train Accuracy: 60.50% Test Accuracy: 72.83%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7161 | Train Accuracy: 70.21% Test Accuracy: 72.83%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6766 | Train Accuracy: 71.57% Test Accuracy: 72.92%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6186 | Train Accuracy: 72.46% Test Accuracy: 72.83%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5757 | Train Accuracy: 77.64% Test Accuracy: 72.33%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5562 | Train Accuracy: 78.89% Test Accuracy: 72.58%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5322 | Train Accuracy: 74.54% Test Accuracy: 72.58%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4537 | Train Accuracy: 24.50% Test Accuracy: 48.42%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3626 | Train Accuracy: 31.21% Test Accuracy: 63.58%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2701 | Train Accuracy: 42.14% Test Accuracy: 97.08%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2038 | Train Accuracy: 50.89% Test Accuracy: 92.83%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1296 | Train Accuracy: 58.86% Test Accuracy: 84.08%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0812 | Train Accuracy: 61.04% Test Accuracy: 80.92%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0274 | Train Accuracy: 64.89% Test Accuracy: 80.58%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9785 | Train Accuracy: 67.57% Test Accuracy: 81.17%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9297 | Train Accuracy: 70.29% Test Accuracy: 82.58%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8874 | Train Accuracy: 73.25% Test Accuracy: 84.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8578 | Train Accuracy: 73.11% Test Accuracy: 88.33%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8120 | Train Accuracy: 76.21% Test Accuracy: 92.67%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7901 | Train Accuracy: 77.82% Test Accuracy: 95.33%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7548 | Train Accuracy: 80.89% Test Accuracy: 96.75%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7230 | Train Accuracy: 83.61% Test Accuracy: 97.00%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6917 | Train Accuracy: 86.21% Test Accuracy: 97.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6716 | Train Accuracy: 87.11% Test Accuracy: 97.25%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6450 | Train Accuracy: 88.68% Test Accuracy: 97.33%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6167 | Train Accuracy: 91.29% Test Accuracy: 97.33%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.6008 | Train Accuracy: 91.54% Test Accuracy: 97.33%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 1.4148 | Train Accuracy: 23.36% Test Accuracy: 93.42%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.3546 | Train Accuracy: 89.79% Test Accuracy: 97.42%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.3342 | Train Accuracy: 91.00% Test Accuracy: 97.92%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1132 | Train Accuracy: 97.25% Test Accuracy: 97.83%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1183 | Train Accuracy: 97.00% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1268 | Train Accuracy: 96.54% Test Accuracy: 98.08%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0990 | Train Accuracy: 97.36% Test Accuracy: 98.67%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0736 | Train Accuracy: 97.89% Test Accuracy: 98.42%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0665 | Train Accuracy: 97.93% Test Accuracy: 98.17%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0705 | Train Accuracy: 97.89% Test Accuracy: 98.08%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0649 | Train Accuracy: 98.07% Test Accuracy: 98.50%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0532 | Train Accuracy: 98.29% Test Accuracy: 98.75%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0497 | Train Accuracy: 98.46% Test Accuracy: 99.17%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0448 | Train Accuracy: 98.68% Test Accuracy: 99.25%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0410 | Train Accuracy: 99.04% Test Accuracy: 99.25%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0399 | Train Accuracy: 99.11% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0354 | Train Accuracy: 99.07% Test Accuracy: 99.25%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0383 | Train Accuracy: 99.21% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0332 | Train Accuracy: 99.32% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0303 | Train Accuracy: 99.25% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.4266 | Train Accuracy: 21.57% Test Accuracy: 66.75%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.0824 | Train Accuracy: 56.64% Test Accuracy: 48.92%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 3.5603 | Train Accuracy: 55.29% Test Accuracy: 49.92%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 2.4570 | Train Accuracy: 49.93% Test Accuracy: 72.67%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.9122 | Train Accuracy: 65.43% Test Accuracy: 48.08%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.6980 | Train Accuracy: 50.46% Test Accuracy: 72.83%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.1409 | Train Accuracy: 66.93% Test Accuracy: 70.83%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.6693 | Train Accuracy: 70.93% Test Accuracy: 57.00%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.8465 | Train Accuracy: 60.75% Test Accuracy: 72.17%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.7551 | Train Accuracy: 70.32% Test Accuracy: 72.58%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.4896 | Train Accuracy: 80.21% Test Accuracy: 97.08%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3754 | Train Accuracy: 90.50% Test Accuracy: 94.50%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3599 | Train Accuracy: 86.68% Test Accuracy: 95.58%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3156 | Train Accuracy: 86.79% Test Accuracy: 97.33%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2448 | Train Accuracy: 92.96% Test Accuracy: 97.42%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2003 | Train Accuracy: 95.75% Test Accuracy: 97.42%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2102 | Train Accuracy: 95.64% Test Accuracy: 97.58%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2167 | Train Accuracy: 95.21% Test Accuracy: 97.58%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1825 | Train Accuracy: 96.50% Test Accuracy: 97.58%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1654 | Train Accuracy: 96.96% Test Accuracy: 97.50%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.4566 | Train Accuracy: 18.36% Test Accuracy: 90.33%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.7187 | Train Accuracy: 86.04% Test Accuracy: 96.50%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.4397 | Train Accuracy: 94.29% Test Accuracy: 97.25%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3013 | Train Accuracy: 96.21% Test Accuracy: 97.42%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2293 | Train Accuracy: 96.68% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1880 | Train Accuracy: 97.00% Test Accuracy: 97.75%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1603 | Train Accuracy: 96.96% Test Accuracy: 97.92%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1404 | Train Accuracy: 97.18% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1234 | Train Accuracy: 97.32% Test Accuracy: 98.00%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1082 | Train Accuracy: 97.39% Test Accuracy: 98.00%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0984 | Train Accuracy: 97.50% Test Accuracy: 98.00%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0904 | Train Accuracy: 97.57% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0835 | Train Accuracy: 97.64% Test Accuracy: 98.17%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0784 | Train Accuracy: 97.86% Test Accuracy: 98.25%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0734 | Train Accuracy: 97.86% Test Accuracy: 98.33%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0678 | Train Accuracy: 98.04% Test Accuracy: 98.50%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0651 | Train Accuracy: 98.14% Test Accuracy: 98.67%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0634 | Train Accuracy: 98.21% Test Accuracy: 98.83%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0595 | Train Accuracy: 98.43% Test Accuracy: 98.92%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.5 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0611 | Train Accuracy: 98.39% Test Accuracy: 99.00%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.7270 | Train Accuracy: 22.04% Test Accuracy: 87.25%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.6465 | Train Accuracy: 78.71% Test Accuracy: 96.42%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.3523 | Train Accuracy: 93.00% Test Accuracy: 97.58%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2241 | Train Accuracy: 96.36% Test Accuracy: 97.67%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1661 | Train Accuracy: 97.14% Test Accuracy: 97.83%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1379 | Train Accuracy: 97.29% Test Accuracy: 97.92%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1090 | Train Accuracy: 97.57% Test Accuracy: 97.92%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0990 | Train Accuracy: 97.79% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0897 | Train Accuracy: 97.96% Test Accuracy: 98.08%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0792 | Train Accuracy: 98.04% Test Accuracy: 98.17%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0762 | Train Accuracy: 98.25% Test Accuracy: 98.33%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0717 | Train Accuracy: 98.32% Test Accuracy: 98.50%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0609 | Train Accuracy: 98.32% Test Accuracy: 98.58%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0588 | Train Accuracy: 98.50% Test Accuracy: 98.83%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0544 | Train Accuracy: 98.54% Test Accuracy: 99.08%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0535 | Train Accuracy: 98.82% Test Accuracy: 99.08%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0490 | Train Accuracy: 98.75% Test Accuracy: 99.08%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0537 | Train Accuracy: 98.79% Test Accuracy: 99.25%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0419 | Train Accuracy: 99.21% Test Accuracy: 99.33%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0477 | Train Accuracy: 98.75% Test Accuracy: 99.33%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 1.6279 | Train Accuracy: 26.54% Test Accuracy: 49.08%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.9829 | Train Accuracy: 59.50% Test Accuracy: 72.42%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.2252 | Train Accuracy: 94.61% Test Accuracy: 72.25%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1717 | Train Accuracy: 96.21% Test Accuracy: 97.08%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1401 | Train Accuracy: 96.82% Test Accuracy: 96.92%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1259 | Train Accuracy: 96.82% Test Accuracy: 96.67%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.1215 | Train Accuracy: 97.11% Test Accuracy: 96.67%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0937 | Train Accuracy: 97.39% Test Accuracy: 97.00%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0998 | Train Accuracy: 97.39% Test Accuracy: 97.17%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0886 | Train Accuracy: 97.50% Test Accuracy: 97.50%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0817 | Train Accuracy: 97.71% Test Accuracy: 97.58%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0817 | Train Accuracy: 97.96% Test Accuracy: 97.58%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0725 | Train Accuracy: 98.21% Test Accuracy: 97.83%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0698 | Train Accuracy: 98.00% Test Accuracy: 97.92%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0648 | Train Accuracy: 98.11% Test Accuracy: 98.00%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0705 | Train Accuracy: 98.18% Test Accuracy: 98.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0666 | Train Accuracy: 98.07% Test Accuracy: 98.25%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0608 | Train Accuracy: 98.43% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0592 | Train Accuracy: 98.36% Test Accuracy: 98.83%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.01 Train Loss: 0.0554 | Train Accuracy: 98.39% Test Accuracy: 98.92%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.6405 | Train Accuracy: 26.39% Test Accuracy: 97.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 1.1096 | Train Accuracy: 53.25% Test Accuracy: 97.67%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.8226 | Train Accuracy: 70.54% Test Accuracy: 97.75%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.6681 | Train Accuracy: 79.86% Test Accuracy: 97.92%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5665 | Train Accuracy: 84.50% Test Accuracy: 98.00%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.5022 | Train Accuracy: 88.39% Test Accuracy: 98.00%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.4389 | Train Accuracy: 90.89% Test Accuracy: 98.00%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3914 | Train Accuracy: 92.36% Test Accuracy: 98.00%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3470 | Train Accuracy: 93.75% Test Accuracy: 98.08%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.3155 | Train Accuracy: 94.29% Test Accuracy: 98.17%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2918 | Train Accuracy: 94.82% Test Accuracy: 98.25%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2626 | Train Accuracy: 96.00% Test Accuracy: 98.33%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2449 | Train Accuracy: 96.57% Test Accuracy: 98.33%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2329 | Train Accuracy: 96.57% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.2143 | Train Accuracy: 97.11% Test Accuracy: 98.25%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1998 | Train Accuracy: 97.11% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1905 | Train Accuracy: 97.07% Test Accuracy: 98.50%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1713 | Train Accuracy: 97.68% Test Accuracy: 98.50%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1671 | Train Accuracy: 97.39% Test Accuracy: 98.50%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: ReLU | LR: 0.0001 Train Loss: 0.1639 | Train Accuracy: 97.07% Test Accuracy: 98.50%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.5480 | Train Accuracy: 24.86% Test Accuracy: 94.83%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1726 | Train Accuracy: 47.29% Test Accuracy: 96.67%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9989 | Train Accuracy: 61.18% Test Accuracy: 96.83%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.8674 | Train Accuracy: 70.21% Test Accuracy: 97.17%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7773 | Train Accuracy: 73.93% Test Accuracy: 97.50%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6814 | Train Accuracy: 80.39% Test Accuracy: 97.58%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.6143 | Train Accuracy: 84.50% Test Accuracy: 97.67%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5502 | Train Accuracy: 87.00% Test Accuracy: 97.58%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5014 | Train Accuracy: 89.71% Test Accuracy: 97.92%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4609 | Train Accuracy: 91.00% Test Accuracy: 98.17%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4282 | Train Accuracy: 92.54% Test Accuracy: 98.17%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3947 | Train Accuracy: 92.82% Test Accuracy: 98.33%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3817 | Train Accuracy: 92.36% Test Accuracy: 98.33%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3548 | Train Accuracy: 93.96% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3287 | Train Accuracy: 94.57% Test Accuracy: 98.42%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3071 | Train Accuracy: 94.86% Test Accuracy: 98.42%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2917 | Train Accuracy: 94.86% Test Accuracy: 98.58%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2821 | Train Accuracy: 95.14% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2695 | Train Accuracy: 95.21% Test Accuracy: 98.67%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2514 | Train Accuracy: 95.86% Test Accuracy: 98.67%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.5660 | Train Accuracy: 25.36% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 2.2892 | Train Accuracy: 25.82% Test Accuracy: 57.08%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 1.0897 | Train Accuracy: 54.43% Test Accuracy: 55.08%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8653 | Train Accuracy: 67.21% Test Accuracy: 72.08%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9310 | Train Accuracy: 58.21% Test Accuracy: 72.50%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8112 | Train Accuracy: 64.04% Test Accuracy: 97.67%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5560 | Train Accuracy: 83.07% Test Accuracy: 96.75%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4687 | Train Accuracy: 85.71% Test Accuracy: 95.33%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4329 | Train Accuracy: 85.54% Test Accuracy: 96.75%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4230 | Train Accuracy: 86.25% Test Accuracy: 97.50%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4132 | Train Accuracy: 87.04% Test Accuracy: 98.08%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3751 | Train Accuracy: 88.79% Test Accuracy: 98.17%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.3455 | Train Accuracy: 89.61% Test Accuracy: 98.17%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2953 | Train Accuracy: 91.64% Test Accuracy: 98.25%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2442 | Train Accuracy: 93.57% Test Accuracy: 98.08%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2215 | Train Accuracy: 94.11% Test Accuracy: 98.08%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2154 | Train Accuracy: 94.96% Test Accuracy: 97.92%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2133 | Train Accuracy: 95.07% Test Accuracy: 97.92%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2141 | Train Accuracy: 94.50% Test Accuracy: 97.83%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.01 Train Loss: 0.2048 | Train Accuracy: 94.75% Test Accuracy: 97.92%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.5425 | Train Accuracy: 24.43% Test Accuracy: 52.67%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3851 | Train Accuracy: 33.75% Test Accuracy: 92.17%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2861 | Train Accuracy: 38.46% Test Accuracy: 95.33%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2148 | Train Accuracy: 44.11% Test Accuracy: 96.92%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1699 | Train Accuracy: 48.25% Test Accuracy: 97.08%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1246 | Train Accuracy: 51.64% Test Accuracy: 97.42%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0842 | Train Accuracy: 54.64% Test Accuracy: 97.42%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0750 | Train Accuracy: 55.04% Test Accuracy: 97.25%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0321 | Train Accuracy: 59.18% Test Accuracy: 97.42%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0049 | Train Accuracy: 62.00% Test Accuracy: 97.50%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0057 | Train Accuracy: 60.96% Test Accuracy: 97.50%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9865 | Train Accuracy: 61.79% Test Accuracy: 97.75%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9607 | Train Accuracy: 64.96% Test Accuracy: 97.75%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9364 | Train Accuracy: 66.82% Test Accuracy: 97.83%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9084 | Train Accuracy: 67.82% Test Accuracy: 97.83%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8913 | Train Accuracy: 70.25% Test Accuracy: 97.92%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8802 | Train Accuracy: 70.14% Test Accuracy: 97.92%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8670 | Train Accuracy: 72.32% Test Accuracy: 98.08%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8495 | Train Accuracy: 72.57% Test Accuracy: 98.08%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8341 | Train Accuracy: 72.89% Test Accuracy: 98.17%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 1.5845 | Train Accuracy: 24.25% Test Accuracy: 93.25%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.3725 | Train Accuracy: 89.07% Test Accuracy: 97.75%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.2422 | Train Accuracy: 95.39% Test Accuracy: 97.83%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1747 | Train Accuracy: 96.82% Test Accuracy: 98.00%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1307 | Train Accuracy: 97.04% Test Accuracy: 97.92%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.1166 | Train Accuracy: 96.86% Test Accuracy: 98.00%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0906 | Train Accuracy: 97.68% Test Accuracy: 98.25%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0849 | Train Accuracy: 97.96% Test Accuracy: 98.42%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0745 | Train Accuracy: 97.82% Test Accuracy: 98.58%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0740 | Train Accuracy: 98.21% Test Accuracy: 98.75%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0675 | Train Accuracy: 98.32% Test Accuracy: 98.92%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0618 | Train Accuracy: 98.61% Test Accuracy: 99.00%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0690 | Train Accuracy: 98.18% Test Accuracy: 99.00%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0603 | Train Accuracy: 98.57% Test Accuracy: 99.00%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0610 | Train Accuracy: 98.54% Test Accuracy: 99.00%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0561 | Train Accuracy: 98.75% Test Accuracy: 99.17%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0517 | Train Accuracy: 98.71% Test Accuracy: 99.08%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0518 | Train Accuracy: 98.61% Test Accuracy: 99.17%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0488 | Train Accuracy: 98.86% Test Accuracy: 99.17%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.001 Train Loss: 0.0521 | Train Accuracy: 98.61% Test Accuracy: 99.17%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 1.6829 | Train Accuracy: 21.21% Test Accuracy: 90.75%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.9949 | Train Accuracy: 59.39% Test Accuracy: 74.83%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.6714 | Train Accuracy: 78.32% Test Accuracy: 57.33%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.3360 | Train Accuracy: 90.39% Test Accuracy: 71.83%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.4108 | Train Accuracy: 84.57% Test Accuracy: 97.67%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.2299 | Train Accuracy: 95.50% Test Accuracy: 97.58%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1727 | Train Accuracy: 96.18% Test Accuracy: 97.00%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1818 | Train Accuracy: 95.46% Test Accuracy: 96.92%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1805 | Train Accuracy: 94.96% Test Accuracy: 97.25%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1711 | Train Accuracy: 95.18% Test Accuracy: 97.75%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1466 | Train Accuracy: 96.00% Test Accuracy: 97.83%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1285 | Train Accuracy: 96.68% Test Accuracy: 97.92%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1232 | Train Accuracy: 97.21% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1126 | Train Accuracy: 97.43% Test Accuracy: 98.00%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1185 | Train Accuracy: 97.50% Test Accuracy: 98.00%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1281 | Train Accuracy: 97.46% Test Accuracy: 98.00%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1167 | Train Accuracy: 97.68% Test Accuracy: 98.00%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1156 | Train Accuracy: 97.61% Test Accuracy: 98.08%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.1094 | Train Accuracy: 97.46% Test Accuracy: 98.08%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.01 Train Loss: 0.0991 | Train Accuracy: 97.68% Test Accuracy: 98.25%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 1.5938 | Train Accuracy: 25.93% Test Accuracy: 93.67%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.8042 | Train Accuracy: 69.14% Test Accuracy: 96.58%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.5060 | Train Accuracy: 84.71% Test Accuracy: 97.25%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3788 | Train Accuracy: 90.50% Test Accuracy: 97.67%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.3016 | Train Accuracy: 93.50% Test Accuracy: 97.83%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2427 | Train Accuracy: 95.25% Test Accuracy: 97.83%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.2106 | Train Accuracy: 95.86% Test Accuracy: 97.83%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1860 | Train Accuracy: 96.21% Test Accuracy: 97.92%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1653 | Train Accuracy: 96.57% Test Accuracy: 97.92%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1450 | Train Accuracy: 97.32% Test Accuracy: 98.17%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1398 | Train Accuracy: 97.43% Test Accuracy: 98.17%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1265 | Train Accuracy: 97.25% Test Accuracy: 98.25%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1187 | Train Accuracy: 97.54% Test Accuracy: 98.33%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1144 | Train Accuracy: 97.50% Test Accuracy: 98.33%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.1062 | Train Accuracy: 97.61% Test Accuracy: 98.42%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0987 | Train Accuracy: 98.07% Test Accuracy: 98.50%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0939 | Train Accuracy: 97.93% Test Accuracy: 98.50%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0909 | Train Accuracy: 98.00% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0865 | Train Accuracy: 97.96% Test Accuracy: 98.67%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: True | Activation: Tanh | LR: 0.0001 Train Loss: 0.0849 | Train Accuracy: 98.04% Test Accuracy: 98.75%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 1.4935 | Train Accuracy: 24.82% Test Accuracy: 95.92%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.7521 | Train Accuracy: 70.93% Test Accuracy: 80.42%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.9940 | Train Accuracy: 76.86% Test Accuracy: 97.83%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.2626 | Train Accuracy: 92.43% Test Accuracy: 97.83%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.3427 | Train Accuracy: 89.61% Test Accuracy: 98.42%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.2200 | Train Accuracy: 94.82% Test Accuracy: 98.75%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1412 | Train Accuracy: 96.89% Test Accuracy: 99.00%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1394 | Train Accuracy: 97.54% Test Accuracy: 99.00%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1198 | Train Accuracy: 98.18% Test Accuracy: 98.92%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0945 | Train Accuracy: 98.29% Test Accuracy: 98.92%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0949 | Train Accuracy: 98.64% Test Accuracy: 99.00%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1208 | Train Accuracy: 98.18% Test Accuracy: 99.17%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1157 | Train Accuracy: 98.18% Test Accuracy: 99.08%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0954 | Train Accuracy: 98.14% Test Accuracy: 99.17%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.1174 | Train Accuracy: 98.39% Test Accuracy: 99.25%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0641 | Train Accuracy: 98.79% Test Accuracy: 99.42%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0680 | Train Accuracy: 98.86% Test Accuracy: 99.42%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0612 | Train Accuracy: 98.93% Test Accuracy: 99.42%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0609 | Train Accuracy: 99.00% Test Accuracy: 99.33%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.001 Train Loss: 0.0464 | Train Accuracy: 99.25% Test Accuracy: 99.08%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.4805 | Train Accuracy: 24.14% Test Accuracy: 41.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 63.2228 | Train Accuracy: 32.93% Test Accuracy: 73.08%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 65.2985 | Train Accuracy: 66.54% Test Accuracy: 79.33%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 57.3610 | Train Accuracy: 68.32% Test Accuracy: 98.25%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 7.5774 | Train Accuracy: 89.75% Test Accuracy: 89.33%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 20.5676 | Train Accuracy: 83.93% Test Accuracy: 97.92%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 4.8054 | Train Accuracy: 92.86% Test Accuracy: 98.25%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 5.2654 | Train Accuracy: 92.54% Test Accuracy: 98.17%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 6.0839 | Train Accuracy: 92.86% Test Accuracy: 98.33%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.5844 | Train Accuracy: 95.79% Test Accuracy: 98.50%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.7858 | Train Accuracy: 96.64% Test Accuracy: 98.25%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 4.6129 | Train Accuracy: 96.04% Test Accuracy: 98.50%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 3.5856 | Train Accuracy: 95.57% Test Accuracy: 99.00%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 2.5504 | Train Accuracy: 96.93% Test Accuracy: 99.17%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 2.9377 | Train Accuracy: 95.71% Test Accuracy: 98.92%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 2.8836 | Train Accuracy: 95.96% Test Accuracy: 98.67%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 2.0533 | Train Accuracy: 95.50% Test Accuracy: 98.50%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.6577 | Train Accuracy: 96.36% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 2.2479 | Train Accuracy: 96.86% Test Accuracy: 98.67%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.01 Train Loss: 1.6156 | Train Accuracy: 96.86% Test Accuracy: 98.67%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.4649 | Train Accuracy: 24.61% Test Accuracy: 96.25%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 1.1501 | Train Accuracy: 50.75% Test Accuracy: 97.25%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.9280 | Train Accuracy: 67.57% Test Accuracy: 97.33%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.7558 | Train Accuracy: 77.29% Test Accuracy: 97.25%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.6307 | Train Accuracy: 81.32% Test Accuracy: 97.25%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.5340 | Train Accuracy: 84.71% Test Accuracy: 97.33%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.4374 | Train Accuracy: 88.36% Test Accuracy: 97.42%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3742 | Train Accuracy: 89.89% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.3255 | Train Accuracy: 91.89% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2746 | Train Accuracy: 92.89% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2336 | Train Accuracy: 94.36% Test Accuracy: 97.83%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.2115 | Train Accuracy: 95.21% Test Accuracy: 98.08%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1767 | Train Accuracy: 95.39% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1512 | Train Accuracy: 96.25% Test Accuracy: 98.08%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1386 | Train Accuracy: 96.64% Test Accuracy: 98.17%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1322 | Train Accuracy: 96.29% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1059 | Train Accuracy: 97.11% Test Accuracy: 98.58%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.1118 | Train Accuracy: 97.18% Test Accuracy: 98.67%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0906 | Train Accuracy: 97.57% Test Accuracy: 98.75%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: ReLU | LR: 0.0001 Train Loss: 0.0890 | Train Accuracy: 97.61% Test Accuracy: 98.83%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.5192 | Train Accuracy: 24.64% Test Accuracy: 48.83%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 1.1518 | Train Accuracy: 47.75% Test Accuracy: 97.08%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.9139 | Train Accuracy: 63.75% Test Accuracy: 97.25%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.7187 | Train Accuracy: 77.25% Test Accuracy: 97.08%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.5721 | Train Accuracy: 84.32% Test Accuracy: 97.33%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.4647 | Train Accuracy: 89.93% Test Accuracy: 97.58%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.3721 | Train Accuracy: 93.89% Test Accuracy: 97.67%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2991 | Train Accuracy: 95.86% Test Accuracy: 97.75%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2512 | Train Accuracy: 96.64% Test Accuracy: 97.83%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.2012 | Train Accuracy: 97.21% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1746 | Train Accuracy: 97.32% Test Accuracy: 98.00%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1522 | Train Accuracy: 97.46% Test Accuracy: 98.00%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1337 | Train Accuracy: 97.43% Test Accuracy: 98.00%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1162 | Train Accuracy: 97.86% Test Accuracy: 98.00%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.1037 | Train Accuracy: 97.68% Test Accuracy: 98.08%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0915 | Train Accuracy: 97.96% Test Accuracy: 98.33%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0847 | Train Accuracy: 97.89% Test Accuracy: 98.67%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0767 | Train Accuracy: 98.32% Test Accuracy: 99.08%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0768 | Train Accuracy: 98.25% Test Accuracy: 99.33%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.001 Train Loss: 0.0747 | Train Accuracy: 98.32% Test Accuracy: 99.50%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.5522 | Train Accuracy: 25.68% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 4.6631 | Train Accuracy: 25.00% Test Accuracy: 50.00%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 2.1118 | Train Accuracy: 48.68% Test Accuracy: 48.25%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.2792 | Train Accuracy: 51.36% Test Accuracy: 48.67%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 1.1825 | Train Accuracy: 41.54% Test Accuracy: 68.67%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.9736 | Train Accuracy: 51.61% Test Accuracy: 59.75%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8739 | Train Accuracy: 58.46% Test Accuracy: 52.25%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.8345 | Train Accuracy: 58.00% Test Accuracy: 72.17%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7620 | Train Accuracy: 64.29% Test Accuracy: 72.58%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.7082 | Train Accuracy: 69.07% Test Accuracy: 72.67%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6616 | Train Accuracy: 70.25% Test Accuracy: 72.67%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.6022 | Train Accuracy: 70.96% Test Accuracy: 72.67%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5614 | Train Accuracy: 71.79% Test Accuracy: 72.58%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5268 | Train Accuracy: 75.39% Test Accuracy: 97.58%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.5035 | Train Accuracy: 76.86% Test Accuracy: 97.33%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4879 | Train Accuracy: 78.64% Test Accuracy: 96.92%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4773 | Train Accuracy: 80.54% Test Accuracy: 93.25%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4648 | Train Accuracy: 80.64% Test Accuracy: 96.58%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4523 | Train Accuracy: 82.07% Test Accuracy: 97.17%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.01 Train Loss: 0.4448 | Train Accuracy: 81.96% Test Accuracy: 97.33%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.6060 | Train Accuracy: 25.11% Test Accuracy: 25.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4796 | Train Accuracy: 28.86% Test Accuracy: 27.92%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.4045 | Train Accuracy: 31.86% Test Accuracy: 45.92%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.3441 | Train Accuracy: 34.68% Test Accuracy: 90.75%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2896 | Train Accuracy: 39.43% Test Accuracy: 97.17%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.2273 | Train Accuracy: 43.32% Test Accuracy: 95.92%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1725 | Train Accuracy: 46.93% Test Accuracy: 88.92%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.1488 | Train Accuracy: 48.79% Test Accuracy: 82.33%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0955 | Train Accuracy: 53.25% Test Accuracy: 79.17%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0654 | Train Accuracy: 53.36% Test Accuracy: 77.67%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 1.0354 | Train Accuracy: 56.14% Test Accuracy: 77.75%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9830 | Train Accuracy: 59.93% Test Accuracy: 79.25%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9758 | Train Accuracy: 59.18% Test Accuracy: 80.67%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9428 | Train Accuracy: 61.82% Test Accuracy: 82.75%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.9226 | Train Accuracy: 62.93% Test Accuracy: 85.75%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8870 | Train Accuracy: 65.89% Test Accuracy: 89.42%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8531 | Train Accuracy: 67.00% Test Accuracy: 92.75%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8519 | Train Accuracy: 67.00% Test Accuracy: 94.58%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.8241 | Train Accuracy: 68.50% Test Accuracy: 96.08%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Sigmoid | LR: 0.0001 Train Loss: 0.7833 | Train Accuracy: 71.93% Test Accuracy: 96.50%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 1.5711 | Train Accuracy: 21.96% Test Accuracy: 87.83%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.5461 | Train Accuracy: 77.86% Test Accuracy: 92.33%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.4517 | Train Accuracy: 82.14% Test Accuracy: 97.83%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1861 | Train Accuracy: 96.25% Test Accuracy: 97.42%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1507 | Train Accuracy: 96.50% Test Accuracy: 97.58%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1350 | Train Accuracy: 96.54% Test Accuracy: 97.92%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1288 | Train Accuracy: 96.82% Test Accuracy: 98.17%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.1055 | Train Accuracy: 97.07% Test Accuracy: 98.50%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0879 | Train Accuracy: 97.79% Test Accuracy: 98.67%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0799 | Train Accuracy: 97.61% Test Accuracy: 98.75%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0775 | Train Accuracy: 97.82% Test Accuracy: 98.83%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0727 | Train Accuracy: 97.79% Test Accuracy: 98.83%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0623 | Train Accuracy: 98.25% Test Accuracy: 98.92%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0681 | Train Accuracy: 98.25% Test Accuracy: 99.25%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0667 | Train Accuracy: 98.11% Test Accuracy: 99.17%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0607 | Train Accuracy: 98.39% Test Accuracy: 99.17%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0512 | Train Accuracy: 98.68% Test Accuracy: 99.17%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0520 | Train Accuracy: 98.89% Test Accuracy: 99.17%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0514 | Train Accuracy: 98.75% Test Accuracy: 99.25%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.001 Train Loss: 0.0462 | Train Accuracy: 98.82% Test Accuracy: 99.25%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.4941 | Train Accuracy: 25.89% Test Accuracy: 80.08%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.3847 | Train Accuracy: 48.79% Test Accuracy: 49.92%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.9457 | Train Accuracy: 52.57% Test Accuracy: 49.25%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.4580 | Train Accuracy: 54.14% Test Accuracy: 73.50%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 1.0244 | Train Accuracy: 67.07% Test Accuracy: 84.58%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.7104 | Train Accuracy: 73.64% Test Accuracy: 72.17%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.7246 | Train Accuracy: 72.36% Test Accuracy: 97.58%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.4594 | Train Accuracy: 86.11% Test Accuracy: 97.25%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3339 | Train Accuracy: 92.61% Test Accuracy: 97.00%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.3172 | Train Accuracy: 92.04% Test Accuracy: 97.17%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.2157 | Train Accuracy: 94.79% Test Accuracy: 97.58%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1822 | Train Accuracy: 95.64% Test Accuracy: 97.58%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1525 | Train Accuracy: 96.71% Test Accuracy: 97.50%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1534 | Train Accuracy: 96.14% Test Accuracy: 97.50%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1440 | Train Accuracy: 95.96% Test Accuracy: 97.92%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1566 | Train Accuracy: 95.61% Test Accuracy: 98.25%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1669 | Train Accuracy: 95.32% Test Accuracy: 98.17%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1383 | Train Accuracy: 96.46% Test Accuracy: 98.33%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.1099 | Train Accuracy: 97.14% Test Accuracy: 98.25%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.01 Train Loss: 0.0969 | Train Accuracy: 97.50% Test Accuracy: 98.25%\n",
      "Epoch [1/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 1.5597 | Train Accuracy: 22.43% Test Accuracy: 95.00%\n",
      "Epoch [2/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.8596 | Train Accuracy: 67.61% Test Accuracy: 96.25%\n",
      "Epoch [3/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.5847 | Train Accuracy: 81.46% Test Accuracy: 97.00%\n",
      "Epoch [4/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.4349 | Train Accuracy: 88.46% Test Accuracy: 97.33%\n",
      "Epoch [5/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.3606 | Train Accuracy: 91.50% Test Accuracy: 97.50%\n",
      "Epoch [6/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2825 | Train Accuracy: 94.36% Test Accuracy: 97.58%\n",
      "Epoch [7/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2468 | Train Accuracy: 95.25% Test Accuracy: 97.83%\n",
      "Epoch [8/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.2092 | Train Accuracy: 96.14% Test Accuracy: 97.92%\n",
      "Epoch [9/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1810 | Train Accuracy: 96.43% Test Accuracy: 97.92%\n",
      "Epoch [10/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1702 | Train Accuracy: 96.89% Test Accuracy: 97.83%\n",
      "Epoch [11/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1445 | Train Accuracy: 97.36% Test Accuracy: 97.92%\n",
      "Epoch [12/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1236 | Train Accuracy: 97.46% Test Accuracy: 98.00%\n",
      "Epoch [13/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1202 | Train Accuracy: 97.43% Test Accuracy: 98.17%\n",
      "Epoch [14/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1135 | Train Accuracy: 97.82% Test Accuracy: 98.25%\n",
      "Epoch [15/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.1021 | Train Accuracy: 97.61% Test Accuracy: 98.25%\n",
      "Epoch [16/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0936 | Train Accuracy: 97.86% Test Accuracy: 98.42%\n",
      "Epoch [17/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0922 | Train Accuracy: 97.79% Test Accuracy: 98.42%\n",
      "Epoch [18/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0850 | Train Accuracy: 98.04% Test Accuracy: 98.58%\n",
      "Epoch [19/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0832 | Train Accuracy: 97.93% Test Accuracy: 98.67%\n",
      "Epoch [20/20] | Hidden: [1024, 512] | Dropout: 0.8 | BatchNorm: False | Activation: Tanh | LR: 0.0001 Train Loss: 0.0800 | Train Accuracy: 97.93% Test Accuracy: 98.58%\n",
      "\n",
      "Best Model Hyperparameters:\n",
      "Hidden Layers: [512, 256]\n",
      "Dropout Rate: 0.5\n",
      "Batch Normalization: True\n",
      "Activation Function: ReLU\n",
      "Learning Rate: 0.001\n",
      "Best Test Accuracy: 99.50%\n",
      "Epoch [1/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 1.5033 | Train Accuracy: 24.71% Test Accuracy: 97.42%\n",
      "Epoch [2/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.4825 | Train Accuracy: 93.25% Test Accuracy: 97.67%\n",
      "Epoch [3/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.3000 | Train Accuracy: 96.82% Test Accuracy: 97.92%\n",
      "Epoch [4/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.2184 | Train Accuracy: 97.39% Test Accuracy: 98.08%\n",
      "Epoch [5/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1707 | Train Accuracy: 97.39% Test Accuracy: 98.08%\n",
      "Epoch [6/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1434 | Train Accuracy: 97.46% Test Accuracy: 98.17%\n",
      "Epoch [7/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1213 | Train Accuracy: 97.68% Test Accuracy: 98.17%\n",
      "Epoch [8/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.1113 | Train Accuracy: 97.57% Test Accuracy: 98.33%\n",
      "Epoch [9/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0984 | Train Accuracy: 98.04% Test Accuracy: 98.33%\n",
      "Epoch [10/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0916 | Train Accuracy: 97.93% Test Accuracy: 98.25%\n",
      "Epoch [11/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0862 | Train Accuracy: 98.00% Test Accuracy: 98.58%\n",
      "Epoch [12/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0759 | Train Accuracy: 98.18% Test Accuracy: 98.58%\n",
      "Epoch [13/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0724 | Train Accuracy: 98.21% Test Accuracy: 98.83%\n",
      "Epoch [14/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0664 | Train Accuracy: 98.39% Test Accuracy: 99.00%\n",
      "Epoch [15/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0620 | Train Accuracy: 98.50% Test Accuracy: 99.17%\n",
      "Epoch [16/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0608 | Train Accuracy: 98.61% Test Accuracy: 99.25%\n",
      "Epoch [17/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0576 | Train Accuracy: 98.64% Test Accuracy: 99.33%\n",
      "Epoch [18/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0567 | Train Accuracy: 98.82% Test Accuracy: 99.33%\n",
      "Epoch [19/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0557 | Train Accuracy: 98.79% Test Accuracy: 99.42%\n",
      "Epoch [20/20] | Hidden: [512, 256] | Dropout: 0.5 | BatchNorm: True | Activation: ReLU | LR: 0.001 Train Loss: 0.0496 | Train Accuracy: 98.82% Test Accuracy: 99.50%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.50%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   BreastMRI       0.99      1.00      1.00       300\n",
      "     ChestCT       1.00      0.99      0.99       300\n",
      "         CXR       1.00      1.00      1.00       300\n",
      "        Hand       0.99      0.99      0.99       300\n",
      "\n",
      "    accuracy                           0.99      1200\n",
      "   macro avg       1.00      0.99      0.99      1200\n",
      "weighted avg       1.00      0.99      0.99      1200\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Υλοποίηση του MLP για πειραματισμό με διαφορετικές υπερπαραμέτρους\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.0, use_batchnorm=False, activation_fn=nn.ReLU):\n",
    "        super(MLP, self).__init__()\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.layers = nn.ModuleList()  # Αρχικοποιούμε τη λίστα των layers\n",
    "        in_size = input_size\n",
    "        \n",
    "        # Δημιουργία των κρυφών επιπέδων\n",
    "        for hidden_size in hidden_sizes:\n",
    "            self.layers.append(nn.Linear(in_size, hidden_size))  # Πρόσθεση Linear Layer\n",
    "            if self.use_batchnorm: \n",
    "                self.layers.append(nn.BatchNorm1d(hidden_size))  # Πρόσθεση Batch Normalization (αν το ζητήσουμε)\n",
    "            self.layers.append(activation_fn())  # Συναρτήσεις ενεργοποίησης (π.χ. ReLU, Sigmoid, Tanh)\n",
    "            self.layers.append(nn.Dropout(dropout_rate))  # Πρόσθεση Dropout για κανονικοποίηση\n",
    "            in_size = hidden_size  # Ορίζουμε το in_size για το επόμενο επίπεδο\n",
    "\n",
    "        # Εξοδος\n",
    "        self.output = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Προώθηση μέσω των layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Προώθηση μέσω του τελευταίου επιπέδου (output layer)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Ρυθμίσεις υπερπαραμέτρων για πειραματισμό\n",
    "input_size = X_train_tensor.shape[1]  # 4096\n",
    "hidden_sizes = [[512, 256], [512, 256, 128], [1024, 512]]  # Πειραματισμός με διαφορετικά μεγέθη\n",
    "output_size = len(np.unique(y_train))  # Ο αριθμός των κατηγοριών\n",
    "dropout_rates = [0.2, 0.5, 0.8]  # Πειραματισμός με διαφορετικούς ρυθμούς dropout\n",
    "batchnorm_options = [True, False]  # Χρήση ή όχι Batch Normalization\n",
    "activation_functions = [nn.ReLU, nn.Sigmoid, nn.Tanh]  # Πειραματισμός με διαφορετικές συναρτήσεις ενεργοποίησης\n",
    "learning_rates = [0.001, 0.01, 0.0001]  # Πειραματισμός με διαφορετικούς ρυθμούς μάθησης\n",
    "\n",
    "# Ορισμός του Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Αρχικοποίηση των λιστών για την καταγραφή της απώλειας και της ακρίβειας\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Αποθήκευση των καλύτερων υπερπαραμέτρων και της αντίστοιχης ακρίβειας\n",
    "best_accuracy = 0\n",
    "best_hyperparams = {}\n",
    "\n",
    "# Εκπαίδευση και αξιολόγηση για κάθε συνδυασμό υπερπαραμέτρων\n",
    "for hidden_size in hidden_sizes:\n",
    "    for dropout_rate in dropout_rates:\n",
    "        for use_batchnorm in batchnorm_options:\n",
    "            for activation_fn in activation_functions:\n",
    "                for lr in learning_rates:\n",
    "                    # Δημιουργία του μοντέλου με τις τρέχουσες υπερπαράμετρους\n",
    "                    model = MLP(input_size, hidden_size, output_size, dropout_rate, use_batchnorm, activation_fn).to(device)\n",
    "\n",
    "                    # Ορισμός του Optimizer\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                    # Εκπαίδευση του μοντέλου για 20 εποχές\n",
    "                    for epoch in range(1, 21):\n",
    "                        model.train()  # Θέτουμε το μοντέλο σε training mode\n",
    "                        optimizer.zero_grad()  # Μηδενίζουμε τους παραμέτρους του βελτιστοποιητή\n",
    "\n",
    "                        # Forward Pass για το train set\n",
    "                        outputs_train = model(X_train_tensor)\n",
    "                        loss_train = criterion(outputs_train, y_train_tensor)\n",
    "\n",
    "                        # Backward Pass και Βελτιστοποίηση\n",
    "                        loss_train.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        # Υπολογισμός της ακρίβειας για το train set\n",
    "                        _, predicted_train = torch.max(outputs_train, 1)\n",
    "                        train_accuracy = accuracy_score(y_train_tensor.cpu(), predicted_train.cpu())\n",
    "\n",
    "                        # Αξιολόγηση στο test set\n",
    "                        model.eval()  # Θέτουμε το μοντέλο σε evaluation mode\n",
    "                        with torch.no_grad():\n",
    "                            outputs_test = model(X_test_tensor)\n",
    "                            loss_test = criterion(outputs_test, y_test_tensor)\n",
    "                            _, predicted_test = torch.max(outputs_test, 1)\n",
    "                            test_accuracy = accuracy_score(y_test_tensor.cpu(), predicted_test.cpu())\n",
    "\n",
    "                        # Καταγραφή των τιμών του loss και accuracy\n",
    "                        train_losses.append(loss_train.item())\n",
    "                        train_accuracies.append(train_accuracy)\n",
    "                        test_losses.append(loss_test.item())\n",
    "                        test_accuracies.append(test_accuracy)\n",
    "\n",
    "                        # Εκτύπωση της πρόοδου κάθε epoch\n",
    "                        print(f\"Epoch [{epoch}/20] | Hidden: {hidden_size} | Dropout: {dropout_rate} | \"\n",
    "                              f\"BatchNorm: {use_batchnorm} | Activation: {activation_fn.__name__} | LR: {lr} \"\n",
    "                              f\"Train Loss: {loss_train.item():.4f} | Train Accuracy: {train_accuracy*100:.2f}% \"\n",
    "                              f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "                    # Ελέγχουμε αν η τρέχουσα ακρίβεια στο test set είναι καλύτερη από την καλύτερη\n",
    "                    if test_accuracy > best_accuracy:\n",
    "                        best_accuracy = test_accuracy\n",
    "                        best_hyperparams = {\n",
    "                            \"hidden_sizes\": hidden_size,\n",
    "                            \"dropout_rate\": dropout_rate,\n",
    "                            \"batchnorm\": use_batchnorm,\n",
    "                            \"activation_fn\": activation_fn.__name__,\n",
    "                            \"learning_rate\": lr\n",
    "                        }\n",
    "\n",
    "# Εκτύπωση των καλύτερων υπερπαραμέτρων και της αντίστοιχης ακρίβειας\n",
    "print(\"\\nBest Model Hyperparameters:\")\n",
    "print(f\"Hidden Layers: {best_hyperparams['hidden_sizes']}\")\n",
    "print(f\"Dropout Rate: {best_hyperparams['dropout_rate']}\")\n",
    "print(f\"Batch Normalization: {best_hyperparams['batchnorm']}\")\n",
    "print(f\"Activation Function: {best_hyperparams['activation_fn']}\")\n",
    "print(f\"Learning Rate: {best_hyperparams['learning_rate']}\")\n",
    "print(f\"Best Test Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Εκπαίδευση και αξιολόγηση για το καλύτερο μοντέλο με τα βέλτιστα υπερπαραμέτρους\n",
    "train_losses_best = []\n",
    "train_accuracies_best = []\n",
    "test_losses_best = []\n",
    "test_accuracies_best = []\n",
    "\n",
    "# Δημιουργία του μοντέλου με τις καλύτερες υπερπαράμετρους\n",
    "model_best = MLP(input_size, best_hyperparams[\"hidden_sizes\"], output_size,\n",
    "                 best_hyperparams[\"dropout_rate\"], best_hyperparams[\"batchnorm\"],\n",
    "                 activation_fn=eval(f\"nn.{best_hyperparams['activation_fn']}\")).to(device)\n",
    "\n",
    "optimizer_best = optim.Adam(model_best.parameters(), lr=best_hyperparams[\"learning_rate\"])\n",
    "\n",
    "# Εκπαίδευση του καλύτερου μοντέλου για 20 εποχές\n",
    "for epoch in range(1, 21):\n",
    "    model_best.train()  # Θέτουμε το μοντέλο σε training mode\n",
    "    optimizer_best.zero_grad()  # Μηδενίζουμε τους παραμέτρους του βελτιστοποιητή\n",
    "\n",
    "    # Forward Pass για το train set\n",
    "    outputs_train_best = model_best(X_train_tensor)\n",
    "    loss_train_best = criterion(outputs_train_best, y_train_tensor)\n",
    "\n",
    "    # Backward Pass και Βελτιστοποίηση\n",
    "    loss_train_best.backward()\n",
    "    optimizer_best.step()\n",
    "\n",
    "    # Υπολογισμός της ακρίβειας για το train set\n",
    "    _, predicted_train_best = torch.max(outputs_train_best, 1)\n",
    "    train_accuracy_best = accuracy_score(y_train_tensor.cpu(), predicted_train_best.cpu())\n",
    "\n",
    "    # Αξιολόγηση στο test set\n",
    "    model_best.eval()  # Θέτουμε το μοντέλο σε evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs_test_best = model_best(X_test_tensor)\n",
    "        loss_test_best = criterion(outputs_test_best, y_test_tensor)\n",
    "        _, predicted_test_best = torch.max(outputs_test_best, 1)\n",
    "        test_accuracy_best = accuracy_score(y_test_tensor.cpu(), predicted_test_best.cpu())\n",
    "\n",
    "    # Καταγραφή των τιμών του loss και accuracy\n",
    "    train_losses_best.append(loss_train_best.item())\n",
    "    train_accuracies_best.append(train_accuracy_best)\n",
    "    test_losses_best.append(loss_test_best.item())\n",
    "    test_accuracies_best.append(test_accuracy_best)\n",
    "\n",
    "    # Εκτύπωση της πρόοδου κάθε epoch\n",
    "    print(f\"Epoch [{epoch}/20] | Hidden: {best_hyperparams['hidden_sizes']} | Dropout: {best_hyperparams['dropout_rate']} | \"\n",
    "          f\"BatchNorm: {best_hyperparams['batchnorm']} | Activation: {best_hyperparams['activation_fn']} | LR: {best_hyperparams['learning_rate']} \"\n",
    "          f\"Train Loss: {loss_train_best.item():.4f} | Train Accuracy: {train_accuracy_best*100:.2f}% \"\n",
    "          f\"Test Accuracy: {test_accuracy_best*100:.2f}%\")\n",
    "\n",
    "# Οπτικοποίηση των Loss και Accuracy για Train και Test\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 21), train_losses_best, label='Train Loss', color='blue')\n",
    "plt.plot(range(1, 21), test_losses_best, label='Test Loss', color='red')\n",
    "plt.title('Train vs Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 21), train_accuracies_best, label='Train Accuracy', color='blue')\n",
    "plt.plot(range(1, 21), test_accuracies_best, label='Test Accuracy', color='red')\n",
    "plt.title('Train vs Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Αξιολόγηση του μοντέλου στο test set\n",
    "model_best.eval()  # Θέτουμε το μοντέλο σε evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs_test_best = model_best(X_test_tensor)  # Εκτιμούμε το test set\n",
    "    _, predicted_test_best = torch.max(outputs_test_best, 1)  # Παίρνουμε τις προβλέψεις\n",
    "\n",
    "    # Υπολογισμός της ακρίβειας για το test set\n",
    "    test_accuracy_best = accuracy_score(y_test_tensor.cpu(), predicted_test_best.cpu())\n",
    "    print(f'Test Accuracy: {test_accuracy_best * 100:.2f}%')\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_tensor.cpu(), predicted_test_best.cpu(), target_names=class_names))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm_best = confusion_matrix(y_test_tensor.cpu(), predicted_test_best.cpu())\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_best, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve - Multi-class ROC Curve\n",
    "    y_test_bin_best = label_binarize(y_test_tensor.cpu(), classes=np.arange(len(class_names)))\n",
    "    outputs_test_best_softmax = outputs_test_best.softmax(dim=1).cpu().numpy()  # Softmax για την εκτίμηση των πιθανοτήτων\n",
    "\n",
    "    # Υπολογισμός του ROC Curve για κάθε κατηγορία\n",
    "    fpr_best, tpr_best, roc_auc_best = {}, {}, {}\n",
    "    for i in range(len(class_names)):\n",
    "        fpr_best[i], tpr_best[i], _ = roc_curve(y_test_bin_best[:, i], outputs_test_best_softmax[:, i])\n",
    "        roc_auc_best[i] = auc(fpr_best[i], tpr_best[i])\n",
    "\n",
    "    # Plotting ROC Curve για κάθε κατηγορία\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(len(class_names)):\n",
    "        plt.plot(fpr_best[i], tpr_best[i], label=f'{class_names[i]} (AUC = {roc_auc_best[i]:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-class ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
